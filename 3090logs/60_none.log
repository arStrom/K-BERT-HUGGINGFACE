nohup: ignoring input
  0%|          | 0/82 [00:00<?, ?it/s]100%|██████████| 82/82 [00:00<00:00, 561065.14it/s]
model:  ernie-rcnn-catlstmwide
pretrained:  ernie1
task:  MLC-slice
dataset:  book_multilabels_task_slice
seq_length:  256
hidden_dropout_prob:  0.1
attention_probs_dropout_prob:  0.1
epochs_num:  20
batch_size:  8
learning_rate:  2e-05
report_steps:  100
kg_name:  CnDbpedia
no_kg:  True
no_vm:  True
GPU:  NVIDIA GeForce RTX 3090
Vocabulary Size:  17964
[BertClassifier] use visible_matrix: False
Some weights of ErnieRCNNForMultiLabelSequenceClassificationSliceCatLSTMWide were not initialized from the model checkpoint at ./models/ernie1 and are newly initialized: ['lstm.weight_ih_l1_reverse', 'lstm.bias_ih_l0_reverse', 'classifier.bias', 'lstm.weight_hh_l0', 'output_layer_1.bias', 'lstm.bias_ih_l1_reverse', 'lstm.weight_ih_l1', 'lstm.bias_hh_l1_reverse', 'lstm.weight_hh_l1', 'lstm.bias_hh_l1', 'lstm.bias_hh_l0', 'classifier.weight', 'lstm.bias_hh_l0_reverse', 'output_layer_1.weight', 'lstm.weight_hh_l1_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.weight_ih_l0_reverse', 'lstm.bias_ih_l0', 'lstm.bias_ih_l1', 'lstm.weight_ih_l0']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
1 GPUs are available. Let's use them.
device:  cuda
Start training.
Loading sentences from ./datasets/book_multilabels_task_slice/train.tsv
There are 9097 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/9097
Loading sentences from ./datasets/book_multilabels_task_slice/dev.tsv
There are 2084 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/2084
Loading sentences from ./datasets/book_multilabels_task_slice/test.tsv
There are 2067 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/2067
/root/miniconda3/envs/lyq/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Epoch id: 1, Training steps: 100, Train Acc:  0.00%, Train Loss: 0.073225, Train Avg Loss: 0.182527, Time: 0:00:31
Epoch id: 1, Training steps: 200, Train Acc:  0.00%, Train Loss: 0.081455, Train Avg Loss: 0.086405, Time: 0:01:02
Epoch id: 1, Training steps: 300, Train Acc:  0.00%, Train Loss: 0.073651, Train Avg Loss: 0.082173, Time: 0:01:33
Epoch id: 1, Training steps: 400, Train Acc:  0.00%, Train Loss: 0.062885, Train Avg Loss: 0.080625, Time: 0:02:04
Epoch id: 1, Training steps: 500, Train Acc:  0.00%, Train Loss: 0.088058, Train Avg Loss: 0.077730, Time: 0:02:35
Epoch id: 1, Training steps: 600, Train Acc:  0.00%, Train Loss: 0.074120, Train Avg Loss: 0.075535, Time: 0:03:06
Epoch id: 1, Training steps: 700, Train Acc:  0.00%, Train Loss: 0.083853, Train Avg Loss: 0.072359, Time: 0:03:37
Epoch id: 1, Training steps: 800, Train Acc:  0.00%, Train Loss: 0.075350, Train Avg Loss: 0.070861, Time: 0:04:08
Epoch id: 1, Training steps: 900, Train Acc:  0.00%, Train Loss: 0.066568, Train Avg Loss: 0.066516, Time: 0:04:39
Epoch id: 1, Training steps: 1000, Train Acc:  0.00%, Train Loss: 0.077147, Train Avg Loss: 0.064173, Time: 0:05:10
Epoch id: 1, Training steps: 1100, Train Acc:  0.00%, Train Loss: 0.061553, Train Avg Loss: 0.060879, Time: 0:05:41
Epoch id: 2, Training steps: 100, Train Acc: 12.50%, Train Loss: 0.042594, Train Avg Loss: 0.073563, Time: 0:06:24
Epoch id: 2, Training steps: 200, Train Acc:  0.00%, Train Loss: 0.047181, Train Avg Loss: 0.050489, Time: 0:06:55
Epoch id: 2, Training steps: 300, Train Acc: 25.00%, Train Loss: 0.037514, Train Avg Loss: 0.045999, Time: 0:07:26
Epoch id: 2, Training steps: 400, Train Acc: 25.00%, Train Loss: 0.051629, Train Avg Loss: 0.044145, Time: 0:07:57
Epoch id: 2, Training steps: 500, Train Acc: 25.00%, Train Loss: 0.028506, Train Avg Loss: 0.041847, Time: 0:08:28
Epoch id: 2, Training steps: 600, Train Acc:  0.00%, Train Loss: 0.030461, Train Avg Loss: 0.041577, Time: 0:08:59
Epoch id: 2, Training steps: 700, Train Acc: 25.00%, Train Loss: 0.031054, Train Avg Loss: 0.040131, Time: 0:09:30
Epoch id: 2, Training steps: 800, Train Acc: 37.50%, Train Loss: 0.030187, Train Avg Loss: 0.035463, Time: 0:10:01
Epoch id: 2, Training steps: 900, Train Acc: 25.00%, Train Loss: 0.025933, Train Avg Loss: 0.036747, Time: 0:10:32
Epoch id: 2, Training steps: 1000, Train Acc:  0.00%, Train Loss: 0.038616, Train Avg Loss: 0.036597, Time: 0:11:03
Epoch id: 2, Training steps: 1100, Train Acc: 25.00%, Train Loss: 0.039549, Train Avg Loss: 0.033639, Time: 0:11:34
Epoch id: 3, Training steps: 100, Train Acc: 12.50%, Train Loss: 0.045302, Train Avg Loss: 0.041196, Time: 0:12:17
Epoch id: 3, Training steps: 200, Train Acc: 50.00%, Train Loss: 0.034304, Train Avg Loss: 0.029561, Time: 0:12:48
Epoch id: 3, Training steps: 300, Train Acc: 50.00%, Train Loss: 0.021284, Train Avg Loss: 0.029581, Time: 0:13:19
Epoch id: 3, Training steps: 400, Train Acc: 25.00%, Train Loss: 0.020890, Train Avg Loss: 0.027614, Time: 0:13:50
Epoch id: 3, Training steps: 500, Train Acc: 50.00%, Train Loss: 0.022296, Train Avg Loss: 0.026870, Time: 0:14:21
Epoch id: 3, Training steps: 600, Train Acc: 25.00%, Train Loss: 0.043674, Train Avg Loss: 0.024971, Time: 0:14:52
Epoch id: 3, Training steps: 700, Train Acc: 62.50%, Train Loss: 0.024044, Train Avg Loss: 0.025959, Time: 0:15:23
Epoch id: 3, Training steps: 800, Train Acc: 50.00%, Train Loss: 0.025508, Train Avg Loss: 0.026957, Time: 0:15:54
Epoch id: 3, Training steps: 900, Train Acc: 25.00%, Train Loss: 0.019227, Train Avg Loss: 0.024879, Time: 0:16:26
Epoch id: 3, Training steps: 1000, Train Acc: 50.00%, Train Loss: 0.020914, Train Avg Loss: 0.026430, Time: 0:16:57
Epoch id: 3, Training steps: 1100, Train Acc:  0.00%, Train Loss: 0.043625, Train Avg Loss: 0.028163, Time: 0:17:28
Epoch id: 4, Training steps: 100, Train Acc: 75.00%, Train Loss: 0.009132, Train Avg Loss: 0.028610, Time: 0:18:10
Epoch id: 4, Training steps: 200, Train Acc: 50.00%, Train Loss: 0.015931, Train Avg Loss: 0.020061, Time: 0:18:42
Epoch id: 4, Training steps: 300, Train Acc: 37.50%, Train Loss: 0.040535, Train Avg Loss: 0.021594, Time: 0:19:13
Epoch id: 4, Training steps: 400, Train Acc: 37.50%, Train Loss: 0.019244, Train Avg Loss: 0.020701, Time: 0:19:44
Epoch id: 4, Training steps: 500, Train Acc: 50.00%, Train Loss: 0.016212, Train Avg Loss: 0.019934, Time: 0:20:15
Epoch id: 4, Training steps: 600, Train Acc: 62.50%, Train Loss: 0.020817, Train Avg Loss: 0.020308, Time: 0:20:46
Epoch id: 4, Training steps: 700, Train Acc: 62.50%, Train Loss: 0.017150, Train Avg Loss: 0.020292, Time: 0:21:17
Epoch id: 4, Training steps: 800, Train Acc: 50.00%, Train Loss: 0.017560, Train Avg Loss: 0.021864, Time: 0:21:48
Epoch id: 4, Training steps: 900, Train Acc: 50.00%, Train Loss: 0.010862, Train Avg Loss: 0.019840, Time: 0:22:19
Epoch id: 4, Training steps: 1000, Train Acc: 50.00%, Train Loss: 0.018715, Train Avg Loss: 0.019357, Time: 0:22:50
Epoch id: 4, Training steps: 1100, Train Acc: 37.50%, Train Loss: 0.034672, Train Avg Loss: 0.019736, Time: 0:23:22
Epoch id: 5, Training steps: 100, Train Acc: 50.00%, Train Loss: 0.009908, Train Avg Loss: 0.022516, Time: 0:24:04
Epoch id: 5, Training steps: 200, Train Acc: 62.50%, Train Loss: 0.011166, Train Avg Loss: 0.015314, Time: 0:24:35
Epoch id: 5, Training steps: 300, Train Acc: 75.00%, Train Loss: 0.004188, Train Avg Loss: 0.016817, Time: 0:25:06
Epoch id: 5, Training steps: 400, Train Acc: 25.00%, Train Loss: 0.032839, Train Avg Loss: 0.015151, Time: 0:25:37
Epoch id: 5, Training steps: 500, Train Acc: 62.50%, Train Loss: 0.011840, Train Avg Loss: 0.013984, Time: 0:26:09
Epoch id: 5, Training steps: 600, Train Acc: 62.50%, Train Loss: 0.005259, Train Avg Loss: 0.016514, Time: 0:26:40
Epoch id: 5, Training steps: 700, Train Acc: 62.50%, Train Loss: 0.029593, Train Avg Loss: 0.015952, Time: 0:27:11
Epoch id: 5, Training steps: 800, Train Acc: 37.50%, Train Loss: 0.025691, Train Avg Loss: 0.015971, Time: 0:27:42
Epoch id: 5, Training steps: 900, Train Acc: 87.50%, Train Loss: 0.003255, Train Avg Loss: 0.015212, Time: 0:28:13
Epoch id: 5, Training steps: 1000, Train Acc: 62.50%, Train Loss: 0.007089, Train Avg Loss: 0.015413, Time: 0:28:44
Epoch id: 5, Training steps: 1100, Train Acc: 62.50%, Train Loss: 0.010191, Train Avg Loss: 0.016052, Time: 0:29:15
Epoch id: 6, Training steps: 100, Train Acc: 37.50%, Train Loss: 0.022706, Train Avg Loss: 0.018866, Time: 0:29:58
Epoch id: 6, Training steps: 200, Train Acc: 37.50%, Train Loss: 0.012042, Train Avg Loss: 0.011711, Time: 0:30:29
Epoch id: 6, Training steps: 300, Train Acc: 75.00%, Train Loss: 0.007861, Train Avg Loss: 0.010958, Time: 0:31:00
Epoch id: 6, Training steps: 400, Train Acc: 87.50%, Train Loss: 0.011502, Train Avg Loss: 0.013349, Time: 0:31:32
Epoch id: 6, Training steps: 500, Train Acc: 62.50%, Train Loss: 0.011631, Train Avg Loss: 0.012152, Time: 0:32:03
Epoch id: 6, Training steps: 600, Train Acc: 62.50%, Train Loss: 0.009656, Train Avg Loss: 0.012701, Time: 0:32:34
Epoch id: 6, Training steps: 700, Train Acc: 50.00%, Train Loss: 0.010237, Train Avg Loss: 0.012915, Time: 0:33:05
Epoch id: 6, Training steps: 800, Train Acc: 75.00%, Train Loss: 0.008621, Train Avg Loss: 0.011876, Time: 0:33:37
Epoch id: 6, Training steps: 900, Train Acc: 50.00%, Train Loss: 0.014225, Train Avg Loss: 0.011784, Time: 0:34:08
Epoch id: 6, Training steps: 1000, Train Acc: 75.00%, Train Loss: 0.012233, Train Avg Loss: 0.010155, Time: 0:34:39
Epoch id: 6, Training steps: 1100, Train Acc: 62.50%, Train Loss: 0.006500, Train Avg Loss: 0.012571, Time: 0:35:10
Epoch id: 7, Training steps: 100, Train Acc: 62.50%, Train Loss: 0.002900, Train Avg Loss: 0.013608, Time: 0:35:53
Epoch id: 7, Training steps: 200, Train Acc: 75.00%, Train Loss: 0.008503, Train Avg Loss: 0.008329, Time: 0:36:24
Epoch id: 7, Training steps: 300, Train Acc: 25.00%, Train Loss: 0.019280, Train Avg Loss: 0.009237, Time: 0:36:56
Epoch id: 7, Training steps: 400, Train Acc: 75.00%, Train Loss: 0.013812, Train Avg Loss: 0.009403, Time: 0:37:27
Epoch id: 7, Training steps: 500, Train Acc: 50.00%, Train Loss: 0.023358, Train Avg Loss: 0.008898, Time: 0:37:58
Epoch id: 7, Training steps: 600, Train Acc: 37.50%, Train Loss: 0.012895, Train Avg Loss: 0.009159, Time: 0:38:29
Epoch id: 7, Training steps: 700, Train Acc: 87.50%, Train Loss: 0.004065, Train Avg Loss: 0.009961, Time: 0:39:01
Epoch id: 7, Training steps: 800, Train Acc: 75.00%, Train Loss: 0.009984, Train Avg Loss: 0.010124, Time: 0:39:32
Epoch id: 7, Training steps: 900, Train Acc: 100.00%, Train Loss: 0.001309, Train Avg Loss: 0.009295, Time: 0:40:03
Epoch id: 7, Training steps: 1000, Train Acc: 100.00%, Train Loss: 0.004027, Train Avg Loss: 0.009575, Time: 0:40:35
Epoch id: 7, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.013964, Train Avg Loss: 0.010415, Time: 0:41:06
Epoch id: 8, Training steps: 100, Train Acc: 50.00%, Train Loss: 0.013198, Train Avg Loss: 0.011607, Time: 0:41:49
Epoch id: 8, Training steps: 200, Train Acc: 75.00%, Train Loss: 0.008540, Train Avg Loss: 0.006433, Time: 0:42:20
Epoch id: 8, Training steps: 300, Train Acc: 62.50%, Train Loss: 0.009639, Train Avg Loss: 0.006789, Time: 0:42:51
Epoch id: 8, Training steps: 400, Train Acc: 62.50%, Train Loss: 0.008953, Train Avg Loss: 0.007179, Time: 0:43:23
Epoch id: 8, Training steps: 500, Train Acc: 75.00%, Train Loss: 0.007103, Train Avg Loss: 0.006878, Time: 0:43:54
Epoch id: 8, Training steps: 600, Train Acc: 62.50%, Train Loss: 0.011433, Train Avg Loss: 0.007093, Time: 0:44:25
Epoch id: 8, Training steps: 700, Train Acc: 75.00%, Train Loss: 0.006862, Train Avg Loss: 0.007326, Time: 0:44:57
Epoch id: 8, Training steps: 800, Train Acc: 87.50%, Train Loss: 0.004694, Train Avg Loss: 0.007902, Time: 0:45:28
Epoch id: 8, Training steps: 900, Train Acc: 75.00%, Train Loss: 0.005669, Train Avg Loss: 0.007574, Time: 0:45:59
Epoch id: 8, Training steps: 1000, Train Acc: 25.00%, Train Loss: 0.019172, Train Avg Loss: 0.008273, Time: 0:46:31
Epoch id: 8, Training steps: 1100, Train Acc: 75.00%, Train Loss: 0.005294, Train Avg Loss: 0.007449, Time: 0:47:02
Epoch id: 9, Training steps: 100, Train Acc: 100.00%, Train Loss: 0.002317, Train Avg Loss: 0.007146, Time: 0:47:45
Epoch id: 9, Training steps: 200, Train Acc: 100.00%, Train Loss: 0.001281, Train Avg Loss: 0.005260, Time: 0:48:17
Epoch id: 9, Training steps: 300, Train Acc: 50.00%, Train Loss: 0.012148, Train Avg Loss: 0.004713, Time: 0:48:48
Epoch id: 9, Training steps: 400, Train Acc: 87.50%, Train Loss: 0.002798, Train Avg Loss: 0.005288, Time: 0:49:19
Epoch id: 9, Training steps: 500, Train Acc: 87.50%, Train Loss: 0.003075, Train Avg Loss: 0.004971, Time: 0:49:50
Epoch id: 9, Training steps: 600, Train Acc: 75.00%, Train Loss: 0.004607, Train Avg Loss: 0.005843, Time: 0:50:22
Epoch id: 9, Training steps: 700, Train Acc: 75.00%, Train Loss: 0.004052, Train Avg Loss: 0.005810, Time: 0:50:53
Epoch id: 9, Training steps: 800, Train Acc: 62.50%, Train Loss: 0.009986, Train Avg Loss: 0.005627, Time: 0:51:24
Epoch id: 9, Training steps: 900, Train Acc: 62.50%, Train Loss: 0.013380, Train Avg Loss: 0.005919, Time: 0:51:56
Epoch id: 9, Training steps: 1000, Train Acc: 75.00%, Train Loss: 0.005908, Train Avg Loss: 0.006079, Time: 0:52:27
Epoch id: 9, Training steps: 1100, Train Acc: 75.00%, Train Loss: 0.004774, Train Avg Loss: 0.005753, Time: 0:52:59
Epoch id: 10, Training steps: 100, Train Acc: 87.50%, Train Loss: 0.002342, Train Avg Loss: 0.006249, Time: 0:53:42
Epoch id: 10, Training steps: 200, Train Acc: 100.00%, Train Loss: 0.001847, Train Avg Loss: 0.004618, Time: 0:54:13
Epoch id: 10, Training steps: 300, Train Acc: 75.00%, Train Loss: 0.010685, Train Avg Loss: 0.003919, Time: 0:54:44
Epoch id: 10, Training steps: 400, Train Acc: 62.50%, Train Loss: 0.011913, Train Avg Loss: 0.004643, Time: 0:55:16
Epoch id: 10, Training steps: 500, Train Acc: 87.50%, Train Loss: 0.001801, Train Avg Loss: 0.004611, Time: 0:55:47
Epoch id: 10, Training steps: 600, Train Acc: 87.50%, Train Loss: 0.003095, Train Avg Loss: 0.004514, Time: 0:56:19
Epoch id: 10, Training steps: 700, Train Acc: 75.00%, Train Loss: 0.007287, Train Avg Loss: 0.005098, Time: 0:56:50
Epoch id: 10, Training steps: 800, Train Acc: 62.50%, Train Loss: 0.005379, Train Avg Loss: 0.005562, Time: 0:57:21
Epoch id: 10, Training steps: 900, Train Acc: 87.50%, Train Loss: 0.003064, Train Avg Loss: 0.004433, Time: 0:57:53
Epoch id: 10, Training steps: 1000, Train Acc: 75.00%, Train Loss: 0.005255, Train Avg Loss: 0.005634, Time: 0:58:24
Epoch id: 10, Training steps: 1100, Train Acc: 75.00%, Train Loss: 0.003656, Train Avg Loss: 0.004788, Time: 0:58:56
Epoch id: 11, Training steps: 100, Train Acc: 87.50%, Train Loss: 0.005830, Train Avg Loss: 0.005202, Time: 0:59:39
Epoch id: 11, Training steps: 200, Train Acc: 100.00%, Train Loss: 0.001145, Train Avg Loss: 0.003572, Time: 1:00:10
Epoch id: 11, Training steps: 300, Train Acc: 100.00%, Train Loss: 0.000882, Train Avg Loss: 0.003059, Time: 1:00:41
Epoch id: 11, Training steps: 400, Train Acc: 62.50%, Train Loss: 0.004565, Train Avg Loss: 0.003654, Time: 1:01:13
Epoch id: 11, Training steps: 500, Train Acc: 75.00%, Train Loss: 0.003735, Train Avg Loss: 0.003477, Time: 1:01:44
Epoch id: 11, Training steps: 600, Train Acc: 100.00%, Train Loss: 0.002079, Train Avg Loss: 0.003410, Time: 1:02:15
Epoch id: 11, Training steps: 700, Train Acc: 100.00%, Train Loss: 0.001630, Train Avg Loss: 0.003464, Time: 1:02:47
Epoch id: 11, Training steps: 800, Train Acc: 75.00%, Train Loss: 0.011152, Train Avg Loss: 0.004319, Time: 1:03:18
Epoch id: 11, Training steps: 900, Train Acc: 75.00%, Train Loss: 0.004086, Train Avg Loss: 0.003622, Time: 1:03:49
Epoch id: 11, Training steps: 1000, Train Acc: 87.50%, Train Loss: 0.003972, Train Avg Loss: 0.004116, Time: 1:04:20
Epoch id: 11, Training steps: 1100, Train Acc: 75.00%, Train Loss: 0.003631, Train Avg Loss: 0.003712, Time: 1:04:52
Epoch id: 12, Training steps: 100, Train Acc: 87.50%, Train Loss: 0.003273, Train Avg Loss: 0.003746, Time: 1:05:35
Epoch id: 12, Training steps: 200, Train Acc: 75.00%, Train Loss: 0.002366, Train Avg Loss: 0.002649, Time: 1:06:06
Epoch id: 12, Training steps: 300, Train Acc: 75.00%, Train Loss: 0.002541, Train Avg Loss: 0.002837, Time: 1:06:38
Epoch id: 12, Training steps: 400, Train Acc: 100.00%, Train Loss: 0.000824, Train Avg Loss: 0.002568, Time: 1:07:09
Epoch id: 12, Training steps: 500, Train Acc: 100.00%, Train Loss: 0.000691, Train Avg Loss: 0.002360, Time: 1:07:40
Epoch id: 12, Training steps: 600, Train Acc: 87.50%, Train Loss: 0.001821, Train Avg Loss: 0.002904, Time: 1:08:12
Epoch id: 12, Training steps: 700, Train Acc: 87.50%, Train Loss: 0.002042, Train Avg Loss: 0.003281, Time: 1:08:43
Epoch id: 12, Training steps: 800, Train Acc: 100.00%, Train Loss: 0.001844, Train Avg Loss: 0.003126, Time: 1:09:15
Epoch id: 12, Training steps: 900, Train Acc: 87.50%, Train Loss: 0.004519, Train Avg Loss: 0.002895, Time: 1:09:46
Epoch id: 12, Training steps: 1000, Train Acc: 100.00%, Train Loss: 0.000668, Train Avg Loss: 0.002501, Time: 1:10:17
Epoch id: 12, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.002784, Train Avg Loss: 0.002958, Time: 1:10:49
Epoch id: 13, Training steps: 100, Train Acc: 87.50%, Train Loss: 0.002335, Train Avg Loss: 0.003627, Time: 1:11:32
Epoch id: 13, Training steps: 200, Train Acc: 87.50%, Train Loss: 0.001242, Train Avg Loss: 0.002185, Time: 1:12:03
Epoch id: 13, Training steps: 300, Train Acc: 75.00%, Train Loss: 0.003442, Train Avg Loss: 0.002732, Time: 1:12:34
Epoch id: 13, Training steps: 400, Train Acc: 75.00%, Train Loss: 0.002337, Train Avg Loss: 0.002573, Time: 1:13:06
Epoch id: 13, Training steps: 500, Train Acc: 75.00%, Train Loss: 0.005545, Train Avg Loss: 0.002325, Time: 1:13:37
Epoch id: 13, Training steps: 600, Train Acc: 100.00%, Train Loss: 0.000228, Train Avg Loss: 0.002140, Time: 1:14:09
Epoch id: 13, Training steps: 700, Train Acc: 100.00%, Train Loss: 0.000409, Train Avg Loss: 0.002190, Time: 1:14:40
Epoch id: 13, Training steps: 800, Train Acc: 100.00%, Train Loss: 0.000513, Train Avg Loss: 0.002302, Time: 1:15:11
Epoch id: 13, Training steps: 900, Train Acc: 100.00%, Train Loss: 0.000379, Train Avg Loss: 0.002011, Time: 1:15:43
Epoch id: 13, Training steps: 1000, Train Acc: 62.50%, Train Loss: 0.005258, Train Avg Loss: 0.002822, Time: 1:16:14
Epoch id: 13, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.001292, Train Avg Loss: 0.002927, Time: 1:16:45
Epoch id: 14, Training steps: 100, Train Acc: 87.50%, Train Loss: 0.002745, Train Avg Loss: 0.003329, Time: 1:17:28
Epoch id: 14, Training steps: 200, Train Acc: 100.00%, Train Loss: 0.000485, Train Avg Loss: 0.001933, Time: 1:18:00
Epoch id: 14, Training steps: 300, Train Acc: 87.50%, Train Loss: 0.001010, Train Avg Loss: 0.002343, Time: 1:18:31
Epoch id: 14, Training steps: 400, Train Acc: 100.00%, Train Loss: 0.000354, Train Avg Loss: 0.002103, Time: 1:19:02
Epoch id: 14, Training steps: 500, Train Acc: 100.00%, Train Loss: 0.000773, Train Avg Loss: 0.001946, Time: 1:19:34
Epoch id: 14, Training steps: 600, Train Acc: 100.00%, Train Loss: 0.000484, Train Avg Loss: 0.001711, Time: 1:20:05
Epoch id: 14, Training steps: 700, Train Acc: 87.50%, Train Loss: 0.008584, Train Avg Loss: 0.001755, Time: 1:20:37
Epoch id: 14, Training steps: 800, Train Acc: 100.00%, Train Loss: 0.001253, Train Avg Loss: 0.002191, Time: 1:21:08
Epoch id: 14, Training steps: 900, Train Acc: 87.50%, Train Loss: 0.001209, Train Avg Loss: 0.002020, Time: 1:21:39
Epoch id: 14, Training steps: 1000, Train Acc: 100.00%, Train Loss: 0.000365, Train Avg Loss: 0.002133, Time: 1:22:11
Epoch id: 14, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.001078, Train Avg Loss: 0.002410, Time: 1:22:42
Epoch id: 15, Training steps: 100, Train Acc: 100.00%, Train Loss: 0.000472, Train Avg Loss: 0.003017, Time: 1:23:25
Epoch id: 15, Training steps: 200, Train Acc: 87.50%, Train Loss: 0.001978, Train Avg Loss: 0.001937, Time: 1:23:56
Epoch id: 15, Training steps: 300, Train Acc: 75.00%, Train Loss: 0.006583, Train Avg Loss: 0.001603, Time: 1:24:28
Epoch id: 15, Training steps: 400, Train Acc: 75.00%, Train Loss: 0.003826, Train Avg Loss: 0.001747, Time: 1:24:59
Epoch id: 15, Training steps: 500, Train Acc: 87.50%, Train Loss: 0.001241, Train Avg Loss: 0.001967, Time: 1:25:30
Epoch id: 15, Training steps: 600, Train Acc: 100.00%, Train Loss: 0.000517, Train Avg Loss: 0.003700, Time: 1:26:02
Epoch id: 15, Training steps: 700, Train Acc: 87.50%, Train Loss: 0.002083, Train Avg Loss: 0.002878, Time: 1:26:33
Epoch id: 15, Training steps: 800, Train Acc: 87.50%, Train Loss: 0.005477, Train Avg Loss: 0.002672, Time: 1:27:04
Epoch id: 15, Training steps: 900, Train Acc: 87.50%, Train Loss: 0.003958, Train Avg Loss: 0.002627, Time: 1:27:36
Epoch id: 15, Training steps: 1000, Train Acc: 100.00%, Train Loss: 0.001341, Train Avg Loss: 0.002020, Time: 1:28:07
Epoch id: 15, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.000969, Train Avg Loss: 0.002221, Time: 1:28:39
Epoch id: 16, Training steps: 100, Train Acc: 87.50%, Train Loss: 0.001291, Train Avg Loss: 0.002223, Time: 1:29:22
Epoch id: 16, Training steps: 200, Train Acc: 100.00%, Train Loss: 0.000526, Train Avg Loss: 0.001218, Time: 1:29:53
Epoch id: 16, Training steps: 300, Train Acc: 100.00%, Train Loss: 0.000963, Train Avg Loss: 0.001423, Time: 1:30:24
Epoch id: 16, Training steps: 400, Train Acc: 100.00%, Train Loss: 0.000350, Train Avg Loss: 0.001423, Time: 1:30:56
Epoch id: 16, Training steps: 500, Train Acc: 87.50%, Train Loss: 0.001296, Train Avg Loss: 0.001983, Time: 1:31:27
Epoch id: 16, Training steps: 600, Train Acc: 75.00%, Train Loss: 0.005663, Train Avg Loss: 0.001624, Time: 1:31:58
Epoch id: 16, Training steps: 700, Train Acc: 87.50%, Train Loss: 0.001980, Train Avg Loss: 0.002000, Time: 1:32:30
Epoch id: 16, Training steps: 800, Train Acc: 100.00%, Train Loss: 0.001647, Train Avg Loss: 0.002247, Time: 1:33:01
Epoch id: 16, Training steps: 900, Train Acc: 75.00%, Train Loss: 0.005024, Train Avg Loss: 0.001615, Time: 1:33:33
Epoch id: 16, Training steps: 1000, Train Acc: 100.00%, Train Loss: 0.000934, Train Avg Loss: 0.001630, Time: 1:34:04
Epoch id: 16, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.001126, Train Avg Loss: 0.001892, Time: 1:34:35
Epoch id: 17, Training steps: 100, Train Acc: 100.00%, Train Loss: 0.000677, Train Avg Loss: 0.001754, Time: 1:35:18
Epoch id: 17, Training steps: 200, Train Acc: 87.50%, Train Loss: 0.001380, Train Avg Loss: 0.001156, Time: 1:35:50
Epoch id: 17, Training steps: 300, Train Acc: 100.00%, Train Loss: 0.001501, Train Avg Loss: 0.001004, Time: 1:36:21
Epoch id: 17, Training steps: 400, Train Acc: 87.50%, Train Loss: 0.003965, Train Avg Loss: 0.000976, Time: 1:36:53
Epoch id: 17, Training steps: 500, Train Acc: 100.00%, Train Loss: 0.001361, Train Avg Loss: 0.001120, Time: 1:37:24
Epoch id: 17, Training steps: 600, Train Acc: 87.50%, Train Loss: 0.000579, Train Avg Loss: 0.001143, Time: 1:37:55
Epoch id: 17, Training steps: 700, Train Acc: 100.00%, Train Loss: 0.000864, Train Avg Loss: 0.001741, Time: 1:38:27
Epoch id: 17, Training steps: 800, Train Acc: 100.00%, Train Loss: 0.001525, Train Avg Loss: 0.001737, Time: 1:38:58
Epoch id: 17, Training steps: 900, Train Acc: 100.00%, Train Loss: 0.000640, Train Avg Loss: 0.001425, Time: 1:39:30
Epoch id: 17, Training steps: 1000, Train Acc: 87.50%, Train Loss: 0.001951, Train Avg Loss: 0.001662, Time: 1:40:01
Epoch id: 17, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.000460, Train Avg Loss: 0.001431, Time: 1:40:32
Epoch id: 18, Training steps: 100, Train Acc: 87.50%, Train Loss: 0.002046, Train Avg Loss: 0.002980, Time: 1:41:15
Epoch id: 18, Training steps: 200, Train Acc: 100.00%, Train Loss: 0.000489, Train Avg Loss: 0.001190, Time: 1:41:47
Epoch id: 18, Training steps: 300, Train Acc: 87.50%, Train Loss: 0.000779, Train Avg Loss: 0.001279, Time: 1:42:18
Epoch id: 18, Training steps: 400, Train Acc: 100.00%, Train Loss: 0.000521, Train Avg Loss: 0.001260, Time: 1:42:50
Epoch id: 18, Training steps: 500, Train Acc: 100.00%, Train Loss: 0.002098, Train Avg Loss: 0.001544, Time: 1:43:21
Epoch id: 18, Training steps: 600, Train Acc: 100.00%, Train Loss: 0.000430, Train Avg Loss: 0.001295, Time: 1:43:52
Epoch id: 18, Training steps: 700, Train Acc: 100.00%, Train Loss: 0.000525, Train Avg Loss: 0.001433, Time: 1:44:24
Epoch id: 18, Training steps: 800, Train Acc: 87.50%, Train Loss: 0.001277, Train Avg Loss: 0.001929, Time: 1:44:55
Epoch id: 18, Training steps: 900, Train Acc: 75.00%, Train Loss: 0.003275, Train Avg Loss: 0.001759, Time: 1:45:27
Epoch id: 18, Training steps: 1000, Train Acc: 100.00%, Train Loss: 0.000110, Train Avg Loss: 0.001794, Time: 1:45:58
Epoch id: 18, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.001003, Train Avg Loss: 0.001207, Time: 1:46:29
Epoch id: 19, Training steps: 100, Train Acc: 75.00%, Train Loss: 0.002114, Train Avg Loss: 0.001387, Time: 1:47:13
Epoch id: 19, Training steps: 200, Train Acc: 87.50%, Train Loss: 0.001517, Train Avg Loss: 0.001052, Time: 1:47:44
Epoch id: 19, Training steps: 300, Train Acc: 100.00%, Train Loss: 0.000536, Train Avg Loss: 0.000860, Time: 1:48:15
Epoch id: 19, Training steps: 400, Train Acc: 87.50%, Train Loss: 0.001018, Train Avg Loss: 0.000929, Time: 1:48:47
Epoch id: 19, Training steps: 500, Train Acc: 100.00%, Train Loss: 0.001382, Train Avg Loss: 0.001122, Time: 1:49:18
Epoch id: 19, Training steps: 600, Train Acc: 100.00%, Train Loss: 0.000600, Train Avg Loss: 0.001207, Time: 1:49:50
Epoch id: 19, Training steps: 700, Train Acc: 100.00%, Train Loss: 0.000434, Train Avg Loss: 0.001014, Time: 1:50:21
Epoch id: 19, Training steps: 800, Train Acc: 100.00%, Train Loss: 0.000713, Train Avg Loss: 0.001435, Time: 1:50:52
Epoch id: 19, Training steps: 900, Train Acc: 100.00%, Train Loss: 0.000732, Train Avg Loss: 0.001542, Time: 1:51:24
Epoch id: 19, Training steps: 1000, Train Acc: 75.00%, Train Loss: 0.001458, Train Avg Loss: 0.002088, Time: 1:51:55
Epoch id: 19, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.000369, Train Avg Loss: 0.001898, Time: 1:52:27
Epoch id: 20, Training steps: 100, Train Acc: 100.00%, Train Loss: 0.001408, Train Avg Loss: 0.001971, Time: 1:53:10
Epoch id: 20, Training steps: 200, Train Acc: 100.00%, Train Loss: 0.000110, Train Avg Loss: 0.001090, Time: 1:53:41
Epoch id: 20, Training steps: 300, Train Acc: 100.00%, Train Loss: 0.000261, Train Avg Loss: 0.001128, Time: 1:54:13
Epoch id: 20, Training steps: 400, Train Acc: 100.00%, Train Loss: 0.000552, Train Avg Loss: 0.001237, Time: 1:54:44
Epoch id: 20, Training steps: 500, Train Acc: 100.00%, Train Loss: 0.000914, Train Avg Loss: 0.001262, Time: 1:55:15
Epoch id: 20, Training steps: 600, Train Acc: 100.00%, Train Loss: 0.000328, Train Avg Loss: 0.001066, Time: 1:55:47
Epoch id: 20, Training steps: 700, Train Acc: 75.00%, Train Loss: 0.004071, Train Avg Loss: 0.000987, Time: 1:56:18
Epoch id: 20, Training steps: 800, Train Acc: 100.00%, Train Loss: 0.000799, Train Avg Loss: 0.001554, Time: 1:56:50
Epoch id: 20, Training steps: 900, Train Acc: 100.00%, Train Loss: 0.000470, Train Avg Loss: 0.001305, Time: 1:57:21
Epoch id: 20, Training steps: 1000, Train Acc: 100.00%, Train Loss: 0.000632, Train Avg Loss: 0.001313, Time: 1:57:53
Epoch id: 20, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.000856, Train Avg Loss: 0.001305, Time: 1:58:24
Final evaluation on the test dataset.
The number of evaluation instances:  2067
Acc. (Correct/Total): 62.07% micro-Prec: 0.8095 micro-Recall:0.7611 micro-F1: 0.7845 dev loss: 0.033066
              precision    recall  f1-score   support

         教育学     0.8292    0.9668    0.8927       241
          法学     0.8584    0.8661    0.8622       224
      中国语言文学     0.9096    0.8162    0.8604       185
         政治学     0.8480    0.6503    0.7361       163
         社会学     0.8630    0.8025    0.8317       157
         心理学     0.8636    0.6179    0.7204       123
       应用经济学     0.7683    0.5385    0.6332       117
         历史学     0.8701    0.6147    0.7204       109
     环境科学与工程     0.9208    0.8611    0.8900       108
          哲学     0.8382    0.5876    0.6909        97
      外国语言文学     0.8046    0.8235    0.8140        85
         生物学     0.7528    0.8481    0.7976        79
      交通运输工程     0.8941    0.9744    0.9325        78
        临床医学     0.8772    0.6579    0.7519        76
    计算机科学与技术     0.8082    0.8310    0.8194        71
        土木工程     0.8649    0.9697    0.9143        66
   航空宇航科学与技术     0.9492    0.9180    0.9333        61
         民族学     0.6212    0.7455    0.6777        55
   公共卫生与预防医学     0.6066    0.7255    0.6607        51
         美术学     0.8305    0.9800    0.8991        50
         艺术学     0.8085    0.8837    0.8444        43
         地理学     0.7442    0.7619    0.7529        42
         体育学     0.9231    0.6000    0.7273        40
       理论经济学     0.8667    0.6842    0.7647        38
         中医学     0.8378    0.8378    0.8378        37
         物理学     0.7857    0.9167    0.8462        36
          林学     0.7667    0.6970    0.7302        33
          数学     0.7273    0.5000    0.5926        32
     电子科学与技术     0.5667    0.5484    0.5574        31
        基础医学     0.7333    0.3793    0.5000        29
        工商管理     0.8261    0.7037    0.7600        27
       新闻传播学     0.8000    0.7273    0.7619        22
         天文学     0.8182    0.8182    0.8182        22
         地质学     0.9286    0.6190    0.7429        21
         畜牧学     0.7917    0.9048    0.8444        21
   军事思想及军事历史     0.6667    0.8000    0.7273        20
     管理科学与工程     0.6087    0.7778    0.6829        18
     测绘科学与技术     0.7500    0.7059    0.7273        17
        水利工程     0.9167    0.6875    0.7857        16
        大气科学     0.6190    0.8125    0.7027        16
     兵器科学与技术     0.7059    0.8000    0.7500        15
       地球物理学     0.6667    0.1429    0.2353        14
        电气工程     1.0000    0.6154    0.7619        13
         作物学     0.7000    0.5385    0.6087        13
     控制科学与工程     0.2778    0.3846    0.3226        13
     信息与通信工程     0.4000    0.3077    0.3478        13
        公共管理     0.3846    0.3846    0.3846        13
         建筑学     0.8750    0.5385    0.6667        13
     化学工程与技术     0.9000    0.7500    0.8182        12
          力学     0.9000    0.8182    0.8571        11
        海洋科学     0.9167    1.0000    0.9565        11
     轻工技术与工程     0.4000    0.5455    0.4615        11
        农业工程     0.8750    0.7000    0.7778        10
         园艺学     0.9000    0.9000    0.9000        10
       中西医结合     1.0000    0.3000    0.4615        10
        机械工程     0.8889    0.8889    0.8889         9
       科学技术史     0.7500    0.7500    0.7500         8
     船舶与海洋工程     0.8571    0.7500    0.8000         8
   图书情报与档案管理     0.6667    0.7500    0.7059         8
        植物保护     0.7000    0.8750    0.7778         8
     材料科学与工程     1.0000    0.7500    0.8571         8
         统计学     0.5455    0.7500    0.6316         8
          化学     0.7000    0.8750    0.7778         8
     食品科学与工程     0.6667    0.7500    0.7059         8
          水产     1.0000    0.8571    0.9231         7
          药学     0.8571    0.8571    0.8571         7
     农业资源与环境     0.5000    0.4286    0.4615         7
         世界史     0.6364    1.0000    0.7778         7
        系统科学     0.7143    0.7143    0.7143         7
      农林经济管理     0.5000    1.0000    0.6667         5
       军队指挥学     1.0000    0.4000    0.5714         5
        矿业工程     0.7500    0.6000    0.6667         5
     纺织科学与工程     0.7143    1.0000    0.8333         5
  动力工程及工程热物理     0.0000    0.0000    0.0000         4
        林业工程     0.5000    0.7500    0.6000         4
     仪器科学与技术     0.0000    0.0000    0.0000         3
         战略学     0.3333    0.6667    0.4444         3
   地质资源与地质工程     0.6000    1.0000    0.7500         3
        旅游管理     1.0000    1.0000    1.0000         3
 图书馆、情报与档案管理     1.0000    0.5000    0.6667         2
        冶金工程     1.0000    0.5000    0.6667         2
      核科学与技术     0.0000    0.0000    0.0000         2

   micro avg     0.8095    0.7611    0.7845      3093
   macro avg     0.7420    0.6988    0.7018      3093
weighted avg     0.8164    0.7611    0.7786      3093
 samples avg     0.8014    0.7784    0.7755      3093


nohup: ignoring input
/root/miniconda3/envs/lyq/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
  0%|          | 0/82 [00:00<?, ?it/s]100%|██████████| 82/82 [00:00<00:00, 1181900.10it/s]
model:  ernie-rcnn-catlstmwide
pretrained:  ernie1
task:  MLC-slice
dataset:  book_multilabels_task_slice
seq_length:  256
hidden_dropout_prob:  0.1
attention_probs_dropout_prob:  0.1
epochs_num:  20
batch_size:  8
learning_rate:  2e-05
report_steps:  100
kg_name:  CnDbpedia
no_kg:  True
no_vm:  True
GPU:  NVIDIA GeForce RTX 3090
Vocabulary Size:  17964
[BertClassifier] use visible_matrix: False
Some weights of ErnieRCNNForMultiLabelSequenceClassificationSliceCatLSTMWide were not initialized from the model checkpoint at ./models/ernie1 and are newly initialized: ['output_layer_1.bias', 'classifier.weight', 'lstm.weight_ih_l0', 'classifier.bias', 'lstm.weight_hh_l0_reverse', 'lstm.bias_hh_l1', 'lstm.weight_ih_l1_reverse', 'lstm.weight_hh_l1', 'lstm.bias_ih_l1', 'lstm.bias_ih_l0', 'lstm.weight_hh_l1_reverse', 'lstm.bias_hh_l1_reverse', 'lstm.bias_ih_l1_reverse', 'lstm.bias_ih_l0_reverse', 'lstm.weight_hh_l0', 'output_layer_1.weight', 'lstm.bias_hh_l0_reverse', 'lstm.weight_ih_l0_reverse', 'lstm.weight_ih_l1', 'lstm.bias_hh_l0']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
1 GPUs are available. Let's use them.
device:  cuda
Start training.
Loading sentences from ./datasets/book_multilabels_task_slice/train.tsv
There are 9097 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/9097
Loading sentences from ./datasets/book_multilabels_task_slice/dev.tsv
There are 2084 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/2084
Loading sentences from ./datasets/book_multilabels_task_slice/test.tsv
There are 2067 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/2067
Epoch id: 1, Training steps: 100,  Train Loss: 0.077,  Train Acc:  0.00%,  Train Avg Loss: 0.173891,  Time: 0:00:31
Epoch id: 1, Training steps: 200,  Train Loss: 0.081,  Train Acc:  0.00%,  Train Avg Loss: 0.085244,  Time: 0:01:02
Epoch id: 1, Training steps: 300,  Train Loss: 0.077,  Train Acc:  0.00%,  Train Avg Loss: 0.083539,  Time: 0:01:32
Epoch id: 1, Training steps: 400,  Train Loss: 0.069,  Train Acc:  0.00%,  Train Avg Loss: 0.084321,  Time: 0:02:03
Epoch id: 1, Training steps: 500,  Train Loss: 0.092,  Train Acc:  0.00%,  Train Avg Loss: 0.082764,  Time: 0:02:34
Epoch id: 1, Training steps: 600,  Train Loss: 0.084,  Train Acc:  0.00%,  Train Avg Loss: 0.084300,  Time: 0:03:05
Epoch id: 1, Training steps: 700,  Train Loss: 0.099,  Train Acc:  0.00%,  Train Avg Loss: 0.084300,  Time: 0:03:36
Epoch id: 1, Training steps: 800,  Train Loss: 0.084,  Train Acc:  0.00%,  Train Avg Loss: 0.082865,  Time: 0:04:07
Epoch id: 1, Training steps: 900,  Train Loss: 0.085,  Train Acc:  0.00%,  Train Avg Loss: 0.080945,  Time: 0:04:38
Epoch id: 1, Training steps: 1000,  Train Loss: 0.098,  Train Acc:  0.00%,  Train Avg Loss: 0.080810,  Time: 0:05:09
Epoch id: 1, Training steps: 1100,  Train Loss: 0.076,  Train Acc:  0.00%,  Train Avg Loss: 0.080668,  Time: 0:05:40
Start evaluation on dev dataset.
Acc. (Correct/Total):  0.00% micro-Prec: 0.0000 micro-Recall:0.0000 micro-F1: 0.0000 dev loss: 0.100790
Start evaluation on test dataset.
Acc. (Correct/Total):  0.00% micro-Prec: 0.0000 micro-Recall:0.0000 micro-F1: 0.0000 dev loss: 0.101351
Epoch id: 2, Training steps: 100,  Train Loss: 0.086,  Train Acc:  0.00%,  Train Avg Loss: 0.106045,  Time: 0:07:19
Epoch id: 2, Training steps: 200,  Train Loss: 0.072,  Train Acc:  0.00%,  Train Avg Loss: 0.076554,  Time: 0:07:50
Epoch id: 2, Training steps: 300,  Train Loss:  0.06,  Train Acc:  0.00%,  Train Avg Loss: 0.074664,  Time: 0:08:21
Epoch id: 2, Training steps: 400,  Train Loss: 0.065,  Train Acc:  0.00%,  Train Avg Loss: 0.069725,  Time: 0:08:52
Epoch id: 2, Training steps: 500,  Train Loss: 0.048,  Train Acc:  0.00%,  Train Avg Loss: 0.068131,  Time: 0:09:23
Epoch id: 2, Training steps: 600,  Train Loss: 0.059,  Train Acc:  0.00%,  Train Avg Loss: 0.064963,  Time: 0:09:54
Epoch id: 2, Training steps: 700,  Train Loss:  0.06,  Train Acc:  0.00%,  Train Avg Loss: 0.062290,  Time: 0:10:25
Epoch id: 2, Training steps: 800,  Train Loss: 0.067,  Train Acc: 12.50%,  Train Avg Loss: 0.058702,  Time: 0:10:56
Epoch id: 2, Training steps: 900,  Train Loss:  0.06,  Train Acc:  0.00%,  Train Avg Loss: 0.065911,  Time: 0:11:27
Epoch id: 2, Training steps: 1000,  Train Loss: 0.061,  Train Acc: 12.50%,  Train Avg Loss: 0.062532,  Time: 0:11:58
Epoch id: 2, Training steps: 1100,  Train Loss: 0.082,  Train Acc:  0.00%,  Train Avg Loss: 0.058178,  Time: 0:12:29
Start evaluation on dev dataset.
Acc. (Correct/Total):  0.00% micro-Prec: 0.0000 micro-Recall:0.0000 micro-F1: 0.0000 dev loss: 0.109870
Start evaluation on test dataset.
Acc. (Correct/Total):  0.00% micro-Prec: 0.0000 micro-Recall:0.0000 micro-F1: 0.0000 dev loss: 0.110326
Epoch id: 3, Training steps: 100,  Train Loss: 0.036,  Train Acc: 12.50%,  Train Avg Loss: 0.071370,  Time: 0:14:08
Epoch id: 3, Training steps: 200,  Train Loss: 0.042,  Train Acc: 12.50%,  Train Avg Loss: 0.049179,  Time: 0:14:39
Epoch id: 3, Training steps: 300,  Train Loss: 0.032,  Train Acc: 37.50%,  Train Avg Loss: 0.048330,  Time: 0:15:10
Epoch id: 3, Training steps: 400,  Train Loss: 0.068,  Train Acc:  0.00%,  Train Avg Loss: 0.045735,  Time: 0:15:41
Epoch id: 3, Training steps: 500,  Train Loss: 0.036,  Train Acc: 25.00%,  Train Avg Loss: 0.044025,  Time: 0:16:12
Epoch id: 3, Training steps: 600,  Train Loss: 0.023,  Train Acc: 50.00%,  Train Avg Loss: 0.043184,  Time: 0:16:43
Epoch id: 3, Training steps: 700,  Train Loss:  0.04,  Train Acc: 37.50%,  Train Avg Loss: 0.041786,  Time: 0:17:14
Epoch id: 3, Training steps: 800,  Train Loss: 0.055,  Train Acc: 12.50%,  Train Avg Loss: 0.042077,  Time: 0:17:45
Epoch id: 3, Training steps: 900,  Train Loss: 0.013,  Train Acc: 50.00%,  Train Avg Loss: 0.037707,  Time: 0:18:16
Epoch id: 3, Training steps: 1000,  Train Loss: 0.023,  Train Acc: 37.50%,  Train Avg Loss: 0.038310,  Time: 0:18:47
Epoch id: 3, Training steps: 1100,  Train Loss: 0.027,  Train Acc: 25.00%,  Train Avg Loss: 0.040422,  Time: 0:19:18
Start evaluation on dev dataset.
Acc. (Correct/Total):  6.48% micro-Prec: 0.7754 micro-Recall:0.0838 micro-F1: 0.1513 dev loss: 0.117524
Start evaluation on test dataset.
Acc. (Correct/Total): 11.47% micro-Prec: 0.8909 micro-Recall:0.1426 micro-F1: 0.2458 dev loss: 0.112207
Epoch id: 4, Training steps: 100,  Train Loss: 0.029,  Train Acc: 12.50%,  Train Avg Loss: 0.051157,  Time: 0:20:57
Epoch id: 4, Training steps: 200,  Train Loss: 0.022,  Train Acc: 37.50%,  Train Avg Loss: 0.034383,  Time: 0:21:28
Epoch id: 4, Training steps: 300,  Train Loss: 0.045,  Train Acc: 25.00%,  Train Avg Loss: 0.034692,  Time: 0:21:59
Epoch id: 4, Training steps: 400,  Train Loss: 0.032,  Train Acc: 37.50%,  Train Avg Loss: 0.033475,  Time: 0:22:30
Epoch id: 4, Training steps: 500,  Train Loss: 0.033,  Train Acc: 37.50%,  Train Avg Loss: 0.033746,  Time: 0:23:01
Epoch id: 4, Training steps: 600,  Train Loss: 0.055,  Train Acc:  0.00%,  Train Avg Loss: 0.032509,  Time: 0:23:32
Epoch id: 4, Training steps: 700,  Train Loss:  0.03,  Train Acc: 50.00%,  Train Avg Loss: 0.033715,  Time: 0:24:03
Epoch id: 4, Training steps: 800,  Train Loss: 0.034,  Train Acc: 37.50%,  Train Avg Loss: 0.033760,  Time: 0:24:34
Epoch id: 4, Training steps: 900,  Train Loss: 0.013,  Train Acc: 37.50%,  Train Avg Loss: 0.034840,  Time: 0:25:05
Epoch id: 4, Training steps: 1000,  Train Loss: 0.023,  Train Acc: 37.50%,  Train Avg Loss: 0.032316,  Time: 0:25:36
Epoch id: 4, Training steps: 1100,  Train Loss: 0.041,  Train Acc: 25.00%,  Train Avg Loss: 0.031758,  Time: 0:26:07
Start evaluation on dev dataset.
Acc. (Correct/Total):  4.08% micro-Prec: 0.8407 micro-Recall:0.0615 micro-F1: 0.1146 dev loss: 0.123141
Start evaluation on test dataset.
Acc. (Correct/Total):  8.76% micro-Prec: 0.9089 micro-Recall:0.1161 micro-F1: 0.2058 dev loss: 0.116163
Epoch id: 5, Training steps: 100,  Train Loss: 0.017,  Train Acc: 62.50%,  Train Avg Loss: 0.039779,  Time: 0:27:46
Epoch id: 5, Training steps: 200,  Train Loss: 0.011,  Train Acc: 62.50%,  Train Avg Loss: 0.028896,  Time: 0:28:17
Epoch id: 5, Training steps: 300,  Train Loss: 0.045,  Train Acc: 25.00%,  Train Avg Loss: 0.027643,  Time: 0:28:48
Epoch id: 5, Training steps: 400,  Train Loss: 0.024,  Train Acc: 25.00%,  Train Avg Loss: 0.026950,  Time: 0:29:18
Epoch id: 5, Training steps: 500,  Train Loss: 0.032,  Train Acc: 37.50%,  Train Avg Loss: 0.028344,  Time: 0:29:49
Epoch id: 5, Training steps: 600,  Train Loss: 0.027,  Train Acc: 25.00%,  Train Avg Loss: 0.029791,  Time: 0:30:20
Epoch id: 5, Training steps: 700,  Train Loss: 0.022,  Train Acc: 37.50%,  Train Avg Loss: 0.027801,  Time: 0:30:51
Epoch id: 5, Training steps: 800,  Train Loss: 0.032,  Train Acc: 25.00%,  Train Avg Loss: 0.028033,  Time: 0:31:22
Epoch id: 5, Training steps: 900,  Train Loss:  0.05,  Train Acc: 12.50%,  Train Avg Loss: 0.027912,  Time: 0:31:53
Epoch id: 5, Training steps: 1000,  Train Loss: 0.029,  Train Acc: 25.00%,  Train Avg Loss: 0.026536,  Time: 0:32:24
Epoch id: 5, Training steps: 1100,  Train Loss: 0.022,  Train Acc: 25.00%,  Train Avg Loss: 0.027343,  Time: 0:32:55
Start evaluation on dev dataset.
Acc. (Correct/Total):  2.16% micro-Prec: 0.8583 micro-Recall:0.0353 micro-F1: 0.0678 dev loss: 0.138908
Start evaluation on test dataset.
Acc. (Correct/Total):  3.24% micro-Prec: 0.8929 micro-Recall:0.0566 micro-F1: 0.1064 dev loss: 0.133254
Epoch id: 6, Training steps: 100,  Train Loss: 0.027,  Train Acc: 50.00%,  Train Avg Loss: 0.035051,  Time: 0:34:35
Epoch id: 6, Training steps: 200,  Train Loss: 0.024,  Train Acc: 37.50%,  Train Avg Loss: 0.025956,  Time: 0:35:05
Epoch id: 6, Training steps: 300,  Train Loss: 0.018,  Train Acc: 50.00%,  Train Avg Loss: 0.022914,  Time: 0:35:37
Epoch id: 6, Training steps: 400,  Train Loss: 0.025,  Train Acc: 37.50%,  Train Avg Loss: 0.022302,  Time: 0:36:08
Epoch id: 6, Training steps: 500,  Train Loss:  0.02,  Train Acc: 50.00%,  Train Avg Loss: 0.022776,  Time: 0:36:38
Epoch id: 6, Training steps: 600,  Train Loss: 0.012,  Train Acc: 75.00%,  Train Avg Loss: 0.021849,  Time: 0:37:09
Epoch id: 6, Training steps: 700,  Train Loss: 0.012,  Train Acc: 50.00%,  Train Avg Loss: 0.024847,  Time: 0:37:40
Epoch id: 6, Training steps: 800,  Train Loss: 0.023,  Train Acc: 25.00%,  Train Avg Loss: 0.023682,  Time: 0:38:11
Epoch id: 6, Training steps: 900,  Train Loss: 0.014,  Train Acc: 50.00%,  Train Avg Loss: 0.022905,  Time: 0:38:42
Epoch id: 6, Training steps: 1000,  Train Loss: 0.029,  Train Acc: 37.50%,  Train Avg Loss: 0.024468,  Time: 0:39:13
Epoch id: 6, Training steps: 1100,  Train Loss: 0.035,  Train Acc: 50.00%,  Train Avg Loss: 0.022992,  Time: 0:39:44
Start evaluation on dev dataset.
Acc. (Correct/Total):  0.14% micro-Prec: 1.0000 micro-Recall:0.0042 micro-F1: 0.0084 dev loss: 0.154466
Start evaluation on test dataset.
Acc. (Correct/Total):  0.05% micro-Prec: 0.9412 micro-Recall:0.0052 micro-F1: 0.0103 dev loss: 0.154973
Epoch id: 7, Training steps: 100,  Train Loss: 0.032,  Train Acc: 37.50%,  Train Avg Loss: 0.027872,  Time: 0:41:23
Epoch id: 7, Training steps: 200,  Train Loss: 0.021,  Train Acc: 25.00%,  Train Avg Loss: 0.020157,  Time: 0:41:54
Epoch id: 7, Training steps: 300,  Train Loss: 0.032,  Train Acc: 25.00%,  Train Avg Loss: 0.020558,  Time: 0:42:25
Epoch id: 7, Training steps: 400,  Train Loss: 0.032,  Train Acc: 37.50%,  Train Avg Loss: 0.020977,  Time: 0:42:56
Epoch id: 7, Training steps: 500,  Train Loss: 0.038,  Train Acc: 25.00%,  Train Avg Loss: 0.022224,  Time: 0:43:27
Epoch id: 7, Training steps: 600,  Train Loss: 0.0041,  Train Acc: 87.50%,  Train Avg Loss: 0.020062,  Time: 0:43:58
Epoch id: 7, Training steps: 700,  Train Loss: 0.0065,  Train Acc: 75.00%,  Train Avg Loss: 0.020456,  Time: 0:44:29
Epoch id: 7, Training steps: 800,  Train Loss: 0.021,  Train Acc: 50.00%,  Train Avg Loss: 0.019200,  Time: 0:45:00
Epoch id: 7, Training steps: 900,  Train Loss: 0.011,  Train Acc: 50.00%,  Train Avg Loss: 0.018856,  Time: 0:45:31
Epoch id: 7, Training steps: 1000,  Train Loss: 0.043,  Train Acc: 37.50%,  Train Avg Loss: 0.019250,  Time: 0:46:02
Epoch id: 7, Training steps: 1100,  Train Loss:  0.01,  Train Acc: 62.50%,  Train Avg Loss: 0.020928,  Time: 0:46:33
Start evaluation on dev dataset.
Acc. (Correct/Total):  0.10% micro-Prec: 0.8000 micro-Recall:0.0013 micro-F1: 0.0026 dev loss: 0.148313
Epoch id: 8, Training steps: 100,  Train Loss: 0.014,  Train Acc: 50.00%,  Train Avg Loss: 0.024883,  Time: 0:47:43
Epoch id: 8, Training steps: 200,  Train Loss: 0.007,  Train Acc: 87.50%,  Train Avg Loss: 0.017414,  Time: 0:48:14
Epoch id: 8, Training steps: 300,  Train Loss: 0.011,  Train Acc: 75.00%,  Train Avg Loss: 0.016813,  Time: 0:48:45
Epoch id: 8, Training steps: 400,  Train Loss: 0.017,  Train Acc: 62.50%,  Train Avg Loss: 0.017408,  Time: 0:49:16
Epoch id: 8, Training steps: 500,  Train Loss: 0.027,  Train Acc: 12.50%,  Train Avg Loss: 0.017086,  Time: 0:49:47
Epoch id: 8, Training steps: 600,  Train Loss: 0.018,  Train Acc: 50.00%,  Train Avg Loss: 0.018489,  Time: 0:50:19
Epoch id: 8, Training steps: 700,  Train Loss: 0.036,  Train Acc: 50.00%,  Train Avg Loss: 0.017694,  Time: 0:50:49
Epoch id: 8, Training steps: 800,  Train Loss: 0.038,  Train Acc: 37.50%,  Train Avg Loss: 0.019088,  Time: 0:51:20
Epoch id: 8, Training steps: 900,  Train Loss: 0.025,  Train Acc: 37.50%,  Train Avg Loss: 0.018204,  Time: 0:51:51
Epoch id: 8, Training steps: 1000,  Train Loss: 0.014,  Train Acc: 37.50%,  Train Avg Loss: 0.017265,  Time: 0:52:22
Epoch id: 8, Training steps: 1100,  Train Loss: 0.0046,  Train Acc: 75.00%,  Train Avg Loss: 0.016407,  Time: 0:52:53
Start evaluation on dev dataset.
Acc. (Correct/Total):  0.48% micro-Prec: 0.7273 micro-Recall:0.0207 micro-F1: 0.0403 dev loss: 0.169318
Start evaluation on test dataset.
Acc. (Correct/Total):  3.58% micro-Prec: 0.8921 micro-Recall:0.0695 micro-F1: 0.1290 dev loss: 0.164911
Epoch id: 9, Training steps: 100,  Train Loss: 0.009,  Train Acc: 50.00%,  Train Avg Loss: 0.020287,  Time: 0:54:32
Epoch id: 9, Training steps: 200,  Train Loss: 0.0057,  Train Acc: 87.50%,  Train Avg Loss: 0.014432,  Time: 0:55:03
Epoch id: 9, Training steps: 300,  Train Loss: 0.0051,  Train Acc: 75.00%,  Train Avg Loss: 0.015377,  Time: 0:55:34
Epoch id: 9, Training steps: 400,  Train Loss: 0.006,  Train Acc: 75.00%,  Train Avg Loss: 0.014616,  Time: 0:56:05
Epoch id: 9, Training steps: 500,  Train Loss: 0.012,  Train Acc: 50.00%,  Train Avg Loss: 0.014461,  Time: 0:56:36
Epoch id: 9, Training steps: 600,  Train Loss: 0.0048,  Train Acc: 87.50%,  Train Avg Loss: 0.014952,  Time: 0:57:07
Epoch id: 9, Training steps: 700,  Train Loss: 0.011,  Train Acc: 62.50%,  Train Avg Loss: 0.015177,  Time: 0:57:38
Epoch id: 9, Training steps: 800,  Train Loss: 0.0031,  Train Acc: 87.50%,  Train Avg Loss: 0.014630,  Time: 0:58:09
Epoch id: 9, Training steps: 900,  Train Loss: 0.013,  Train Acc: 62.50%,  Train Avg Loss: 0.015755,  Time: 0:58:40
Epoch id: 9, Training steps: 1000,  Train Loss: 0.018,  Train Acc: 50.00%,  Train Avg Loss: 0.015961,  Time: 0:59:11
Epoch id: 9, Training steps: 1100,  Train Loss: 0.0076,  Train Acc: 75.00%,  Train Avg Loss: 0.015202,  Time: 0:59:42
Start evaluation on dev dataset.
Acc. (Correct/Total):  0.14% micro-Prec: 0.6667 micro-Recall:0.0065 micro-F1: 0.0128 dev loss: 0.156084
Epoch id: 10, Training steps: 100,  Train Loss: 0.019,  Train Acc: 37.50%,  Train Avg Loss: 0.020450,  Time: 1:00:52
Epoch id: 10, Training steps: 200,  Train Loss: 0.0083,  Train Acc: 50.00%,  Train Avg Loss: 0.012228,  Time: 1:01:23
Epoch id: 10, Training steps: 300,  Train Loss: 0.0039,  Train Acc: 87.50%,  Train Avg Loss: 0.012063,  Time: 1:01:54
Epoch id: 10, Training steps: 400,  Train Loss: 0.013,  Train Acc: 62.50%,  Train Avg Loss: 0.012007,  Time: 1:02:25
Epoch id: 10, Training steps: 500,  Train Loss: 0.0025,  Train Acc: 100.00%,  Train Avg Loss: 0.013219,  Time: 1:02:56
Epoch id: 10, Training steps: 600,  Train Loss: 0.017,  Train Acc: 50.00%,  Train Avg Loss: 0.013459,  Time: 1:03:27
Epoch id: 10, Training steps: 700,  Train Loss: 0.0064,  Train Acc: 87.50%,  Train Avg Loss: 0.012189,  Time: 1:03:58
Epoch id: 10, Training steps: 800,  Train Loss: 0.023,  Train Acc: 50.00%,  Train Avg Loss: 0.013260,  Time: 1:04:29
Epoch id: 10, Training steps: 900,  Train Loss: 0.015,  Train Acc: 50.00%,  Train Avg Loss: 0.013442,  Time: 1:05:00
Epoch id: 10, Training steps: 1000,  Train Loss: 0.0018,  Train Acc: 100.00%,  Train Avg Loss: 0.012279,  Time: 1:05:31
Epoch id: 10, Training steps: 1100,  Train Loss: 0.019,  Train Acc: 87.50%,  Train Avg Loss: 0.013924,  Time: 1:06:02
Start evaluation on dev dataset.
Acc. (Correct/Total):  0.48% micro-Prec: 0.7246 micro-Recall:0.0162 micro-F1: 0.0317 dev loss: 0.167109
Epoch id: 11, Training steps: 100,  Train Loss: 0.0091,  Train Acc: 62.50%,  Train Avg Loss: 0.015262,  Time: 1:07:13
Epoch id: 11, Training steps: 200,  Train Loss: 0.0033,  Train Acc: 100.00%,  Train Avg Loss: 0.009928,  Time: 1:07:44
Epoch id: 11, Training steps: 300,  Train Loss: 0.014,  Train Acc: 75.00%,  Train Avg Loss: 0.011186,  Time: 1:08:15
Epoch id: 11, Training steps: 400,  Train Loss: 0.015,  Train Acc: 37.50%,  Train Avg Loss: 0.011025,  Time: 1:08:46
Epoch id: 11, Training steps: 500,  Train Loss: 0.0023,  Train Acc: 75.00%,  Train Avg Loss: 0.011898,  Time: 1:09:17
Epoch id: 11, Training steps: 600,  Train Loss: 0.018,  Train Acc: 50.00%,  Train Avg Loss: 0.010720,  Time: 1:09:48
Epoch id: 11, Training steps: 700,  Train Loss: 0.0086,  Train Acc: 62.50%,  Train Avg Loss: 0.011277,  Time: 1:10:19
Epoch id: 11, Training steps: 800,  Train Loss: 0.016,  Train Acc: 50.00%,  Train Avg Loss: 0.011994,  Time: 1:10:50
Epoch id: 11, Training steps: 900,  Train Loss: 0.023,  Train Acc: 50.00%,  Train Avg Loss: 0.014531,  Time: 1:11:21
Epoch id: 11, Training steps: 1000,  Train Loss: 0.0055,  Train Acc: 75.00%,  Train Avg Loss: 0.013093,  Time: 1:11:51
Epoch id: 11, Training steps: 1100,  Train Loss: 0.017,  Train Acc: 50.00%,  Train Avg Loss: 0.012132,  Time: 1:12:22
Start evaluation on dev dataset.
Acc. (Correct/Total):  1.01% micro-Prec: 0.7581 micro-Recall:0.0152 micro-F1: 0.0298 dev loss: 0.145402
Epoch id: 12, Training steps: 100,  Train Loss: 0.016,  Train Acc: 75.00%,  Train Avg Loss: 0.015408,  Time: 1:13:33
Epoch id: 12, Training steps: 200,  Train Loss: 0.017,  Train Acc: 50.00%,  Train Avg Loss: 0.009172,  Time: 1:14:04
Epoch id: 12, Training steps: 300,  Train Loss: 0.0012,  Train Acc: 100.00%,  Train Avg Loss: 0.010311,  Time: 1:14:35
Epoch id: 12, Training steps: 400,  Train Loss: 0.017,  Train Acc: 75.00%,  Train Avg Loss: 0.010955,  Time: 1:15:06
Epoch id: 12, Training steps: 500,  Train Loss: 0.009,  Train Acc: 62.50%,  Train Avg Loss: 0.009786,  Time: 1:15:37
Epoch id: 12, Training steps: 600,  Train Loss: 0.007,  Train Acc: 75.00%,  Train Avg Loss: 0.010293,  Time: 1:16:08
Epoch id: 12, Training steps: 700,  Train Loss: 0.024,  Train Acc: 75.00%,  Train Avg Loss: 0.015750,  Time: 1:16:39
Epoch id: 12, Training steps: 800,  Train Loss: 0.0052,  Train Acc: 87.50%,  Train Avg Loss: 0.009990,  Time: 1:17:10
Epoch id: 12, Training steps: 900,  Train Loss: 0.028,  Train Acc: 50.00%,  Train Avg Loss: 0.011555,  Time: 1:17:41
Epoch id: 12, Training steps: 1000,  Train Loss:  0.02,  Train Acc: 37.50%,  Train Avg Loss: 0.011858,  Time: 1:18:12
Epoch id: 12, Training steps: 1100,  Train Loss: 0.0059,  Train Acc: 87.50%,  Train Avg Loss: 0.011781,  Time: 1:18:42
Start evaluation on dev dataset.
Acc. (Correct/Total):  0.91% micro-Prec: 0.8333 micro-Recall:0.0227 micro-F1: 0.0441 dev loss: 0.167963
Epoch id: 13, Training steps: 100,  Train Loss: 0.0091,  Train Acc: 75.00%,  Train Avg Loss: 0.012956,  Time: 1:19:53
Epoch id: 13, Training steps: 200,  Train Loss:  0.01,  Train Acc: 75.00%,  Train Avg Loss: 0.008508,  Time: 1:20:24
Epoch id: 13, Training steps: 300,  Train Loss: 0.0051,  Train Acc: 75.00%,  Train Avg Loss: 0.008475,  Time: 1:20:55
Epoch id: 13, Training steps: 400,  Train Loss: 0.0042,  Train Acc: 87.50%,  Train Avg Loss: 0.008987,  Time: 1:21:26
Epoch id: 13, Training steps: 500,  Train Loss: 0.013,  Train Acc: 50.00%,  Train Avg Loss: 0.008510,  Time: 1:21:57
Epoch id: 13, Training steps: 600,  Train Loss: 0.0071,  Train Acc: 75.00%,  Train Avg Loss: 0.008913,  Time: 1:22:28
Epoch id: 13, Training steps: 700,  Train Loss: 0.0023,  Train Acc: 87.50%,  Train Avg Loss: 0.009037,  Time: 1:22:59
Epoch id: 13, Training steps: 800,  Train Loss: 0.0085,  Train Acc: 62.50%,  Train Avg Loss: 0.008676,  Time: 1:23:30
Epoch id: 13, Training steps: 900,  Train Loss: 0.0081,  Train Acc: 62.50%,  Train Avg Loss: 0.009532,  Time: 1:24:01
Epoch id: 13, Training steps: 1000,  Train Loss: 0.0029,  Train Acc: 87.50%,  Train Avg Loss: 0.008476,  Time: 1:24:32
Epoch id: 13, Training steps: 1100,  Train Loss: 0.0054,  Train Acc: 75.00%,  Train Avg Loss: 0.008194,  Time: 1:25:03
Start evaluation on dev dataset.
Acc. (Correct/Total):  0.77% micro-Prec: 0.8000 micro-Recall:0.0220 micro-F1: 0.0428 dev loss: 0.141316
Epoch id: 14, Training steps: 100,  Train Loss: 0.0064,  Train Acc: 50.00%,  Train Avg Loss: 0.011374,  Time: 1:26:13
Epoch id: 14, Training steps: 200,  Train Loss:  0.01,  Train Acc: 75.00%,  Train Avg Loss: 0.007579,  Time: 1:26:44
Epoch id: 14, Training steps: 300,  Train Loss: 0.019,  Train Acc: 37.50%,  Train Avg Loss: 0.007259,  Time: 1:27:15
Epoch id: 14, Training steps: 400,  Train Loss: 0.0013,  Train Acc: 100.00%,  Train Avg Loss: 0.006828,  Time: 1:27:46
Epoch id: 14, Training steps: 500,  Train Loss: 0.0063,  Train Acc: 75.00%,  Train Avg Loss: 0.006164,  Time: 1:28:17
Epoch id: 14, Training steps: 600,  Train Loss: 0.0058,  Train Acc: 75.00%,  Train Avg Loss: 0.006985,  Time: 1:28:48
Epoch id: 14, Training steps: 700,  Train Loss: 0.0026,  Train Acc: 75.00%,  Train Avg Loss: 0.007893,  Time: 1:29:19
Epoch id: 14, Training steps: 800,  Train Loss: 0.0095,  Train Acc: 62.50%,  Train Avg Loss: 0.006707,  Time: 1:29:50
Epoch id: 14, Training steps: 900,  Train Loss: 0.0076,  Train Acc: 75.00%,  Train Avg Loss: 0.007739,  Time: 1:30:21
Epoch id: 14, Training steps: 1000,  Train Loss: 0.011,  Train Acc: 50.00%,  Train Avg Loss: 0.008012,  Time: 1:30:52
Epoch id: 14, Training steps: 1100,  Train Loss: 0.0076,  Train Acc: 75.00%,  Train Avg Loss: 0.008017,  Time: 1:31:23
Start evaluation on dev dataset.
Acc. (Correct/Total):  2.21% micro-Prec: 0.7231 micro-Recall:0.0567 micro-F1: 0.1051 dev loss: 0.144882
Epoch id: 15, Training steps: 100,  Train Loss: 0.008,  Train Acc: 62.50%,  Train Avg Loss: 0.009855,  Time: 1:32:33
Epoch id: 15, Training steps: 200,  Train Loss: 0.002,  Train Acc: 100.00%,  Train Avg Loss: 0.005934,  Time: 1:33:04
Epoch id: 15, Training steps: 300,  Train Loss: 0.0038,  Train Acc: 87.50%,  Train Avg Loss: 0.005950,  Time: 1:33:35
Epoch id: 15, Training steps: 400,  Train Loss: 0.0053,  Train Acc: 75.00%,  Train Avg Loss: 0.005628,  Time: 1:34:06
Epoch id: 15, Training steps: 500,  Train Loss:  0.02,  Train Acc: 62.50%,  Train Avg Loss: 0.007204,  Time: 1:34:37
Epoch id: 15, Training steps: 600,  Train Loss:  0.01,  Train Acc: 37.50%,  Train Avg Loss: 0.007982,  Time: 1:35:08
Epoch id: 15, Training steps: 700,  Train Loss: 0.0074,  Train Acc: 75.00%,  Train Avg Loss: 0.007796,  Time: 1:35:39
Epoch id: 15, Training steps: 800,  Train Loss: 0.019,  Train Acc: 75.00%,  Train Avg Loss: 0.008457,  Time: 1:36:10
Epoch id: 15, Training steps: 900,  Train Loss: 0.0027,  Train Acc: 87.50%,  Train Avg Loss: 0.008473,  Time: 1:36:41
Epoch id: 15, Training steps: 1000,  Train Loss: 0.019,  Train Acc: 50.00%,  Train Avg Loss: 0.008065,  Time: 1:37:12
Epoch id: 15, Training steps: 1100,  Train Loss: 0.0077,  Train Acc: 50.00%,  Train Avg Loss: 0.006528,  Time: 1:37:43
Start evaluation on dev dataset.
Acc. (Correct/Total):  1.92% micro-Prec: 0.7515 micro-Recall:0.0411 micro-F1: 0.0780 dev loss: 0.180664
Start evaluation on test dataset.
Acc. (Correct/Total):  3.29% micro-Prec: 0.8222 micro-Recall:0.0598 micro-F1: 0.1115 dev loss: 0.177494
Epoch id: 16, Training steps: 100,  Train Loss: 0.0071,  Train Acc: 62.50%,  Train Avg Loss: 0.009515,  Time: 1:39:22
Epoch id: 16, Training steps: 200,  Train Loss: 0.0067,  Train Acc: 50.00%,  Train Avg Loss: 0.006248,  Time: 1:39:53
Epoch id: 16, Training steps: 300,  Train Loss: 0.0096,  Train Acc: 75.00%,  Train Avg Loss: 0.005346,  Time: 1:40:24
Epoch id: 16, Training steps: 400,  Train Loss: 0.0005,  Train Acc: 100.00%,  Train Avg Loss: 0.006162,  Time: 1:40:55
Epoch id: 16, Training steps: 500,  Train Loss: 0.0013,  Train Acc: 87.50%,  Train Avg Loss: 0.005679,  Time: 1:41:26
Epoch id: 16, Training steps: 600,  Train Loss:  0.01,  Train Acc: 75.00%,  Train Avg Loss: 0.005855,  Time: 1:41:57
Epoch id: 16, Training steps: 700,  Train Loss: 0.0019,  Train Acc: 75.00%,  Train Avg Loss: 0.006963,  Time: 1:42:28
Epoch id: 16, Training steps: 800,  Train Loss:  0.02,  Train Acc: 62.50%,  Train Avg Loss: 0.006594,  Time: 1:42:59
Epoch id: 16, Training steps: 900,  Train Loss: 0.0073,  Train Acc: 62.50%,  Train Avg Loss: 0.005851,  Time: 1:43:30
Epoch id: 16, Training steps: 1000,  Train Loss: 0.0034,  Train Acc: 87.50%,  Train Avg Loss: 0.006411,  Time: 1:44:01
Epoch id: 16, Training steps: 1100,  Train Loss: 0.0097,  Train Acc: 50.00%,  Train Avg Loss: 0.006514,  Time: 1:44:32
Start evaluation on dev dataset.
Acc. (Correct/Total):  5.18% micro-Prec: 0.7769 micro-Recall:0.0654 micro-F1: 0.1206 dev loss: 0.193743
Start evaluation on test dataset.
Acc. (Correct/Total):  9.77% micro-Prec: 0.8846 micro-Recall:0.1190 micro-F1: 0.2097 dev loss: 0.184891
Epoch id: 17, Training steps: 100,  Train Loss: 0.0069,  Train Acc: 87.50%,  Train Avg Loss: 0.007294,  Time: 1:46:11
Epoch id: 17, Training steps: 200,  Train Loss: 0.0038,  Train Acc: 75.00%,  Train Avg Loss: 0.004543,  Time: 1:46:42
Epoch id: 17, Training steps: 300,  Train Loss: 0.0018,  Train Acc: 87.50%,  Train Avg Loss: 0.005497,  Time: 1:47:13
Epoch id: 17, Training steps: 400,  Train Loss: 0.0098,  Train Acc: 75.00%,  Train Avg Loss: 0.005149,  Time: 1:47:44
Epoch id: 17, Training steps: 500,  Train Loss: 0.0013,  Train Acc: 87.50%,  Train Avg Loss: 0.004351,  Time: 1:48:15
Epoch id: 17, Training steps: 600,  Train Loss: 0.0038,  Train Acc: 75.00%,  Train Avg Loss: 0.005038,  Time: 1:48:46
Epoch id: 17, Training steps: 700,  Train Loss: 0.0094,  Train Acc: 62.50%,  Train Avg Loss: 0.004849,  Time: 1:49:17
Epoch id: 17, Training steps: 800,  Train Loss: 0.0051,  Train Acc: 87.50%,  Train Avg Loss: 0.005503,  Time: 1:49:48
Epoch id: 17, Training steps: 900,  Train Loss: 0.0032,  Train Acc: 75.00%,  Train Avg Loss: 0.005855,  Time: 1:50:19
Epoch id: 17, Training steps: 1000,  Train Loss: 0.0052,  Train Acc: 87.50%,  Train Avg Loss: 0.004963,  Time: 1:50:51
Epoch id: 17, Training steps: 1100,  Train Loss:  0.01,  Train Acc: 62.50%,  Train Avg Loss: 0.005872,  Time: 1:51:22
Start evaluation on dev dataset.
Acc. (Correct/Total):  1.01% micro-Prec: 0.8082 micro-Recall:0.0191 micro-F1: 0.0373 dev loss: 0.202082
Start evaluation on test dataset.
Acc. (Correct/Total):  0.77% micro-Prec: 0.6491 micro-Recall:0.0120 micro-F1: 0.0235 dev loss: 0.203446
Epoch id: 18, Training steps: 100,  Train Loss: 0.0043,  Train Acc: 75.00%,  Train Avg Loss: 0.006153,  Time: 1:53:01
Epoch id: 18, Training steps: 200,  Train Loss: 0.0048,  Train Acc: 87.50%,  Train Avg Loss: 0.003913,  Time: 1:53:32
Epoch id: 18, Training steps: 300,  Train Loss: 0.0021,  Train Acc: 100.00%,  Train Avg Loss: 0.003572,  Time: 1:54:03
Epoch id: 18, Training steps: 400,  Train Loss: 0.0038,  Train Acc: 75.00%,  Train Avg Loss: 0.004693,  Time: 1:54:34
Epoch id: 18, Training steps: 500,  Train Loss: 0.0046,  Train Acc: 75.00%,  Train Avg Loss: 0.004382,  Time: 1:55:05
Epoch id: 18, Training steps: 600,  Train Loss: 0.00053,  Train Acc: 100.00%,  Train Avg Loss: 0.004452,  Time: 1:55:36
Epoch id: 18, Training steps: 700,  Train Loss: 0.0013,  Train Acc: 87.50%,  Train Avg Loss: 0.004175,  Time: 1:56:07
Epoch id: 18, Training steps: 800,  Train Loss: 0.0041,  Train Acc: 87.50%,  Train Avg Loss: 0.004519,  Time: 1:56:38
Epoch id: 18, Training steps: 900,  Train Loss: 0.0023,  Train Acc: 87.50%,  Train Avg Loss: 0.006347,  Time: 1:57:09
Epoch id: 18, Training steps: 1000,  Train Loss: 0.007,  Train Acc: 75.00%,  Train Avg Loss: 0.005036,  Time: 1:57:40
Epoch id: 18, Training steps: 1100,  Train Loss: 0.0067,  Train Acc: 75.00%,  Train Avg Loss: 0.005965,  Time: 1:58:11
Start evaluation on dev dataset.
Acc. (Correct/Total):  5.18% micro-Prec: 0.6951 micro-Recall:0.0871 micro-F1: 0.1548 dev loss: 0.166576
Epoch id: 19, Training steps: 100,  Train Loss: 0.0025,  Train Acc: 100.00%,  Train Avg Loss: 0.007006,  Time: 1:59:21
Epoch id: 19, Training steps: 200,  Train Loss: 0.0015,  Train Acc: 100.00%,  Train Avg Loss: 0.005152,  Time: 1:59:52
Epoch 00201: reducing learning rate of group 0 to 2.0000e-06.
Epoch id: 19, Training steps: 300,  Train Loss: 0.0048,  Train Acc: 62.50%,  Train Avg Loss: 0.003926,  Time: 2:00:23
Epoch id: 19, Training steps: 400,  Train Loss: 0.0027,  Train Acc: 87.50%,  Train Avg Loss: 0.004254,  Time: 2:00:54
Epoch id: 19, Training steps: 500,  Train Loss: 0.00044,  Train Acc: 100.00%,  Train Avg Loss: 0.003630,  Time: 2:01:25
Epoch id: 19, Training steps: 600,  Train Loss: 0.0079,  Train Acc: 87.50%,  Train Avg Loss: 0.003660,  Time: 2:01:56
Epoch id: 19, Training steps: 700,  Train Loss: 0.0012,  Train Acc: 87.50%,  Train Avg Loss: 0.003593,  Time: 2:02:27
Epoch id: 19, Training steps: 800,  Train Loss: 0.001,  Train Acc: 87.50%,  Train Avg Loss: 0.003214,  Time: 2:02:58
Epoch id: 19, Training steps: 900,  Train Loss: 0.016,  Train Acc: 50.00%,  Train Avg Loss: 0.003293,  Time: 2:03:29
Epoch id: 19, Training steps: 1000,  Train Loss: 0.0034,  Train Acc: 87.50%,  Train Avg Loss: 0.003179,  Time: 2:04:00
Epoch id: 19, Training steps: 1100,  Train Loss: 0.0046,  Train Acc: 87.50%,  Train Avg Loss: 0.003148,  Time: 2:04:31
Start evaluation on dev dataset.
Acc. (Correct/Total):  3.45% micro-Prec: 0.7530 micro-Recall:0.0819 micro-F1: 0.1477 dev loss: 0.155169
Epoch id: 20, Training steps: 100,  Train Loss: 0.00066,  Train Acc: 100.00%,  Train Avg Loss: 0.003545,  Time: 2:05:41
Epoch id: 20, Training steps: 200,  Train Loss: 0.0028,  Train Acc: 100.00%,  Train Avg Loss: 0.002009,  Time: 2:06:12
Epoch id: 20, Training steps: 300,  Train Loss: 0.0015,  Train Acc: 87.50%,  Train Avg Loss: 0.002954,  Time: 2:06:43
Epoch id: 20, Training steps: 400,  Train Loss: 0.0022,  Train Acc: 87.50%,  Train Avg Loss: 0.002957,  Time: 2:07:14
Epoch id: 20, Training steps: 500,  Train Loss: 0.001,  Train Acc: 87.50%,  Train Avg Loss: 0.002568,  Time: 2:07:45
Epoch id: 20, Training steps: 600,  Train Loss: 0.0048,  Train Acc: 87.50%,  Train Avg Loss: 0.002866,  Time: 2:08:16
Epoch id: 20, Training steps: 700,  Train Loss: 0.0035,  Train Acc: 75.00%,  Train Avg Loss: 0.002473,  Time: 2:08:47
Epoch id: 20, Training steps: 800,  Train Loss: 0.00079,  Train Acc: 100.00%,  Train Avg Loss: 0.002768,  Time: 2:09:18
Epoch id: 20, Training steps: 900,  Train Loss: 0.0024,  Train Acc: 75.00%,  Train Avg Loss: 0.002426,  Time: 2:09:49
Epoch id: 20, Training steps: 1000,  Train Loss: 0.00081,  Train Acc: 100.00%,  Train Avg Loss: 0.002656,  Time: 2:10:20
Epoch id: 20, Training steps: 1100,  Train Loss: 0.0012,  Train Acc: 100.00%,  Train Avg Loss: 0.002423,  Time: 2:10:51
Start evaluation on dev dataset.
Acc. (Correct/Total):  4.13% micro-Prec: 0.7500 micro-Recall:0.0874 micro-F1: 0.1566 dev loss: 0.159116
Start evaluation on test dataset.
The number of evaluation instances:  2067
Acc. (Correct/Total):  7.69% micro-Prec: 0.8389 micro-Recall:0.1229 micro-F1: 0.2143 dev loss: 0.157095
              precision    recall  f1-score   support

         教育学     0.7879    0.2158    0.3388       241
          法学     0.9667    0.5179    0.6744       224
      中国语言文学     1.0000    0.0162    0.0319       185
         政治学     0.7609    0.2147    0.3349       163
         社会学     0.9600    0.6115    0.7471       157
         心理学     0.9412    0.2602    0.4076       123
       应用经济学     0.2500    0.0085    0.0165       117
         历史学     0.0000    0.0000    0.0000       109
     环境科学与工程     0.7500    0.0556    0.1034       108
          哲学     1.0000    0.0412    0.0792        97
      外国语言文学     0.0000    0.0000    0.0000        85
         生物学     1.0000    0.1266    0.2247        79
      交通运输工程     0.0000    0.0000    0.0000        78
        临床医学     0.7500    0.0395    0.0750        76
    计算机科学与技术     0.0000    0.0000    0.0000        71
        土木工程     0.0000    0.0000    0.0000        66
   航空宇航科学与技术     0.0000    0.0000    0.0000        61
         民族学     0.0000    0.0000    0.0000        55
   公共卫生与预防医学     0.1176    0.0392    0.0588        51
         美术学     0.0000    0.0000    0.0000        50
         艺术学     0.0000    0.0000    0.0000        43
         地理学     0.0000    0.0000    0.0000        42
         体育学     0.0000    0.0000    0.0000        40
       理论经济学     0.8125    0.3421    0.4815        38
         中医学     0.0000    0.0000    0.0000        37
         物理学     0.0000    0.0000    0.0000        36
          林学     0.0000    0.0000    0.0000        33
          数学     0.0000    0.0000    0.0000        32
     电子科学与技术     0.0000    0.0000    0.0000        31
        基础医学     0.0000    0.0000    0.0000        29
        工商管理     0.0000    0.0000    0.0000        27
       新闻传播学     0.0000    0.0000    0.0000        22
         天文学     0.0000    0.0000    0.0000        22
         地质学     0.0000    0.0000    0.0000        21
         畜牧学     0.0000    0.0000    0.0000        21
   军事思想及军事历史     0.8571    0.3000    0.4444        20
     管理科学与工程     0.0000    0.0000    0.0000        18
     测绘科学与技术     0.0000    0.0000    0.0000        17
        水利工程     0.0000    0.0000    0.0000        16
        大气科学     0.0000    0.0000    0.0000        16
     兵器科学与技术     0.0000    0.0000    0.0000        15
       地球物理学     0.0000    0.0000    0.0000        14
        电气工程     0.0000    0.0000    0.0000        13
         作物学     0.0000    0.0000    0.0000        13
     控制科学与工程     0.0000    0.0000    0.0000        13
     信息与通信工程     0.0000    0.0000    0.0000        13
        公共管理     0.0000    0.0000    0.0000        13
         建筑学     1.0000    0.0769    0.1429        13
     化学工程与技术     0.0000    0.0000    0.0000        12
          力学     0.0000    0.0000    0.0000        11
        海洋科学     0.0000    0.0000    0.0000        11
     轻工技术与工程     0.0000    0.0000    0.0000        11
        农业工程     0.0000    0.0000    0.0000        10
         园艺学     0.0000    0.0000    0.0000        10
       中西医结合     0.0000    0.0000    0.0000        10
        机械工程     0.0000    0.0000    0.0000         9
       科学技术史     0.0000    0.0000    0.0000         8
     船舶与海洋工程     0.0000    0.0000    0.0000         8
   图书情报与档案管理     0.0000    0.0000    0.0000         8
        植物保护     0.0000    0.0000    0.0000         8
     材料科学与工程     0.0000    0.0000    0.0000         8
         统计学     0.0000    0.0000    0.0000         8
          化学     0.0000    0.0000    0.0000         8
     食品科学与工程     0.0000    0.0000    0.0000         8
          水产     0.0000    0.0000    0.0000         7
          药学     0.0000    0.0000    0.0000         7
     农业资源与环境     0.0000    0.0000    0.0000         7
         世界史     0.0000    0.0000    0.0000         7
        系统科学     0.0000    0.0000    0.0000         7
      农林经济管理     0.0000    0.0000    0.0000         5
       军队指挥学     0.0000    0.0000    0.0000         5
        矿业工程     0.0000    0.0000    0.0000         5
     纺织科学与工程     0.0000    0.0000    0.0000         5
  动力工程及工程热物理     0.0000    0.0000    0.0000         4
        林业工程     0.0000    0.0000    0.0000         4
     仪器科学与技术     0.0000    0.0000    0.0000         3
         战略学     0.0000    0.0000    0.0000         3
   地质资源与地质工程     0.0000    0.0000    0.0000         3
        旅游管理     0.0000    0.0000    0.0000         3
 图书馆、情报与档案管理     0.0000    0.0000    0.0000         2
        冶金工程     0.0000    0.0000    0.0000         2
      核科学与技术     0.0000    0.0000    0.0000         2

   micro avg     0.8389    0.1229    0.2143      3093
   macro avg     0.1458    0.0349    0.0507      3093
weighted avg     0.4501    0.1229    0.1736      3093
 samples avg     0.1130    0.0979    0.1026      3093

Final evaluation on the test dataset.
The number of evaluation instances:  2067
Acc. (Correct/Total):  0.77% micro-Prec: 0.6491 micro-Recall:0.0120 micro-F1: 0.0235 dev loss: 0.203446
              precision    recall  f1-score   support

         教育学     0.6842    0.0539    0.1000       241
          法学     1.0000    0.0179    0.0351       224
      中国语言文学     1.0000    0.0054    0.0108       185
         政治学     0.7500    0.0184    0.0359       163
         社会学     1.0000    0.0064    0.0127       157
         心理学     0.9286    0.1057    0.1898       123
       应用经济学     1.0000    0.0085    0.0169       117
         历史学     0.5000    0.0092    0.0180       109
     环境科学与工程     0.0000    0.0000    0.0000       108
          哲学     0.0000    0.0000    0.0000        97
      外国语言文学     0.0000    0.0000    0.0000        85
         生物学     0.0000    0.0000    0.0000        79
      交通运输工程     0.0000    0.0000    0.0000        78
        临床医学     0.0000    0.0000    0.0000        76
    计算机科学与技术     0.0000    0.0000    0.0000        71
        土木工程     0.0000    0.0000    0.0000        66
   航空宇航科学与技术     0.0000    0.0000    0.0000        61
         民族学     0.0000    0.0000    0.0000        55
   公共卫生与预防医学     0.0000    0.0000    0.0000        51
         美术学     0.0000    0.0000    0.0000        50
         艺术学     0.0000    0.0000    0.0000        43
         地理学     0.0000    0.0000    0.0000        42
         体育学     0.0000    0.0000    0.0000        40
       理论经济学     0.0000    0.0000    0.0000        38
         中医学     0.0000    0.0000    0.0000        37
         物理学     0.0000    0.0000    0.0000        36
          林学     0.0000    0.0000    0.0000        33
          数学     0.0000    0.0000    0.0000        32
     电子科学与技术     0.0000    0.0000    0.0000        31
        基础医学     0.0000    0.0000    0.0000        29
        工商管理     0.0000    0.0000    0.0000        27
       新闻传播学     0.0000    0.0000    0.0000        22
         天文学     0.0000    0.0000    0.0000        22
         地质学     0.0000    0.0000    0.0000        21
         畜牧学     0.0000    0.0000    0.0000        21
   军事思想及军事历史     0.0000    0.0000    0.0000        20
     管理科学与工程     0.0000    0.0000    0.0000        18
     测绘科学与技术     0.0000    0.0000    0.0000        17
        水利工程     0.0000    0.0000    0.0000        16
        大气科学     0.0000    0.0000    0.0000        16
     兵器科学与技术     0.0000    0.0000    0.0000        15
       地球物理学     0.0000    0.0000    0.0000        14
        电气工程     0.0000    0.0000    0.0000        13
         作物学     0.0000    0.0000    0.0000        13
     控制科学与工程     0.0000    0.0000    0.0000        13
     信息与通信工程     0.0000    0.0000    0.0000        13
        公共管理     0.0000    0.0000    0.0000        13
         建筑学     0.0000    0.0000    0.0000        13
     化学工程与技术     0.0000    0.0000    0.0000        12
          力学     0.0000    0.0000    0.0000        11
        海洋科学     0.0000    0.0000    0.0000        11
     轻工技术与工程     0.0000    0.0000    0.0000        11
        农业工程     0.0000    0.0000    0.0000        10
         园艺学     0.0000    0.0000    0.0000        10
       中西医结合     0.0000    0.0000    0.0000        10
        机械工程     0.0000    0.0000    0.0000         9
       科学技术史     0.0000    0.0000    0.0000         8
     船舶与海洋工程     0.0000    0.0000    0.0000         8
   图书情报与档案管理     0.0000    0.0000    0.0000         8
        植物保护     0.0000    0.0000    0.0000         8
     材料科学与工程     0.0000    0.0000    0.0000         8
         统计学     0.0000    0.0000    0.0000         8
          化学     0.0000    0.0000    0.0000         8
     食品科学与工程     0.0000    0.0000    0.0000         8
          水产     0.0000    0.0000    0.0000         7
          药学     0.0000    0.0000    0.0000         7
     农业资源与环境     0.0000    0.0000    0.0000         7
         世界史     0.0000    0.0000    0.0000         7
        系统科学     0.0000    0.0000    0.0000         7
      农林经济管理     0.0000    0.0000    0.0000         5
       军队指挥学     0.0000    0.0000    0.0000         5
        矿业工程     0.0000    0.0000    0.0000         5
     纺织科学与工程     0.0000    0.0000    0.0000         5
  动力工程及工程热物理     0.0000    0.0000    0.0000         4
        林业工程     0.0000    0.0000    0.0000         4
     仪器科学与技术     0.0000    0.0000    0.0000         3
         战略学     0.0000    0.0000    0.0000         3
   地质资源与地质工程     0.0000    0.0000    0.0000         3
        旅游管理     0.0000    0.0000    0.0000         3
 图书馆、情报与档案管理     0.0000    0.0000    0.0000         2
        冶金工程     0.0000    0.0000    0.0000         2
      核科学与技术     0.0000    0.0000    0.0000         2

   micro avg     0.6491    0.0120    0.0235      3093
   macro avg     0.0837    0.0027    0.0051      3093
weighted avg     0.3682    0.0120    0.0223      3093
 samples avg     0.0106    0.0094    0.0098      3093


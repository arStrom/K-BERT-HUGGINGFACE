nohup: ignoring input
  0%|          | 0/82 [00:00<?, ?it/s]100%|██████████| 82/82 [00:00<00:00, 1421210.45it/s]
model:  ernie-rcnn-catlstmwide
pretrained:  ernie1
task:  MLC-slice
dataset:  book_multilabels_task_slice
seq_length:  256
hidden_dropout_prob:  0.2
attention_probs_dropout_prob:  0.2
epochs_num:  20
batch_size:  8
learning_rate:  2e-05
report_steps:  100
kg_name:  CnDbpedia
no_kg:  True
no_vm:  True
GPU:  NVIDIA GeForce RTX 3090
Vocabulary Size:  17964
[BertClassifier] use visible_matrix: False
Some weights of ErnieRCNNForMultiLabelSequenceClassificationSliceCatLSTMWide were not initialized from the model checkpoint at ./models/ernie1 and are newly initialized: ['lstm.weight_hh_l1_reverse', 'lstm.weight_hh_l0', 'lstm.bias_ih_l1', 'lstm.bias_ih_l0', 'classifier.bias', 'lstm.bias_ih_l0_reverse', 'lstm.weight_ih_l0', 'lstm.bias_hh_l0_reverse', 'lstm.bias_hh_l1_reverse', 'lstm.weight_hh_l1', 'classifier.weight', 'lstm.weight_hh_l0_reverse', 'lstm.weight_ih_l1_reverse', 'lstm.bias_ih_l1_reverse', 'lstm.weight_ih_l1', 'output_layer_1.bias', 'output_layer_1.weight', 'lstm.weight_ih_l0_reverse', 'lstm.bias_hh_l0', 'lstm.bias_hh_l1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
1 GPUs are available. Let's use them.
device:  cuda
Start training.
Loading sentences from ./datasets/book_multilabels_task_slice/train.tsv
There are 9097 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/9097
Loading sentences from ./datasets/book_multilabels_task_slice/dev.tsv
There are 2084 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/2084
Loading sentences from ./datasets/book_multilabels_task_slice/test.tsv
There are 2067 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/2067
Epoch id: 1, Training steps: 100,  Train Loss: 0.072,  Train Acc:  0.00%,  Train Avg Loss: 0.177267,  Time: 0:00:31
Epoch id: 1, Training steps: 200,  Train Loss: 0.085,  Train Acc:  0.00%,  Train Avg Loss: 0.085443,  Time: 0:01:01
Epoch id: 1, Training steps: 300,  Train Loss: 0.079,  Train Acc:  0.00%,  Train Avg Loss: 0.084777,  Time: 0:01:32
Epoch id: 1, Training steps: 400,  Train Loss: 0.069,  Train Acc:  0.00%,  Train Avg Loss: 0.083767,  Time: 0:02:03
Epoch id: 1, Training steps: 500,  Train Loss:  0.09,  Train Acc:  0.00%,  Train Avg Loss: 0.082030,  Time: 0:02:34
Epoch id: 1, Training steps: 600,  Train Loss: 0.087,  Train Acc:  0.00%,  Train Avg Loss: 0.082003,  Time: 0:03:05
Epoch id: 1, Training steps: 700,  Train Loss: 0.094,  Train Acc:  0.00%,  Train Avg Loss: 0.082598,  Time: 0:03:36
Epoch id: 1, Training steps: 800,  Train Loss: 0.084,  Train Acc:  0.00%,  Train Avg Loss: 0.080363,  Time: 0:04:07
Epoch id: 1, Training steps: 900,  Train Loss: 0.084,  Train Acc:  0.00%,  Train Avg Loss: 0.079303,  Time: 0:04:38
Epoch id: 1, Training steps: 1000,  Train Loss: 0.092,  Train Acc:  0.00%,  Train Avg Loss: 0.077514,  Time: 0:05:09
Epoch id: 1, Training steps: 1100,  Train Loss: 0.072,  Train Acc:  0.00%,  Train Avg Loss: 0.075428,  Time: 0:05:40
Start evaluation on dev dataset.
Acc. (Correct/Total):  0.00% micro-Prec: 0.5882 micro-Recall:0.0032 micro-F1: 0.0064 dev loss: 0.095074
Start evaluation on test dataset.
Acc. (Correct/Total):  0.00% micro-Prec: 0.6154 micro-Recall:0.0026 micro-F1: 0.0052 dev loss: 0.094754
Epoch id: 2, Training steps: 100,  Train Loss:  0.08,  Train Acc:  0.00%,  Train Avg Loss: 0.093570,  Time: 0:07:19
Epoch id: 2, Training steps: 200,  Train Loss: 0.055,  Train Acc:  0.00%,  Train Avg Loss: 0.064705,  Time: 0:07:50
Epoch id: 2, Training steps: 300,  Train Loss:  0.05,  Train Acc: 12.50%,  Train Avg Loss: 0.059993,  Time: 0:08:21
Epoch id: 2, Training steps: 400,  Train Loss: 0.052,  Train Acc: 12.50%,  Train Avg Loss: 0.055133,  Time: 0:08:52
Epoch id: 2, Training steps: 500,  Train Loss: 0.041,  Train Acc: 12.50%,  Train Avg Loss: 0.051496,  Time: 0:09:23
Epoch id: 2, Training steps: 600,  Train Loss: 0.048,  Train Acc: 12.50%,  Train Avg Loss: 0.047683,  Time: 0:09:54
Epoch id: 2, Training steps: 700,  Train Loss: 0.049,  Train Acc: 12.50%,  Train Avg Loss: 0.046500,  Time: 0:10:25
Epoch id: 2, Training steps: 800,  Train Loss: 0.063,  Train Acc: 12.50%,  Train Avg Loss: 0.044591,  Time: 0:10:56
Epoch id: 2, Training steps: 900,  Train Loss: 0.032,  Train Acc: 12.50%,  Train Avg Loss: 0.042079,  Time: 0:11:27
Epoch id: 2, Training steps: 1000,  Train Loss:  0.04,  Train Acc: 25.00%,  Train Avg Loss: 0.043500,  Time: 0:11:58
Epoch id: 2, Training steps: 1100,  Train Loss: 0.063,  Train Acc:  0.00%,  Train Avg Loss: 0.043581,  Time: 0:12:29
Start evaluation on dev dataset.
Acc. (Correct/Total): 27.78% micro-Prec: 0.7816 micro-Recall:0.3464 micro-F1: 0.4800 dev loss: 0.066245
Start evaluation on test dataset.
Acc. (Correct/Total): 34.93% micro-Prec: 0.8497 micro-Recall:0.4058 micro-F1: 0.5492 dev loss: 0.062421
Epoch id: 3, Training steps: 100,  Train Loss: 0.022,  Train Acc: 37.50%,  Train Avg Loss: 0.053009,  Time: 0:14:08
Epoch id: 3, Training steps: 200,  Train Loss: 0.028,  Train Acc: 25.00%,  Train Avg Loss: 0.036727,  Time: 0:14:39
Epoch id: 3, Training steps: 300,  Train Loss: 0.021,  Train Acc: 25.00%,  Train Avg Loss: 0.037972,  Time: 0:15:10
Epoch id: 3, Training steps: 400,  Train Loss: 0.054,  Train Acc:  0.00%,  Train Avg Loss: 0.036328,  Time: 0:15:41
Epoch id: 3, Training steps: 500,  Train Loss: 0.043,  Train Acc: 37.50%,  Train Avg Loss: 0.034400,  Time: 0:16:12
Epoch id: 3, Training steps: 600,  Train Loss: 0.034,  Train Acc: 25.00%,  Train Avg Loss: 0.046660,  Time: 0:16:43
Epoch id: 3, Training steps: 700,  Train Loss: 0.037,  Train Acc: 25.00%,  Train Avg Loss: 0.043905,  Time: 0:17:14
Epoch id: 3, Training steps: 800,  Train Loss: 0.049,  Train Acc:  0.00%,  Train Avg Loss: 0.044512,  Time: 0:17:45
Epoch id: 3, Training steps: 900,  Train Loss: 0.0099,  Train Acc: 75.00%,  Train Avg Loss: 0.040014,  Time: 0:18:16
Epoch id: 3, Training steps: 1000,  Train Loss: 0.022,  Train Acc: 37.50%,  Train Avg Loss: 0.037635,  Time: 0:18:47
Epoch id: 3, Training steps: 1100,  Train Loss: 0.026,  Train Acc: 25.00%,  Train Avg Loss: 0.036967,  Time: 0:19:18
Start evaluation on dev dataset.
Acc. (Correct/Total): 30.90% micro-Prec: 0.7676 micro-Recall:0.4234 micro-F1: 0.5458 dev loss: 0.062707
Start evaluation on test dataset.
Acc. (Correct/Total): 37.69% micro-Prec: 0.7939 micro-Recall:0.4808 micro-F1: 0.5989 dev loss: 0.058877
Epoch id: 4, Training steps: 100,  Train Loss: 0.033,  Train Acc: 25.00%,  Train Avg Loss: 0.046655,  Time: 0:20:57
Epoch id: 4, Training steps: 200,  Train Loss:  0.02,  Train Acc: 37.50%,  Train Avg Loss: 0.029921,  Time: 0:21:28
Epoch id: 4, Training steps: 300,  Train Loss: 0.037,  Train Acc: 25.00%,  Train Avg Loss: 0.029759,  Time: 0:21:59
Epoch id: 4, Training steps: 400,  Train Loss: 0.038,  Train Acc: 25.00%,  Train Avg Loss: 0.030733,  Time: 0:22:30
Epoch id: 4, Training steps: 500,  Train Loss: 0.037,  Train Acc: 37.50%,  Train Avg Loss: 0.029274,  Time: 0:23:01
Epoch id: 4, Training steps: 600,  Train Loss: 0.052,  Train Acc:  0.00%,  Train Avg Loss: 0.029439,  Time: 0:23:32
Epoch id: 4, Training steps: 700,  Train Loss: 0.025,  Train Acc: 25.00%,  Train Avg Loss: 0.029308,  Time: 0:24:03
Epoch id: 4, Training steps: 800,  Train Loss: 0.031,  Train Acc: 25.00%,  Train Avg Loss: 0.029077,  Time: 0:24:34
Epoch id: 4, Training steps: 900,  Train Loss: 0.022,  Train Acc: 75.00%,  Train Avg Loss: 0.030137,  Time: 0:25:06
Epoch id: 4, Training steps: 1000,  Train Loss: 0.018,  Train Acc: 37.50%,  Train Avg Loss: 0.028162,  Time: 0:25:37
Epoch id: 4, Training steps: 1100,  Train Loss: 0.031,  Train Acc: 25.00%,  Train Avg Loss: 0.027772,  Time: 0:26:08
Start evaluation on dev dataset.
Acc. (Correct/Total): 39.73% micro-Prec: 0.7602 micro-Recall:0.5050 micro-F1: 0.6069 dev loss: 0.053515
Start evaluation on test dataset.
Acc. (Correct/Total): 46.15% micro-Prec: 0.8147 micro-Recall:0.5529 micro-F1: 0.6587 dev loss: 0.049604
Epoch id: 5, Training steps: 100,  Train Loss: 0.013,  Train Acc: 50.00%,  Train Avg Loss: 0.035671,  Time: 0:27:49
Epoch id: 5, Training steps: 200,  Train Loss: 0.0098,  Train Acc: 62.50%,  Train Avg Loss: 0.026490,  Time: 0:28:20
Epoch id: 5, Training steps: 300,  Train Loss: 0.031,  Train Acc: 37.50%,  Train Avg Loss: 0.024794,  Time: 0:28:51
Epoch id: 5, Training steps: 400,  Train Loss:  0.02,  Train Acc: 75.00%,  Train Avg Loss: 0.022982,  Time: 0:29:22
Epoch id: 5, Training steps: 500,  Train Loss: 0.029,  Train Acc: 37.50%,  Train Avg Loss: 0.024051,  Time: 0:29:53
Epoch id: 5, Training steps: 600,  Train Loss: 0.025,  Train Acc: 37.50%,  Train Avg Loss: 0.025123,  Time: 0:30:24
Epoch id: 5, Training steps: 700,  Train Loss: 0.017,  Train Acc: 37.50%,  Train Avg Loss: 0.024919,  Time: 0:30:55
Epoch id: 5, Training steps: 800,  Train Loss: 0.024,  Train Acc: 25.00%,  Train Avg Loss: 0.023567,  Time: 0:31:26
Epoch id: 5, Training steps: 900,  Train Loss:  0.04,  Train Acc: 25.00%,  Train Avg Loss: 0.024538,  Time: 0:31:57
Epoch id: 5, Training steps: 1000,  Train Loss: 0.032,  Train Acc: 25.00%,  Train Avg Loss: 0.023205,  Time: 0:32:28
Epoch id: 5, Training steps: 1100,  Train Loss: 0.028,  Train Acc: 25.00%,  Train Avg Loss: 0.025545,  Time: 0:32:59
Start evaluation on dev dataset.
Acc. (Correct/Total): 42.03% micro-Prec: 0.7413 micro-Recall:0.5604 micro-F1: 0.6383 dev loss: 0.053223
Start evaluation on test dataset.
Acc. (Correct/Total): 49.98% micro-Prec: 0.7977 micro-Recall:0.6220 micro-F1: 0.6990 dev loss: 0.048423
Epoch id: 6, Training steps: 100,  Train Loss: 0.027,  Train Acc: 50.00%,  Train Avg Loss: 0.032944,  Time: 0:34:39
Epoch id: 6, Training steps: 200,  Train Loss:  0.02,  Train Acc: 50.00%,  Train Avg Loss: 0.022805,  Time: 0:35:10
Epoch id: 6, Training steps: 300,  Train Loss: 0.013,  Train Acc: 37.50%,  Train Avg Loss: 0.021301,  Time: 0:35:41
Epoch id: 6, Training steps: 400,  Train Loss: 0.019,  Train Acc: 50.00%,  Train Avg Loss: 0.020221,  Time: 0:36:12
Epoch id: 6, Training steps: 500,  Train Loss: 0.012,  Train Acc: 62.50%,  Train Avg Loss: 0.019758,  Time: 0:36:43
Epoch id: 6, Training steps: 600,  Train Loss: 0.0097,  Train Acc: 75.00%,  Train Avg Loss: 0.019886,  Time: 0:37:14
Epoch id: 6, Training steps: 700,  Train Loss:  0.01,  Train Acc: 75.00%,  Train Avg Loss: 0.021686,  Time: 0:37:45
Epoch id: 6, Training steps: 800,  Train Loss: 0.027,  Train Acc: 25.00%,  Train Avg Loss: 0.020747,  Time: 0:38:16
Epoch id: 6, Training steps: 900,  Train Loss: 0.014,  Train Acc: 37.50%,  Train Avg Loss: 0.020719,  Time: 0:38:47
Epoch id: 6, Training steps: 1000,  Train Loss:  0.02,  Train Acc: 50.00%,  Train Avg Loss: 0.022712,  Time: 0:39:18
Epoch id: 6, Training steps: 1100,  Train Loss: 0.033,  Train Acc: 37.50%,  Train Avg Loss: 0.020065,  Time: 0:39:49
Start evaluation on dev dataset.
Acc. (Correct/Total): 46.16% micro-Prec: 0.7607 micro-Recall:0.5947 micro-F1: 0.6675 dev loss: 0.045212
Start evaluation on test dataset.
Acc. (Correct/Total): 53.22% micro-Prec: 0.8092 micro-Recall:0.6570 micro-F1: 0.7252 dev loss: 0.041081
Epoch id: 7, Training steps: 100,  Train Loss: 0.033,  Train Acc: 25.00%,  Train Avg Loss: 0.026148,  Time: 0:41:29
Epoch id: 7, Training steps: 200,  Train Loss: 0.022,  Train Acc: 50.00%,  Train Avg Loss: 0.017314,  Time: 0:42:00
Epoch id: 7, Training steps: 300,  Train Loss: 0.025,  Train Acc: 50.00%,  Train Avg Loss: 0.018424,  Time: 0:42:31
Epoch id: 7, Training steps: 400,  Train Loss: 0.027,  Train Acc: 37.50%,  Train Avg Loss: 0.017971,  Time: 0:43:02
Epoch id: 7, Training steps: 500,  Train Loss: 0.038,  Train Acc: 25.00%,  Train Avg Loss: 0.018951,  Time: 0:43:34
Epoch id: 7, Training steps: 600,  Train Loss: 0.0021,  Train Acc: 87.50%,  Train Avg Loss: 0.017459,  Time: 0:44:05
Epoch id: 7, Training steps: 700,  Train Loss: 0.0075,  Train Acc: 75.00%,  Train Avg Loss: 0.017260,  Time: 0:44:36
Epoch id: 7, Training steps: 800,  Train Loss: 0.016,  Train Acc: 62.50%,  Train Avg Loss: 0.017049,  Time: 0:45:07
Epoch id: 7, Training steps: 900,  Train Loss: 0.015,  Train Acc: 50.00%,  Train Avg Loss: 0.016469,  Time: 0:45:38
Epoch id: 7, Training steps: 1000,  Train Loss: 0.038,  Train Acc: 50.00%,  Train Avg Loss: 0.016947,  Time: 0:46:09
Epoch id: 7, Training steps: 1100,  Train Loss:  0.01,  Train Acc: 50.00%,  Train Avg Loss: 0.018579,  Time: 0:46:40
Start evaluation on dev dataset.
Acc. (Correct/Total): 47.07% micro-Prec: 0.7556 micro-Recall:0.6125 micro-F1: 0.6766 dev loss: 0.047355
Epoch id: 8, Training steps: 100,  Train Loss: 0.012,  Train Acc: 62.50%,  Train Avg Loss: 0.024275,  Time: 0:47:50
Epoch id: 8, Training steps: 200,  Train Loss: 0.006,  Train Acc: 87.50%,  Train Avg Loss: 0.015302,  Time: 0:48:21
Epoch id: 8, Training steps: 300,  Train Loss: 0.0085,  Train Acc: 75.00%,  Train Avg Loss: 0.014440,  Time: 0:48:52
Epoch id: 8, Training steps: 400,  Train Loss: 0.018,  Train Acc: 25.00%,  Train Avg Loss: 0.014235,  Time: 0:49:23
Epoch id: 8, Training steps: 500,  Train Loss:  0.03,  Train Acc: 25.00%,  Train Avg Loss: 0.014130,  Time: 0:49:54
Epoch id: 8, Training steps: 600,  Train Loss: 0.022,  Train Acc: 37.50%,  Train Avg Loss: 0.015779,  Time: 0:50:25
Epoch id: 8, Training steps: 700,  Train Loss: 0.018,  Train Acc: 62.50%,  Train Avg Loss: 0.014028,  Time: 0:50:56
Epoch id: 8, Training steps: 800,  Train Loss: 0.024,  Train Acc: 50.00%,  Train Avg Loss: 0.019715,  Time: 0:51:27
Epoch id: 8, Training steps: 900,  Train Loss: 0.017,  Train Acc: 37.50%,  Train Avg Loss: 0.019658,  Time: 0:51:58
Epoch id: 8, Training steps: 1000,  Train Loss: 0.018,  Train Acc: 50.00%,  Train Avg Loss: 0.017130,  Time: 0:52:29
Epoch id: 8, Training steps: 1100,  Train Loss: 0.0045,  Train Acc: 75.00%,  Train Avg Loss: 0.017364,  Time: 0:53:00
Start evaluation on dev dataset.
Acc. (Correct/Total): 49.81% micro-Prec: 0.7539 micro-Recall:0.6445 micro-F1: 0.6949 dev loss: 0.041193
Start evaluation on test dataset.
Acc. (Correct/Total): 57.96% micro-Prec: 0.8145 micro-Recall:0.7042 micro-F1: 0.7553 dev loss: 0.036144
Epoch id: 9, Training steps: 100,  Train Loss: 0.0087,  Train Acc: 50.00%,  Train Avg Loss: 0.018842,  Time: 0:54:40
Epoch id: 9, Training steps: 200,  Train Loss: 0.0046,  Train Acc: 87.50%,  Train Avg Loss: 0.013669,  Time: 0:55:11
Epoch id: 9, Training steps: 300,  Train Loss: 0.0079,  Train Acc: 62.50%,  Train Avg Loss: 0.014396,  Time: 0:55:42
Epoch id: 9, Training steps: 400,  Train Loss: 0.0068,  Train Acc: 75.00%,  Train Avg Loss: 0.014024,  Time: 0:56:13
Epoch id: 9, Training steps: 500,  Train Loss: 0.014,  Train Acc: 50.00%,  Train Avg Loss: 0.014743,  Time: 0:56:44
Epoch id: 9, Training steps: 600,  Train Loss: 0.0075,  Train Acc: 50.00%,  Train Avg Loss: 0.014189,  Time: 0:57:15
Epoch id: 9, Training steps: 700,  Train Loss: 0.013,  Train Acc: 37.50%,  Train Avg Loss: 0.013191,  Time: 0:57:46
Epoch id: 9, Training steps: 800,  Train Loss: 0.0023,  Train Acc: 87.50%,  Train Avg Loss: 0.013212,  Time: 0:58:17
Epoch id: 9, Training steps: 900,  Train Loss:  0.01,  Train Acc: 62.50%,  Train Avg Loss: 0.014068,  Time: 0:58:48
Epoch id: 9, Training steps: 1000,  Train Loss: 0.024,  Train Acc: 25.00%,  Train Avg Loss: 0.013897,  Time: 0:59:19
Epoch id: 9, Training steps: 1100,  Train Loss: 0.011,  Train Acc: 87.50%,  Train Avg Loss: 0.013964,  Time: 0:59:50
Start evaluation on dev dataset.
Acc. (Correct/Total): 51.49% micro-Prec: 0.7716 micro-Recall:0.6607 micro-F1: 0.7119 dev loss: 0.039128
Start evaluation on test dataset.
Acc. (Correct/Total): 60.14% micro-Prec: 0.8161 micro-Recall:0.7245 micro-F1: 0.7676 dev loss: 0.033887
Epoch id: 10, Training steps: 100,  Train Loss: 0.021,  Train Acc: 62.50%,  Train Avg Loss: 0.019587,  Time: 1:01:30
Epoch id: 10, Training steps: 200,  Train Loss:  0.01,  Train Acc: 62.50%,  Train Avg Loss: 0.011340,  Time: 1:02:01
Epoch id: 10, Training steps: 300,  Train Loss: 0.0079,  Train Acc: 62.50%,  Train Avg Loss: 0.010951,  Time: 1:02:32
Epoch id: 10, Training steps: 400,  Train Loss: 0.0082,  Train Acc: 75.00%,  Train Avg Loss: 0.011916,  Time: 1:03:03
Epoch id: 10, Training steps: 500,  Train Loss: 0.011,  Train Acc: 62.50%,  Train Avg Loss: 0.010706,  Time: 1:03:34
Epoch id: 10, Training steps: 600,  Train Loss: 0.0069,  Train Acc: 62.50%,  Train Avg Loss: 0.011231,  Time: 1:04:05
Epoch id: 10, Training steps: 700,  Train Loss: 0.012,  Train Acc: 50.00%,  Train Avg Loss: 0.013170,  Time: 1:04:36
Epoch id: 10, Training steps: 800,  Train Loss: 0.013,  Train Acc: 37.50%,  Train Avg Loss: 0.011566,  Time: 1:05:07
Epoch id: 10, Training steps: 900,  Train Loss: 0.013,  Train Acc: 37.50%,  Train Avg Loss: 0.010680,  Time: 1:05:38
Epoch id: 10, Training steps: 1000,  Train Loss: 0.0069,  Train Acc: 62.50%,  Train Avg Loss: 0.011592,  Time: 1:06:09
Epoch id: 10, Training steps: 1100,  Train Loss: 0.0039,  Train Acc: 75.00%,  Train Avg Loss: 0.011342,  Time: 1:06:40
Start evaluation on dev dataset.
Acc. (Correct/Total): 52.50% micro-Prec: 0.7677 micro-Recall:0.6675 micro-F1: 0.7141 dev loss: 0.039425
Epoch id: 11, Training steps: 100,  Train Loss: 0.012,  Train Acc: 62.50%,  Train Avg Loss: 0.012107,  Time: 1:07:51
Epoch id: 11, Training steps: 200,  Train Loss: 0.004,  Train Acc: 75.00%,  Train Avg Loss: 0.008371,  Time: 1:08:22
Epoch id: 11, Training steps: 300,  Train Loss: 0.0059,  Train Acc: 62.50%,  Train Avg Loss: 0.008658,  Time: 1:08:53
Epoch id: 11, Training steps: 400,  Train Loss: 0.0053,  Train Acc: 75.00%,  Train Avg Loss: 0.007793,  Time: 1:09:24
Epoch id: 11, Training steps: 500,  Train Loss: 0.013,  Train Acc: 62.50%,  Train Avg Loss: 0.009317,  Time: 1:09:55
Epoch id: 11, Training steps: 600,  Train Loss: 0.014,  Train Acc: 62.50%,  Train Avg Loss: 0.008185,  Time: 1:10:26
Epoch id: 11, Training steps: 700,  Train Loss: 0.0086,  Train Acc: 37.50%,  Train Avg Loss: 0.008623,  Time: 1:10:57
Epoch id: 11, Training steps: 800,  Train Loss: 0.0088,  Train Acc: 62.50%,  Train Avg Loss: 0.009494,  Time: 1:11:28
Epoch id: 11, Training steps: 900,  Train Loss: 0.0055,  Train Acc: 75.00%,  Train Avg Loss: 0.008373,  Time: 1:11:59
Epoch id: 11, Training steps: 1000,  Train Loss: 0.011,  Train Acc: 75.00%,  Train Avg Loss: 0.009723,  Time: 1:12:30
Epoch id: 11, Training steps: 1100,  Train Loss: 0.0036,  Train Acc: 75.00%,  Train Avg Loss: 0.008891,  Time: 1:13:01
Start evaluation on dev dataset.
Acc. (Correct/Total): 51.01% micro-Prec: 0.7530 micro-Recall:0.6691 micro-F1: 0.7086 dev loss: 0.041674
Epoch id: 12, Training steps: 100,  Train Loss: 0.0059,  Train Acc: 75.00%,  Train Avg Loss: 0.010100,  Time: 1:14:11
Epoch id: 12, Training steps: 200,  Train Loss: 0.0038,  Train Acc: 75.00%,  Train Avg Loss: 0.006520,  Time: 1:14:42
Epoch id: 12, Training steps: 300,  Train Loss: 0.0093,  Train Acc: 62.50%,  Train Avg Loss: 0.006089,  Time: 1:15:13
Epoch id: 12, Training steps: 400,  Train Loss: 0.0081,  Train Acc: 75.00%,  Train Avg Loss: 0.006049,  Time: 1:15:44
Epoch id: 12, Training steps: 500,  Train Loss: 0.0046,  Train Acc: 75.00%,  Train Avg Loss: 0.006351,  Time: 1:16:15
Epoch id: 12, Training steps: 600,  Train Loss:  0.01,  Train Acc: 75.00%,  Train Avg Loss: 0.006594,  Time: 1:16:46
Epoch id: 12, Training steps: 700,  Train Loss: 0.0038,  Train Acc: 87.50%,  Train Avg Loss: 0.007217,  Time: 1:17:17
Epoch id: 12, Training steps: 800,  Train Loss: 0.0052,  Train Acc: 87.50%,  Train Avg Loss: 0.007630,  Time: 1:17:48
Epoch id: 12, Training steps: 900,  Train Loss: 0.013,  Train Acc: 50.00%,  Train Avg Loss: 0.007960,  Time: 1:18:20
Epoch id: 12, Training steps: 1000,  Train Loss: 0.0081,  Train Acc: 62.50%,  Train Avg Loss: 0.008523,  Time: 1:18:51
Epoch id: 12, Training steps: 1100,  Train Loss: 0.0051,  Train Acc: 87.50%,  Train Avg Loss: 0.008161,  Time: 1:19:22
Start evaluation on dev dataset.
Acc. (Correct/Total): 52.88% micro-Prec: 0.7605 micro-Recall:0.6918 micro-F1: 0.7245 dev loss: 0.039158
Epoch id: 13, Training steps: 100,  Train Loss: 0.0057,  Train Acc: 75.00%,  Train Avg Loss: 0.009179,  Time: 1:20:32
Epoch id: 13, Training steps: 200,  Train Loss: 0.0025,  Train Acc: 87.50%,  Train Avg Loss: 0.005533,  Time: 1:21:03
Epoch id: 13, Training steps: 300,  Train Loss: 0.003,  Train Acc: 87.50%,  Train Avg Loss: 0.005033,  Time: 1:21:34
Epoch id: 13, Training steps: 400,  Train Loss: 0.0033,  Train Acc: 75.00%,  Train Avg Loss: 0.005455,  Time: 1:22:05
Epoch id: 13, Training steps: 500,  Train Loss: 0.006,  Train Acc: 62.50%,  Train Avg Loss: 0.005440,  Time: 1:22:36
Epoch id: 13, Training steps: 600,  Train Loss: 0.0059,  Train Acc: 62.50%,  Train Avg Loss: 0.005552,  Time: 1:23:07
Epoch id: 13, Training steps: 700,  Train Loss: 0.0019,  Train Acc: 87.50%,  Train Avg Loss: 0.006213,  Time: 1:23:38
Epoch id: 13, Training steps: 800,  Train Loss: 0.0016,  Train Acc: 100.00%,  Train Avg Loss: 0.006375,  Time: 1:24:09
Epoch id: 13, Training steps: 900,  Train Loss: 0.0044,  Train Acc: 75.00%,  Train Avg Loss: 0.005687,  Time: 1:24:40
Epoch id: 13, Training steps: 1000,  Train Loss: 0.0078,  Train Acc: 62.50%,  Train Avg Loss: 0.006165,  Time: 1:25:11
Epoch id: 13, Training steps: 1100,  Train Loss: 0.0017,  Train Acc: 87.50%,  Train Avg Loss: 0.006455,  Time: 1:25:42
Start evaluation on dev dataset.
Acc. (Correct/Total): 53.45% micro-Prec: 0.7554 micro-Recall:0.7009 micro-F1: 0.7271 dev loss: 0.039498
Epoch id: 14, Training steps: 100,  Train Loss: 0.0088,  Train Acc: 62.50%,  Train Avg Loss: 0.007363,  Time: 1:26:53
Epoch id: 14, Training steps: 200,  Train Loss: 0.0038,  Train Acc: 87.50%,  Train Avg Loss: 0.004806,  Time: 1:27:24
Epoch id: 14, Training steps: 300,  Train Loss: 0.0021,  Train Acc: 87.50%,  Train Avg Loss: 0.004233,  Time: 1:27:55
Epoch id: 14, Training steps: 400,  Train Loss: 0.0025,  Train Acc: 87.50%,  Train Avg Loss: 0.004757,  Time: 1:28:26
Epoch id: 14, Training steps: 500,  Train Loss: 0.0054,  Train Acc: 50.00%,  Train Avg Loss: 0.004655,  Time: 1:28:57
Epoch id: 14, Training steps: 600,  Train Loss: 0.0065,  Train Acc: 75.00%,  Train Avg Loss: 0.004532,  Time: 1:29:28
Epoch id: 14, Training steps: 700,  Train Loss: 0.0046,  Train Acc: 87.50%,  Train Avg Loss: 0.004644,  Time: 1:29:59
Epoch id: 14, Training steps: 800,  Train Loss: 0.0036,  Train Acc: 75.00%,  Train Avg Loss: 0.004929,  Time: 1:30:30
Epoch id: 14, Training steps: 900,  Train Loss: 0.0031,  Train Acc: 87.50%,  Train Avg Loss: 0.004899,  Time: 1:31:01
Epoch id: 14, Training steps: 1000,  Train Loss: 0.011,  Train Acc: 62.50%,  Train Avg Loss: 0.004748,  Time: 1:31:32
Epoch id: 14, Training steps: 1100,  Train Loss: 0.0058,  Train Acc: 75.00%,  Train Avg Loss: 0.004784,  Time: 1:32:03
Start evaluation on dev dataset.
Acc. (Correct/Total): 52.45% micro-Prec: 0.7482 micro-Recall:0.6860 micro-F1: 0.7158 dev loss: 0.040299
Epoch id: 15, Training steps: 100,  Train Loss: 0.0041,  Train Acc: 87.50%,  Train Avg Loss: 0.005810,  Time: 1:33:14
Epoch id: 15, Training steps: 200,  Train Loss: 0.0017,  Train Acc: 100.00%,  Train Avg Loss: 0.004308,  Time: 1:33:45
Epoch id: 15, Training steps: 300,  Train Loss: 0.002,  Train Acc: 87.50%,  Train Avg Loss: 0.003826,  Time: 1:34:16
Epoch id: 15, Training steps: 400,  Train Loss: 0.0028,  Train Acc: 87.50%,  Train Avg Loss: 0.003991,  Time: 1:34:47
Epoch id: 15, Training steps: 500,  Train Loss: 0.0037,  Train Acc: 75.00%,  Train Avg Loss: 0.004176,  Time: 1:35:18
Epoch id: 15, Training steps: 600,  Train Loss: 0.0059,  Train Acc: 75.00%,  Train Avg Loss: 0.004701,  Time: 1:35:49
Epoch id: 15, Training steps: 700,  Train Loss: 0.0067,  Train Acc: 75.00%,  Train Avg Loss: 0.003884,  Time: 1:36:20
Epoch id: 15, Training steps: 800,  Train Loss: 0.0051,  Train Acc: 75.00%,  Train Avg Loss: 0.004649,  Time: 1:36:51
Epoch id: 15, Training steps: 900,  Train Loss: 0.0081,  Train Acc: 75.00%,  Train Avg Loss: 0.005255,  Time: 1:37:22
Epoch id: 15, Training steps: 1000,  Train Loss: 0.011,  Train Acc: 62.50%,  Train Avg Loss: 0.004790,  Time: 1:37:53
Epoch id: 15, Training steps: 1100,  Train Loss: 0.0025,  Train Acc: 100.00%,  Train Avg Loss: 0.004853,  Time: 1:38:24
Start evaluation on dev dataset.
Acc. (Correct/Total): 53.84% micro-Prec: 0.7428 micro-Recall:0.7135 micro-F1: 0.7279 dev loss: 0.039541
Epoch id: 16, Training steps: 100,  Train Loss: 0.0049,  Train Acc: 75.00%,  Train Avg Loss: 0.006178,  Time: 1:39:34
Epoch id: 16, Training steps: 200,  Train Loss: 0.0052,  Train Acc: 62.50%,  Train Avg Loss: 0.003401,  Time: 1:40:05
Epoch id: 16, Training steps: 300,  Train Loss: 0.0023,  Train Acc: 87.50%,  Train Avg Loss: 0.003081,  Time: 1:40:36
Epoch id: 16, Training steps: 400,  Train Loss: 0.00078,  Train Acc: 100.00%,  Train Avg Loss: 0.002994,  Time: 1:41:07
Epoch id: 16, Training steps: 500,  Train Loss: 0.003,  Train Acc: 100.00%,  Train Avg Loss: 0.003065,  Time: 1:41:38
Epoch id: 16, Training steps: 600,  Train Loss: 0.0064,  Train Acc: 87.50%,  Train Avg Loss: 0.003247,  Time: 1:42:09
Epoch id: 16, Training steps: 700,  Train Loss: 0.0026,  Train Acc: 75.00%,  Train Avg Loss: 0.003546,  Time: 1:42:40
Epoch id: 16, Training steps: 800,  Train Loss: 0.0061,  Train Acc: 75.00%,  Train Avg Loss: 0.003572,  Time: 1:43:11
Epoch id: 16, Training steps: 900,  Train Loss: 0.0021,  Train Acc: 100.00%,  Train Avg Loss: 0.002795,  Time: 1:43:42
Epoch id: 16, Training steps: 1000,  Train Loss: 0.0021,  Train Acc: 87.50%,  Train Avg Loss: 0.002870,  Time: 1:44:13
Epoch id: 16, Training steps: 1100,  Train Loss: 0.0057,  Train Acc: 75.00%,  Train Avg Loss: 0.003119,  Time: 1:44:44
Start evaluation on dev dataset.
Acc. (Correct/Total): 54.61% micro-Prec: 0.7551 micro-Recall:0.7096 micro-F1: 0.7316 dev loss: 0.039403
Epoch id: 17, Training steps: 100,  Train Loss: 0.003,  Train Acc: 87.50%,  Train Avg Loss: 0.003848,  Time: 1:45:55
Epoch id: 17, Training steps: 200,  Train Loss: 0.0028,  Train Acc: 75.00%,  Train Avg Loss: 0.002730,  Time: 1:46:26
Epoch id: 17, Training steps: 300,  Train Loss: 0.00061,  Train Acc: 100.00%,  Train Avg Loss: 0.002551,  Time: 1:46:57
Epoch id: 17, Training steps: 400,  Train Loss: 0.0028,  Train Acc: 87.50%,  Train Avg Loss: 0.002634,  Time: 1:47:28
Epoch id: 17, Training steps: 500,  Train Loss: 0.0058,  Train Acc: 87.50%,  Train Avg Loss: 0.002509,  Time: 1:47:59
Epoch id: 17, Training steps: 600,  Train Loss: 0.0021,  Train Acc: 87.50%,  Train Avg Loss: 0.002512,  Time: 1:48:30
Epoch id: 17, Training steps: 700,  Train Loss: 0.00066,  Train Acc: 100.00%,  Train Avg Loss: 0.002452,  Time: 1:49:01
Epoch id: 17, Training steps: 800,  Train Loss: 0.00093,  Train Acc: 100.00%,  Train Avg Loss: 0.002487,  Time: 1:49:32
Epoch id: 17, Training steps: 900,  Train Loss: 0.0044,  Train Acc: 75.00%,  Train Avg Loss: 0.002507,  Time: 1:50:03
Epoch id: 17, Training steps: 1000,  Train Loss: 0.0024,  Train Acc: 87.50%,  Train Avg Loss: 0.002838,  Time: 1:50:34
Epoch id: 17, Training steps: 1100,  Train Loss: 0.0013,  Train Acc: 87.50%,  Train Avg Loss: 0.002835,  Time: 1:51:05
Start evaluation on dev dataset.
Acc. (Correct/Total): 55.52% micro-Prec: 0.7627 micro-Recall:0.7158 micro-F1: 0.7385 dev loss: 0.037642
Start evaluation on test dataset.
Acc. (Correct/Total): 62.12% micro-Prec: 0.7960 micro-Recall:0.7507 micro-F1: 0.7727 dev loss: 0.032217
Epoch id: 18, Training steps: 100,  Train Loss: 0.0016,  Train Acc: 100.00%,  Train Avg Loss: 0.003109,  Time: 1:52:45
Epoch id: 18, Training steps: 200,  Train Loss: 0.0025,  Train Acc: 87.50%,  Train Avg Loss: 0.002183,  Time: 1:53:16
Epoch id: 18, Training steps: 300,  Train Loss: 0.00054,  Train Acc: 100.00%,  Train Avg Loss: 0.002096,  Time: 1:53:47
Epoch id: 18, Training steps: 400,  Train Loss: 0.0025,  Train Acc: 87.50%,  Train Avg Loss: 0.003248,  Time: 1:54:18
Epoch id: 18, Training steps: 500,  Train Loss: 0.0014,  Train Acc: 100.00%,  Train Avg Loss: 0.002318,  Time: 1:54:49
Epoch id: 18, Training steps: 600,  Train Loss: 0.00057,  Train Acc: 100.00%,  Train Avg Loss: 0.002508,  Time: 1:55:20
Epoch id: 18, Training steps: 700,  Train Loss: 0.001,  Train Acc: 100.00%,  Train Avg Loss: 0.002577,  Time: 1:55:51
Epoch id: 18, Training steps: 800,  Train Loss: 0.0009,  Train Acc: 100.00%,  Train Avg Loss: 0.002391,  Time: 1:56:22
Epoch id: 18, Training steps: 900,  Train Loss: 0.001,  Train Acc: 100.00%,  Train Avg Loss: 0.002506,  Time: 1:56:53
Epoch id: 18, Training steps: 1000,  Train Loss: 0.00039,  Train Acc: 100.00%,  Train Avg Loss: 0.002849,  Time: 1:57:24
Epoch id: 18, Training steps: 1100,  Train Loss: 0.0034,  Train Acc: 75.00%,  Train Avg Loss: 0.002827,  Time: 1:57:55
Start evaluation on dev dataset.
Acc. (Correct/Total): 53.93% micro-Prec: 0.7604 micro-Recall:0.7015 micro-F1: 0.7298 dev loss: 0.038052
Epoch id: 19, Training steps: 100,  Train Loss: 0.001,  Train Acc: 87.50%,  Train Avg Loss: 0.002313,  Time: 1:59:06
Epoch id: 19, Training steps: 200,  Train Loss: 0.001,  Train Acc: 100.00%,  Train Avg Loss: 0.002145,  Time: 1:59:37
Epoch id: 19, Training steps: 300,  Train Loss: 0.0022,  Train Acc: 75.00%,  Train Avg Loss: 0.001919,  Time: 2:00:08
Epoch id: 19, Training steps: 400,  Train Loss: 0.0012,  Train Acc: 100.00%,  Train Avg Loss: 0.001700,  Time: 2:00:39
Epoch id: 19, Training steps: 500,  Train Loss: 0.0021,  Train Acc: 87.50%,  Train Avg Loss: 0.001983,  Time: 2:01:10
Epoch id: 19, Training steps: 600,  Train Loss: 0.0027,  Train Acc: 62.50%,  Train Avg Loss: 0.001720,  Time: 2:01:41
Epoch id: 19, Training steps: 700,  Train Loss: 0.0015,  Train Acc: 87.50%,  Train Avg Loss: 0.001709,  Time: 2:02:12
Epoch id: 19, Training steps: 800,  Train Loss: 0.0018,  Train Acc: 87.50%,  Train Avg Loss: 0.002039,  Time: 2:02:43
Epoch id: 19, Training steps: 900,  Train Loss: 0.005,  Train Acc: 75.00%,  Train Avg Loss: 0.001919,  Time: 2:03:14
Epoch id: 19, Training steps: 1000,  Train Loss: 0.0011,  Train Acc: 87.50%,  Train Avg Loss: 0.002110,  Time: 2:03:45
Epoch id: 19, Training steps: 1100,  Train Loss: 0.0014,  Train Acc: 100.00%,  Train Avg Loss: 0.002066,  Time: 2:04:16
Start evaluation on dev dataset.
Acc. (Correct/Total): 55.61% micro-Prec: 0.7613 micro-Recall:0.7310 micro-F1: 0.7458 dev loss: 0.037530
Start evaluation on test dataset.
Acc. (Correct/Total): 61.10% micro-Prec: 0.7986 micro-Recall:0.7614 micro-F1: 0.7795 dev loss: 0.033079
Epoch id: 20, Training steps: 100,  Train Loss: 0.00031,  Train Acc: 100.00%,  Train Avg Loss: 0.002001,  Time: 2:05:55
Epoch id: 20, Training steps: 200,  Train Loss: 0.00037,  Train Acc: 100.00%,  Train Avg Loss: 0.001125,  Time: 2:06:26
Epoch id: 20, Training steps: 300,  Train Loss: 0.00084,  Train Acc: 100.00%,  Train Avg Loss: 0.001468,  Time: 2:06:57
Epoch id: 20, Training steps: 400,  Train Loss: 0.00028,  Train Acc: 100.00%,  Train Avg Loss: 0.001536,  Time: 2:07:28
Epoch id: 20, Training steps: 500,  Train Loss: 0.00063,  Train Acc: 100.00%,  Train Avg Loss: 0.001839,  Time: 2:07:59
Epoch id: 20, Training steps: 600,  Train Loss: 0.0012,  Train Acc: 87.50%,  Train Avg Loss: 0.001510,  Time: 2:08:30
Epoch id: 20, Training steps: 700,  Train Loss: 0.00068,  Train Acc: 100.00%,  Train Avg Loss: 0.001169,  Time: 2:09:01
Epoch id: 20, Training steps: 800,  Train Loss: 0.00046,  Train Acc: 100.00%,  Train Avg Loss: 0.001596,  Time: 2:09:32
Epoch id: 20, Training steps: 900,  Train Loss: 0.0011,  Train Acc: 100.00%,  Train Avg Loss: 0.001644,  Time: 2:10:03
Epoch id: 20, Training steps: 1000,  Train Loss: 0.00059,  Train Acc: 100.00%,  Train Avg Loss: 0.001442,  Time: 2:10:34
Epoch id: 20, Training steps: 1100,  Train Loss: 0.00056,  Train Acc: 100.00%,  Train Avg Loss: 0.001573,  Time: 2:11:05
Start evaluation on dev dataset.
Acc. (Correct/Total): 55.47% micro-Prec: 0.7455 micro-Recall:0.7329 micro-F1: 0.7391 dev loss: 0.039950
Start evaluation on test dataset.
The number of evaluation instances:  2067
Acc. (Correct/Total): 61.97% micro-Prec: 0.7814 micro-Recall:0.7756 micro-F1: 0.7785 dev loss: 0.033509
              precision    recall  f1-score   support

         教育学     0.8382    0.9461    0.8889       241
          法学     0.8204    0.8973    0.8571       224
      中国语言文学     0.8020    0.8541    0.8272       185
         政治学     0.7785    0.7546    0.7664       163
         社会学     0.8446    0.7962    0.8197       157
         心理学     0.8152    0.6098    0.6977       123
       应用经济学     0.7439    0.5214    0.6131       117
         历史学     0.7400    0.6789    0.7081       109
     环境科学与工程     0.8468    0.8704    0.8584       108
          哲学     0.8507    0.5876    0.6951        97
      外国语言文学     0.8514    0.7412    0.7925        85
         生物学     0.7423    0.9114    0.8182        79
      交通运输工程     0.8750    0.9872    0.9277        78
        临床医学     0.8077    0.8289    0.8182        76
    计算机科学与技术     0.7722    0.8592    0.8133        71
        土木工程     0.8649    0.9697    0.9143        66
   航空宇航科学与技术     0.9508    0.9508    0.9508        61
         民族学     0.6034    0.6364    0.6195        55
   公共卫生与预防医学     0.5965    0.6667    0.6296        51
         美术学     0.8750    0.9800    0.9245        50
         艺术学     0.7347    0.8372    0.7826        43
         地理学     0.7500    0.7143    0.7317        42
         体育学     0.8235    0.7000    0.7568        40
       理论经济学     0.6750    0.7105    0.6923        38
         中医学     0.9032    0.7568    0.8235        37
         物理学     0.8049    0.9167    0.8571        36
          林学     0.6667    0.6061    0.6349        33
          数学     0.8636    0.5938    0.7037        32
     电子科学与技术     0.5676    0.6774    0.6176        31
        基础医学     0.5926    0.5517    0.5714        29
        工商管理     0.9474    0.6667    0.7826        27
       新闻传播学     0.7826    0.8182    0.8000        22
         天文学     0.6923    0.8182    0.7500        22
         地质学     0.8824    0.7143    0.7895        21
         畜牧学     0.8636    0.9048    0.8837        21
   军事思想及军事历史     0.8333    0.7500    0.7895        20
     管理科学与工程     0.5833    0.7778    0.6667        18
     测绘科学与技术     0.8000    0.7059    0.7500        17
        水利工程     0.9000    0.5625    0.6923        16
        大气科学     0.5909    0.8125    0.6842        16
     兵器科学与技术     0.6000    0.8000    0.6857        15
       地球物理学     0.7143    0.3571    0.4762        14
        电气工程     1.0000    0.5385    0.7000        13
         作物学     0.7000    0.5385    0.6087        13
     控制科学与工程     0.2778    0.3846    0.3226        13
     信息与通信工程     0.5000    0.5385    0.5185        13
        公共管理     0.2500    0.3077    0.2759        13
         建筑学     1.0000    0.3077    0.4706        13
     化学工程与技术     0.6471    0.9167    0.7586        12
          力学     0.9000    0.8182    0.8571        11
        海洋科学     1.0000    0.9091    0.9524        11
     轻工技术与工程     0.3846    0.4545    0.4167        11
        农业工程     0.8000    0.4000    0.5333        10
         园艺学     0.8333    1.0000    0.9091        10
       中西医结合     1.0000    0.6000    0.7500        10
        机械工程     0.8182    1.0000    0.9000         9
       科学技术史     1.0000    0.6250    0.7692         8
     船舶与海洋工程     0.8889    1.0000    0.9412         8
   图书情报与档案管理     0.6250    0.6250    0.6250         8
        植物保护     0.8000    1.0000    0.8889         8
     材料科学与工程     0.8571    0.7500    0.8000         8
         统计学     0.5385    0.8750    0.6667         8
          化学     0.7000    0.8750    0.7778         8
     食品科学与工程     1.0000    0.5000    0.6667         8
          水产     1.0000    1.0000    1.0000         7
          药学     1.0000    0.8571    0.9231         7
     农业资源与环境     1.0000    0.2857    0.4444         7
         世界史     0.4615    0.8571    0.6000         7
        系统科学     0.8750    1.0000    0.9333         7
      农林经济管理     0.2857    0.8000    0.4211         5
       军队指挥学     1.0000    0.6000    0.7500         5
        矿业工程     0.7500    0.6000    0.6667         5
     纺织科学与工程     0.7143    1.0000    0.8333         5
  动力工程及工程热物理     0.0000    0.0000    0.0000         4
        林业工程     0.5000    0.2500    0.3333         4
     仪器科学与技术     0.0000    0.0000    0.0000         3
         战略学     0.4286    1.0000    0.6000         3
   地质资源与地质工程     0.5000    1.0000    0.6667         3
        旅游管理     0.6667    0.6667    0.6667         3
 图书馆、情报与档案管理     0.0000    0.0000    0.0000         2
        冶金工程     1.0000    0.5000    0.6667         2
      核科学与技术     0.0000    0.0000    0.0000         2

   micro avg     0.7814    0.7756    0.7785      3093
   macro avg     0.7231    0.6973    0.6887      3093
weighted avg     0.7887    0.7756    0.7739      3093
 samples avg     0.7935    0.7906    0.7782      3093

Final evaluation on the test dataset.
The number of evaluation instances:  2067
Acc. (Correct/Total): 61.10% micro-Prec: 0.7986 micro-Recall:0.7614 micro-F1: 0.7795 dev loss: 0.033079
              precision    recall  f1-score   support

         教育学     0.8382    0.9461    0.8889       241
          法学     0.8277    0.8795    0.8528       224
      中国语言文学     0.8196    0.8595    0.8391       185
         政治学     0.8583    0.6319    0.7279       163
         社会学     0.7840    0.8089    0.7962       157
         心理学     0.8132    0.6016    0.6916       123
       应用经济学     0.7838    0.4957    0.6073       117
         历史学     0.7935    0.6697    0.7264       109
     环境科学与工程     0.8611    0.8611    0.8611       108
          哲学     0.8548    0.5464    0.6667        97
      外国语言文学     0.8667    0.7647    0.8125        85
         生物学     0.7273    0.9114    0.8090        79
      交通运输工程     0.9367    0.9487    0.9427        78
        临床医学     0.9333    0.7368    0.8235        76
    计算机科学与技术     0.8333    0.8451    0.8392        71
        土木工程     0.8873    0.9545    0.9197        66
   航空宇航科学与技术     0.9661    0.9344    0.9500        61
         民族学     0.6889    0.5636    0.6200        55
   公共卫生与预防医学     0.6140    0.6863    0.6481        51
         美术学     0.7692    1.0000    0.8696        50
         艺术学     0.6852    0.8605    0.7629        43
         地理学     0.7838    0.6905    0.7342        42
         体育学     0.7500    0.7500    0.7500        40
       理论经济学     0.7778    0.7368    0.7568        38
         中医学     0.9333    0.7568    0.8358        37
         物理学     0.8095    0.9444    0.8718        36
          林学     0.7037    0.5758    0.6333        33
          数学     0.8125    0.4062    0.5417        32
     电子科学与技术     0.6667    0.6452    0.6557        31
        基础医学     0.4688    0.5172    0.4918        29
        工商管理     0.7000    0.7778    0.7368        27
       新闻传播学     0.8095    0.7727    0.7907        22
         天文学     0.7917    0.8636    0.8261        22
         地质学     0.8750    0.6667    0.7568        21
         畜牧学     0.8636    0.9048    0.8837        21
   军事思想及军事历史     0.7619    0.8000    0.7805        20
     管理科学与工程     0.6000    0.8333    0.6977        18
     测绘科学与技术     0.8000    0.7059    0.7500        17
        水利工程     0.9167    0.6875    0.7857        16
        大气科学     0.6667    0.7500    0.7059        16
     兵器科学与技术     0.7059    0.8000    0.7500        15
       地球物理学     0.8333    0.3571    0.5000        14
        电气工程     1.0000    0.6154    0.7619        13
         作物学     0.6667    0.4615    0.5455        13
     控制科学与工程     0.2174    0.3846    0.2778        13
     信息与通信工程     0.6364    0.5385    0.5833        13
        公共管理     0.3077    0.3077    0.3077        13
         建筑学     1.0000    0.2308    0.3750        13
     化学工程与技术     0.7692    0.8333    0.8000        12
          力学     0.8750    0.6364    0.7368        11
        海洋科学     0.8462    1.0000    0.9167        11
     轻工技术与工程     0.4286    0.5455    0.4800        11
        农业工程     0.8333    0.5000    0.6250        10
         园艺学     0.8182    0.9000    0.8571        10
       中西医结合     1.0000    0.6000    0.7500        10
        机械工程     1.0000    0.8889    0.9412         9
       科学技术史     1.0000    0.6250    0.7692         8
     船舶与海洋工程     0.8889    1.0000    0.9412         8
   图书情报与档案管理     0.7000    0.8750    0.7778         8
        植物保护     0.8889    1.0000    0.9412         8
     材料科学与工程     0.6667    0.7500    0.7059         8
         统计学     0.5833    0.8750    0.7000         8
          化学     1.0000    0.7500    0.8571         8
     食品科学与工程     1.0000    0.3750    0.5455         8
          水产     1.0000    1.0000    1.0000         7
          药学     1.0000    0.8571    0.9231         7
     农业资源与环境     1.0000    0.5714    0.7273         7
         世界史     0.6667    0.8571    0.7500         7
        系统科学     0.8333    0.7143    0.7692         7
      农林经济管理     0.4444    0.8000    0.5714         5
       军队指挥学     1.0000    0.6000    0.7500         5
        矿业工程     0.8000    0.8000    0.8000         5
     纺织科学与工程     0.7143    1.0000    0.8333         5
  动力工程及工程热物理     0.0000    0.0000    0.0000         4
        林业工程     0.5000    0.2500    0.3333         4
     仪器科学与技术     0.0000    0.0000    0.0000         3
         战略学     0.7500    1.0000    0.8571         3
   地质资源与地质工程     0.4286    1.0000    0.6000         3
        旅游管理     1.0000    1.0000    1.0000         3
 图书馆、情报与档案管理     0.0000    0.0000    0.0000         2
        冶金工程     1.0000    0.5000    0.6667         2
      核科学与技术     1.0000    0.5000    0.6667         2

   micro avg     0.7986    0.7614    0.7795      3093
   macro avg     0.7614    0.7023    0.7114      3093
weighted avg     0.8061    0.7614    0.7733      3093
 samples avg     0.7905    0.7761    0.7691      3093


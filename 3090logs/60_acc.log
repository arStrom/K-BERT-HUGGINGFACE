nohup: ignoring input
  0%|          | 0/82 [00:00<?, ?it/s]100%|██████████| 82/82 [00:00<00:00, 1482469.52it/s]
model:  ernie-rcnn-catlstmwide
pretrained:  ernie1
task:  MLC-slice
dataset:  book_multilabels_task_slice
seq_length:  256
hidden_dropout_prob:  0.1
attention_probs_dropout_prob:  0.1
epochs_num:  20
batch_size:  8
learning_rate:  2e-05
report_steps:  100
kg_name:  CnDbpedia
no_kg:  True
no_vm:  True
GPU:  NVIDIA GeForce RTX 3090
Vocabulary Size:  17964
[BertClassifier] use visible_matrix: False
Some weights of ErnieRCNNForMultiLabelSequenceClassificationSliceCatLSTMWide were not initialized from the model checkpoint at ./models/ernie1 and are newly initialized: ['lstm.bias_ih_l0', 'lstm.weight_ih_l0', 'lstm.weight_ih_l0_reverse', 'output_layer_1.bias', 'lstm.bias_ih_l1_reverse', 'lstm.bias_hh_l0', 'lstm.bias_ih_l0_reverse', 'classifier.weight', 'lstm.weight_hh_l0_reverse', 'lstm.weight_hh_l1', 'lstm.weight_ih_l1', 'classifier.bias', 'output_layer_1.weight', 'lstm.bias_hh_l1_reverse', 'lstm.weight_hh_l1_reverse', 'lstm.weight_ih_l1_reverse', 'lstm.weight_hh_l0', 'lstm.bias_ih_l1', 'lstm.bias_hh_l0_reverse', 'lstm.bias_hh_l1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
1 GPUs are available. Let's use them.
device:  cuda
Start training.
Loading sentences from ./datasets/book_multilabels_task_slice/train.tsv
There are 9097 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/9097
Loading sentences from ./datasets/book_multilabels_task_slice/dev.tsv
There are 2084 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/2084
Loading sentences from ./datasets/book_multilabels_task_slice/test.tsv
There are 2067 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/2067
Epoch id: 1, Training steps: 100, Train Acc:  0.00%, Train Loss: 0.077297, Train Avg Loss: 0.173891, Time: 0:01:06
Epoch id: 1, Training steps: 200, Train Acc:  0.00%, Train Loss: 0.080805, Train Avg Loss: 0.085244, Time: 0:02:11
Epoch id: 1, Training steps: 300, Train Acc:  0.00%, Train Loss: 0.076645, Train Avg Loss: 0.083539, Time: 0:03:17
Epoch id: 1, Training steps: 400, Train Acc:  0.00%, Train Loss: 0.069032, Train Avg Loss: 0.084321, Time: 0:04:22
Epoch id: 1, Training steps: 500, Train Acc:  0.00%, Train Loss: 0.092322, Train Avg Loss: 0.082764, Time: 0:05:27
Epoch id: 1, Training steps: 600, Train Acc:  0.00%, Train Loss: 0.084443, Train Avg Loss: 0.084300, Time: 0:06:29
Epoch id: 1, Training steps: 700, Train Acc:  0.00%, Train Loss: 0.099178, Train Avg Loss: 0.084300, Time: 0:07:34
Epoch id: 1, Training steps: 800, Train Acc:  0.00%, Train Loss: 0.084405, Train Avg Loss: 0.082865, Time: 0:08:40
Epoch id: 1, Training steps: 900, Train Acc:  0.00%, Train Loss: 0.085157, Train Avg Loss: 0.080945, Time: 0:09:45
Epoch id: 1, Training steps: 1000, Train Acc:  0.00%, Train Loss: 0.097697, Train Avg Loss: 0.080810, Time: 0:10:51
Epoch id: 1, Training steps: 1100, Train Acc:  0.00%, Train Loss: 0.075840, Train Avg Loss: 0.080668, Time: 0:11:57
Start evaluation on dev dataset.
Acc. (Correct/Total):  0.00% micro-Prec: 0.0000 micro-Recall:0.0000 micro-F1: 0.0000 dev loss: 0.100790
Epoch id: 2, Training steps: 100, Train Acc:  0.00%, Train Loss: 0.078238, Train Avg Loss: 0.106784, Time: 0:14:28
Epoch id: 2, Training steps: 200, Train Acc:  0.00%, Train Loss: 0.068220, Train Avg Loss: 0.076321, Time: 0:15:33
Epoch id: 2, Training steps: 300, Train Acc:  0.00%, Train Loss: 0.063349, Train Avg Loss: 0.074069, Time: 0:16:39
Epoch id: 2, Training steps: 400, Train Acc:  0.00%, Train Loss: 0.060069, Train Avg Loss: 0.071623, Time: 0:17:44
Epoch id: 2, Training steps: 500, Train Acc:  0.00%, Train Loss: 0.067821, Train Avg Loss: 0.066203, Time: 0:18:50
Epoch id: 2, Training steps: 600, Train Acc:  0.00%, Train Loss: 0.064380, Train Avg Loss: 0.066629, Time: 0:19:54
Epoch id: 2, Training steps: 700, Train Acc:  0.00%, Train Loss: 0.077428, Train Avg Loss: 0.063399, Time: 0:20:59
Epoch id: 2, Training steps: 800, Train Acc:  0.00%, Train Loss: 0.063235, Train Avg Loss: 0.061182, Time: 0:22:05
Epoch id: 2, Training steps: 900, Train Acc:  0.00%, Train Loss: 0.050448, Train Avg Loss: 0.055722, Time: 0:23:11
Epoch id: 2, Training steps: 1000, Train Acc: 12.50%, Train Loss: 0.052271, Train Avg Loss: 0.052275, Time: 0:24:17
Epoch id: 2, Training steps: 1100, Train Acc:  0.00%, Train Loss: 0.043922, Train Avg Loss: 0.051245, Time: 0:25:23
Start evaluation on dev dataset.
Acc. (Correct/Total): 19.43% micro-Prec: 0.8125 micro-Recall:0.2399 micro-F1: 0.3704 dev loss: 0.067669
Start evaluation on test dataset.
Acc. (Correct/Total): 23.27% micro-Prec: 0.8664 micro-Recall:0.2768 micro-F1: 0.4195 dev loss: 0.064372
Epoch id: 3, Training steps: 100, Train Acc: 25.00%, Train Loss: 0.038596, Train Avg Loss: 0.062758, Time: 0:28:55
Epoch id: 3, Training steps: 200, Train Acc: 25.00%, Train Loss: 0.032652, Train Avg Loss: 0.043692, Time: 0:30:01
Epoch id: 3, Training steps: 300, Train Acc: 37.50%, Train Loss: 0.028105, Train Avg Loss: 0.041507, Time: 0:31:07
Epoch id: 3, Training steps: 400, Train Acc: 25.00%, Train Loss: 0.039180, Train Avg Loss: 0.038684, Time: 0:32:13
Epoch id: 3, Training steps: 500, Train Acc: 37.50%, Train Loss: 0.039174, Train Avg Loss: 0.038576, Time: 0:33:17
Epoch id: 3, Training steps: 600, Train Acc: 25.00%, Train Loss: 0.042614, Train Avg Loss: 0.035396, Time: 0:34:22
Epoch id: 3, Training steps: 700, Train Acc:  0.00%, Train Loss: 0.047685, Train Avg Loss: 0.034948, Time: 0:35:28
Epoch id: 3, Training steps: 800, Train Acc: 37.50%, Train Loss: 0.043865, Train Avg Loss: 0.031569, Time: 0:36:34
Epoch id: 3, Training steps: 900, Train Acc: 25.00%, Train Loss: 0.029469, Train Avg Loss: 0.034538, Time: 0:37:40
Epoch id: 3, Training steps: 1000, Train Acc: 37.50%, Train Loss: 0.033993, Train Avg Loss: 0.030518, Time: 0:38:46
Epoch id: 3, Training steps: 1100, Train Acc: 12.50%, Train Loss: 0.039216, Train Avg Loss: 0.031148, Time: 0:39:52
Start evaluation on dev dataset.
Acc. (Correct/Total): 33.54% micro-Prec: 0.8133 micro-Recall:0.4034 micro-F1: 0.5393 dev loss: 0.051418
Start evaluation on test dataset.
Acc. (Correct/Total): 39.43% micro-Prec: 0.8698 micro-Recall:0.4620 micro-F1: 0.6035 dev loss: 0.047300
Epoch id: 4, Training steps: 100, Train Acc: 25.00%, Train Loss: 0.035957, Train Avg Loss: 0.038034, Time: 0:43:24
Epoch id: 4, Training steps: 200, Train Acc: 12.50%, Train Loss: 0.027896, Train Avg Loss: 0.028136, Time: 0:44:29
Epoch id: 4, Training steps: 300, Train Acc: 25.00%, Train Loss: 0.041344, Train Avg Loss: 0.025717, Time: 0:45:35
Epoch id: 4, Training steps: 400, Train Acc: 37.50%, Train Loss: 0.030581, Train Avg Loss: 0.026843, Time: 0:46:39
Epoch id: 4, Training steps: 500, Train Acc: 12.50%, Train Loss: 0.035973, Train Avg Loss: 0.025659, Time: 0:47:45
Epoch id: 4, Training steps: 600, Train Acc: 25.00%, Train Loss: 0.031934, Train Avg Loss: 0.024092, Time: 0:48:50
Epoch id: 4, Training steps: 700, Train Acc: 50.00%, Train Loss: 0.012554, Train Avg Loss: 0.024483, Time: 0:49:56
Epoch id: 4, Training steps: 800, Train Acc: 37.50%, Train Loss: 0.036556, Train Avg Loss: 0.024568, Time: 0:51:01
Epoch id: 4, Training steps: 900, Train Acc: 25.00%, Train Loss: 0.044986, Train Avg Loss: 0.023355, Time: 0:52:07
Epoch id: 4, Training steps: 1000, Train Acc: 62.50%, Train Loss: 0.029069, Train Avg Loss: 0.023734, Time: 0:53:13
Epoch id: 4, Training steps: 1100, Train Acc: 50.00%, Train Loss: 0.020011, Train Avg Loss: 0.025107, Time: 0:54:18
Start evaluation on dev dataset.
Acc. (Correct/Total): 38.68% micro-Prec: 0.8123 micro-Recall:0.4791 micro-F1: 0.6027 dev loss: 0.045225
Start evaluation on test dataset.
Acc. (Correct/Total): 46.83% micro-Prec: 0.8637 micro-Recall:0.5509 micro-F1: 0.6727 dev loss: 0.040652
Epoch id: 5, Training steps: 100, Train Acc: 37.50%, Train Loss: 0.020903, Train Avg Loss: 0.029654, Time: 0:57:49
Epoch id: 5, Training steps: 200, Train Acc: 62.50%, Train Loss: 0.006989, Train Avg Loss: 0.019840, Time: 0:58:55
Epoch id: 5, Training steps: 300, Train Acc: 37.50%, Train Loss: 0.028148, Train Avg Loss: 0.019326, Time: 0:59:59
Epoch id: 5, Training steps: 400, Train Acc: 62.50%, Train Loss: 0.008741, Train Avg Loss: 0.019077, Time: 1:01:04
Epoch id: 5, Training steps: 500, Train Acc: 25.00%, Train Loss: 0.019102, Train Avg Loss: 0.018198, Time: 1:02:10
Epoch id: 5, Training steps: 600, Train Acc: 37.50%, Train Loss: 0.028674, Train Avg Loss: 0.019402, Time: 1:03:16
Epoch id: 5, Training steps: 700, Train Acc: 25.00%, Train Loss: 0.037922, Train Avg Loss: 0.020022, Time: 1:04:22
Epoch id: 5, Training steps: 800, Train Acc: 75.00%, Train Loss: 0.007491, Train Avg Loss: 0.017801, Time: 1:05:27
Epoch id: 5, Training steps: 900, Train Acc: 25.00%, Train Loss: 0.031297, Train Avg Loss: 0.017791, Time: 1:06:33
Epoch id: 5, Training steps: 1000, Train Acc: 50.00%, Train Loss: 0.014111, Train Avg Loss: 0.019128, Time: 1:07:39
Epoch id: 5, Training steps: 1100, Train Acc: 62.50%, Train Loss: 0.014394, Train Avg Loss: 0.018049, Time: 1:08:45
Start evaluation on dev dataset.
Acc. (Correct/Total): 43.33% micro-Prec: 0.7690 micro-Recall:0.5549 micro-F1: 0.6446 dev loss: 0.044995
Start evaluation on test dataset.
Acc. (Correct/Total): 53.94% micro-Prec: 0.8431 micro-Recall:0.6356 micro-F1: 0.7248 dev loss: 0.039410
Epoch id: 6, Training steps: 100, Train Acc: 75.00%, Train Loss: 0.015419, Train Avg Loss: 0.021892, Time: 1:12:17
Epoch id: 6, Training steps: 200, Train Acc: 75.00%, Train Loss: 0.004893, Train Avg Loss: 0.015004, Time: 1:13:22
Epoch id: 6, Training steps: 300, Train Acc: 87.50%, Train Loss: 0.013722, Train Avg Loss: 0.014203, Time: 1:14:27
Epoch id: 6, Training steps: 400, Train Acc: 50.00%, Train Loss: 0.022954, Train Avg Loss: 0.014082, Time: 1:15:32
Epoch id: 6, Training steps: 500, Train Acc: 25.00%, Train Loss: 0.011127, Train Avg Loss: 0.014139, Time: 1:16:38
Epoch id: 6, Training steps: 600, Train Acc: 37.50%, Train Loss: 0.014909, Train Avg Loss: 0.014721, Time: 1:17:44
Epoch id: 6, Training steps: 700, Train Acc: 25.00%, Train Loss: 0.031622, Train Avg Loss: 0.013885, Time: 1:18:50
Epoch id: 6, Training steps: 800, Train Acc: 50.00%, Train Loss: 0.012748, Train Avg Loss: 0.016484, Time: 1:19:56
Epoch id: 6, Training steps: 900, Train Acc: 50.00%, Train Loss: 0.015139, Train Avg Loss: 0.015039, Time: 1:21:01
Epoch id: 6, Training steps: 1000, Train Acc: 50.00%, Train Loss: 0.013380, Train Avg Loss: 0.015206, Time: 1:22:07
Epoch id: 6, Training steps: 1100, Train Acc: 37.50%, Train Loss: 0.013092, Train Avg Loss: 0.013729, Time: 1:23:13
Start evaluation on dev dataset.
Acc. (Correct/Total): 47.60% micro-Prec: 0.7921 micro-Recall:0.5872 micro-F1: 0.6745 dev loss: 0.041983
Start evaluation on test dataset.
Acc. (Correct/Total): 55.83% micro-Prec: 0.8473 micro-Recall:0.6654 micro-F1: 0.7454 dev loss: 0.036603
Epoch id: 7, Training steps: 100, Train Acc: 62.50%, Train Loss: 0.006598, Train Avg Loss: 0.017168, Time: 1:26:43
Epoch id: 7, Training steps: 200, Train Acc: 75.00%, Train Loss: 0.012490, Train Avg Loss: 0.009668, Time: 1:27:48
Epoch id: 7, Training steps: 300, Train Acc: 25.00%, Train Loss: 0.019160, Train Avg Loss: 0.010709, Time: 1:28:54
Epoch id: 7, Training steps: 400, Train Acc: 37.50%, Train Loss: 0.014229, Train Avg Loss: 0.012530, Time: 1:29:59
Epoch id: 7, Training steps: 500, Train Acc: 75.00%, Train Loss: 0.006208, Train Avg Loss: 0.011323, Time: 1:31:05
Epoch id: 7, Training steps: 600, Train Acc: 75.00%, Train Loss: 0.006891, Train Avg Loss: 0.012373, Time: 1:32:11
Epoch id: 7, Training steps: 700, Train Acc: 75.00%, Train Loss: 0.006185, Train Avg Loss: 0.010741, Time: 1:33:16
Epoch id: 7, Training steps: 800, Train Acc: 37.50%, Train Loss: 0.011831, Train Avg Loss: 0.012177, Time: 1:34:22
Epoch id: 7, Training steps: 900, Train Acc: 75.00%, Train Loss: 0.011961, Train Avg Loss: 0.010882, Time: 1:35:27
Epoch id: 7, Training steps: 1000, Train Acc: 87.50%, Train Loss: 0.003634, Train Avg Loss: 0.010443, Time: 1:36:33
Epoch id: 7, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.012805, Train Avg Loss: 0.012090, Time: 1:37:39
Start evaluation on dev dataset.
Acc. (Correct/Total): 49.42% micro-Prec: 0.7829 micro-Recall:0.6267 micro-F1: 0.6962 dev loss: 0.039786
Start evaluation on test dataset.
Acc. (Correct/Total): 58.64% micro-Prec: 0.8450 micro-Recall:0.7035 micro-F1: 0.7678 dev loss: 0.034119
Epoch id: 8, Training steps: 100, Train Acc: 62.50%, Train Loss: 0.008782, Train Avg Loss: 0.015148, Time: 1:41:08
Epoch id: 8, Training steps: 200, Train Acc: 87.50%, Train Loss: 0.003235, Train Avg Loss: 0.008605, Time: 1:42:14
Epoch id: 8, Training steps: 300, Train Acc: 87.50%, Train Loss: 0.003301, Train Avg Loss: 0.008500, Time: 1:43:20
Epoch id: 8, Training steps: 400, Train Acc: 62.50%, Train Loss: 0.007934, Train Avg Loss: 0.008317, Time: 1:44:26
Epoch id: 8, Training steps: 500, Train Acc: 37.50%, Train Loss: 0.014450, Train Avg Loss: 0.007899, Time: 1:45:31
Epoch id: 8, Training steps: 600, Train Acc: 50.00%, Train Loss: 0.008013, Train Avg Loss: 0.009207, Time: 1:46:37
Epoch id: 8, Training steps: 700, Train Acc: 62.50%, Train Loss: 0.009856, Train Avg Loss: 0.008397, Time: 1:47:43
Epoch id: 8, Training steps: 800, Train Acc: 62.50%, Train Loss: 0.014332, Train Avg Loss: 0.009405, Time: 1:48:49
Epoch id: 8, Training steps: 900, Train Acc: 62.50%, Train Loss: 0.008604, Train Avg Loss: 0.009086, Time: 1:49:55
Epoch id: 8, Training steps: 1000, Train Acc: 62.50%, Train Loss: 0.012385, Train Avg Loss: 0.009711, Time: 1:51:00
Epoch id: 8, Training steps: 1100, Train Acc: 75.00%, Train Loss: 0.004270, Train Avg Loss: 0.009133, Time: 1:52:06
Start evaluation on dev dataset.
Acc. (Correct/Total): 50.19% micro-Prec: 0.7645 micro-Recall:0.6297 micro-F1: 0.6906 dev loss: 0.039907
Start evaluation on test dataset.
Acc. (Correct/Total): 59.46% micro-Prec: 0.8257 micro-Recall:0.7155 micro-F1: 0.7667 dev loss: 0.034129
Epoch id: 9, Training steps: 100, Train Acc: 62.50%, Train Loss: 0.004688, Train Avg Loss: 0.008858, Time: 1:55:36
Epoch id: 9, Training steps: 200, Train Acc: 87.50%, Train Loss: 0.002917, Train Avg Loss: 0.006411, Time: 1:56:42
Epoch id: 9, Training steps: 300, Train Acc: 87.50%, Train Loss: 0.002849, Train Avg Loss: 0.006653, Time: 1:57:48
Epoch id: 9, Training steps: 400, Train Acc: 100.00%, Train Loss: 0.001494, Train Avg Loss: 0.006697, Time: 1:58:53
Epoch id: 9, Training steps: 500, Train Acc: 87.50%, Train Loss: 0.002714, Train Avg Loss: 0.006869, Time: 1:59:59
Epoch id: 9, Training steps: 600, Train Acc: 87.50%, Train Loss: 0.003821, Train Avg Loss: 0.006990, Time: 2:01:05
Epoch id: 9, Training steps: 700, Train Acc: 75.00%, Train Loss: 0.004261, Train Avg Loss: 0.006942, Time: 2:02:10
Epoch id: 9, Training steps: 800, Train Acc: 87.50%, Train Loss: 0.001854, Train Avg Loss: 0.006857, Time: 2:03:16
Epoch id: 9, Training steps: 900, Train Acc: 75.00%, Train Loss: 0.007219, Train Avg Loss: 0.007690, Time: 2:04:21
Epoch id: 9, Training steps: 1000, Train Acc: 62.50%, Train Loss: 0.009279, Train Avg Loss: 0.007896, Time: 2:05:27
Epoch id: 9, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.003731, Train Avg Loss: 0.006921, Time: 2:06:32
Start evaluation on dev dataset.
Acc. (Correct/Total): 52.69% micro-Prec: 0.7815 micro-Recall:0.6611 micro-F1: 0.7162 dev loss: 0.038797
Start evaluation on test dataset.
Acc. (Correct/Total): 61.01% micro-Prec: 0.8226 micro-Recall:0.7284 micro-F1: 0.7726 dev loss: 0.033600
Epoch id: 10, Training steps: 100, Train Acc: 62.50%, Train Loss: 0.010258, Train Avg Loss: 0.008800, Time: 2:08:12
Epoch id: 10, Training steps: 200, Train Acc: 62.50%, Train Loss: 0.009421, Train Avg Loss: 0.004976, Time: 2:08:43
Epoch id: 10, Training steps: 300, Train Acc: 87.50%, Train Loss: 0.003161, Train Avg Loss: 0.004965, Time: 2:09:14
Epoch id: 10, Training steps: 400, Train Acc: 75.00%, Train Loss: 0.003746, Train Avg Loss: 0.005022, Time: 2:09:46
Epoch id: 10, Training steps: 500, Train Acc: 75.00%, Train Loss: 0.005527, Train Avg Loss: 0.004820, Time: 2:10:17
Epoch id: 10, Training steps: 600, Train Acc: 100.00%, Train Loss: 0.002988, Train Avg Loss: 0.004300, Time: 2:10:48
Epoch id: 10, Training steps: 700, Train Acc: 75.00%, Train Loss: 0.004795, Train Avg Loss: 0.005629, Time: 2:11:19
Epoch id: 10, Training steps: 800, Train Acc: 62.50%, Train Loss: 0.010126, Train Avg Loss: 0.005232, Time: 2:11:51
Epoch id: 10, Training steps: 900, Train Acc: 75.00%, Train Loss: 0.008853, Train Avg Loss: 0.004735, Time: 2:12:22
Epoch id: 10, Training steps: 1000, Train Acc: 75.00%, Train Loss: 0.004872, Train Avg Loss: 0.005367, Time: 2:12:53
Epoch id: 10, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.001982, Train Avg Loss: 0.005750, Time: 2:13:24
Start evaluation on dev dataset.
Acc. (Correct/Total): 52.88% micro-Prec: 0.7694 micro-Recall:0.6879 micro-F1: 0.7264 dev loss: 0.039183
Start evaluation on test dataset.
Acc. (Correct/Total): 59.94% micro-Prec: 0.8083 micro-Recall:0.7333 micro-F1: 0.7689 dev loss: 0.033778
Epoch id: 11, Training steps: 100, Train Acc: 87.50%, Train Loss: 0.001972, Train Avg Loss: 0.006085, Time: 2:15:04
Epoch id: 11, Training steps: 200, Train Acc: 87.50%, Train Loss: 0.002279, Train Avg Loss: 0.003741, Time: 2:15:35
Epoch id: 11, Training steps: 300, Train Acc: 87.50%, Train Loss: 0.003282, Train Avg Loss: 0.004482, Time: 2:16:06
Epoch id: 11, Training steps: 400, Train Acc: 87.50%, Train Loss: 0.002368, Train Avg Loss: 0.004111, Time: 2:16:37
Epoch id: 11, Training steps: 500, Train Acc: 50.00%, Train Loss: 0.009302, Train Avg Loss: 0.004629, Time: 2:17:09
Epoch id: 11, Training steps: 600, Train Acc: 87.50%, Train Loss: 0.002533, Train Avg Loss: 0.003986, Time: 2:17:40
Epoch id: 11, Training steps: 700, Train Acc: 87.50%, Train Loss: 0.001396, Train Avg Loss: 0.003656, Time: 2:18:11
Epoch id: 11, Training steps: 800, Train Acc: 87.50%, Train Loss: 0.003078, Train Avg Loss: 0.004282, Time: 2:18:42
Epoch id: 11, Training steps: 900, Train Acc: 100.00%, Train Loss: 0.000641, Train Avg Loss: 0.003938, Time: 2:19:13
Epoch id: 11, Training steps: 1000, Train Acc: 75.00%, Train Loss: 0.003718, Train Avg Loss: 0.004975, Time: 2:19:44
Epoch id: 11, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.003940, Train Avg Loss: 0.004166, Time: 2:20:15
Start evaluation on dev dataset.
Acc. (Correct/Total): 52.83% micro-Prec: 0.7513 micro-Recall:0.6944 micro-F1: 0.7217 dev loss: 0.040243
Epoch id: 12, Training steps: 100, Train Acc: 87.50%, Train Loss: 0.003369, Train Avg Loss: 0.004584, Time: 2:21:26
Epoch id: 12, Training steps: 200, Train Acc: 87.50%, Train Loss: 0.002191, Train Avg Loss: 0.002443, Time: 2:21:57
Epoch id: 12, Training steps: 300, Train Acc: 100.00%, Train Loss: 0.002326, Train Avg Loss: 0.003625, Time: 2:22:29
Epoch id: 12, Training steps: 400, Train Acc: 62.50%, Train Loss: 0.018409, Train Avg Loss: 0.003345, Time: 2:23:00
Epoch id: 12, Training steps: 500, Train Acc: 75.00%, Train Loss: 0.005318, Train Avg Loss: 0.003008, Time: 2:23:31
Epoch id: 12, Training steps: 600, Train Acc: 87.50%, Train Loss: 0.002625, Train Avg Loss: 0.003448, Time: 2:24:02
Epoch id: 12, Training steps: 700, Train Acc: 75.00%, Train Loss: 0.005508, Train Avg Loss: 0.003343, Time: 2:24:33
Epoch id: 12, Training steps: 800, Train Acc: 87.50%, Train Loss: 0.001138, Train Avg Loss: 0.003132, Time: 2:25:04
Epoch id: 12, Training steps: 900, Train Acc: 75.00%, Train Loss: 0.003799, Train Avg Loss: 0.003489, Time: 2:25:35
Epoch id: 12, Training steps: 1000, Train Acc: 75.00%, Train Loss: 0.004538, Train Avg Loss: 0.004719, Time: 2:26:07
Epoch id: 12, Training steps: 1100, Train Acc: 62.50%, Train Loss: 0.006428, Train Avg Loss: 0.004192, Time: 2:26:38
Start evaluation on dev dataset.
Acc. (Correct/Total): 54.22% micro-Prec: 0.7617 micro-Recall:0.7015 micro-F1: 0.7304 dev loss: 0.039229
Start evaluation on test dataset.
Acc. (Correct/Total): 61.15% micro-Prec: 0.8006 micro-Recall:0.7465 micro-F1: 0.7726 dev loss: 0.033957
Epoch id: 13, Training steps: 100, Train Acc: 100.00%, Train Loss: 0.001116, Train Avg Loss: 0.004801, Time: 2:28:17
Epoch id: 13, Training steps: 200, Train Acc: 75.00%, Train Loss: 0.002672, Train Avg Loss: 0.002794, Time: 2:28:48
Epoch id: 13, Training steps: 300, Train Acc: 75.00%, Train Loss: 0.005377, Train Avg Loss: 0.002569, Time: 2:29:20
Epoch id: 13, Training steps: 400, Train Acc: 100.00%, Train Loss: 0.000390, Train Avg Loss: 0.002477, Time: 2:29:51
Epoch id: 13, Training steps: 500, Train Acc: 62.50%, Train Loss: 0.005548, Train Avg Loss: 0.002083, Time: 2:30:22
Epoch id: 13, Training steps: 600, Train Acc: 87.50%, Train Loss: 0.001831, Train Avg Loss: 0.002267, Time: 2:30:53
Epoch id: 13, Training steps: 700, Train Acc: 87.50%, Train Loss: 0.001958, Train Avg Loss: 0.003201, Time: 2:31:24
Epoch id: 13, Training steps: 800, Train Acc: 87.50%, Train Loss: 0.003556, Train Avg Loss: 0.002457, Time: 2:31:55
Epoch id: 13, Training steps: 900, Train Acc: 100.00%, Train Loss: 0.000685, Train Avg Loss: 0.002614, Time: 2:32:26
Epoch id: 13, Training steps: 1000, Train Acc: 75.00%, Train Loss: 0.003310, Train Avg Loss: 0.003247, Time: 2:32:58
Epoch id: 13, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.001312, Train Avg Loss: 0.003098, Time: 2:33:29
Start evaluation on dev dataset.
Acc. (Correct/Total): 53.65% micro-Prec: 0.7590 micro-Recall:0.7015 micro-F1: 0.7291 dev loss: 0.038616
Epoch id: 14, Training steps: 100, Train Acc: 75.00%, Train Loss: 0.004301, Train Avg Loss: 0.003896, Time: 2:34:40
Epoch id: 14, Training steps: 200, Train Acc: 100.00%, Train Loss: 0.000632, Train Avg Loss: 0.002170, Time: 2:35:11
Epoch id: 14, Training steps: 300, Train Acc: 87.50%, Train Loss: 0.002042, Train Avg Loss: 0.001977, Time: 2:35:42
Epoch id: 14, Training steps: 400, Train Acc: 100.00%, Train Loss: 0.001171, Train Avg Loss: 0.002222, Time: 2:36:13
Epoch id: 14, Training steps: 500, Train Acc: 75.00%, Train Loss: 0.005524, Train Avg Loss: 0.003010, Time: 2:36:44
Epoch id: 14, Training steps: 600, Train Acc: 75.00%, Train Loss: 0.003288, Train Avg Loss: 0.002762, Time: 2:37:16
Epoch id: 14, Training steps: 700, Train Acc: 87.50%, Train Loss: 0.001859, Train Avg Loss: 0.002096, Time: 2:37:47
Epoch id: 14, Training steps: 800, Train Acc: 87.50%, Train Loss: 0.003371, Train Avg Loss: 0.002185, Time: 2:38:18
Epoch id: 14, Training steps: 900, Train Acc: 100.00%, Train Loss: 0.001271, Train Avg Loss: 0.002476, Time: 2:38:49
Epoch id: 14, Training steps: 1000, Train Acc: 75.00%, Train Loss: 0.010617, Train Avg Loss: 0.002720, Time: 2:39:20
Epoch id: 14, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.003504, Train Avg Loss: 0.002258, Time: 2:39:51
Start evaluation on dev dataset.
Acc. (Correct/Total): 55.09% micro-Prec: 0.7581 micro-Recall:0.7151 micro-F1: 0.7360 dev loss: 0.038616
Start evaluation on test dataset.
Acc. (Correct/Total): 63.28% micro-Prec: 0.8110 micro-Recall:0.7604 micro-F1: 0.7849 dev loss: 0.032818
Epoch id: 15, Training steps: 100, Train Acc: 87.50%, Train Loss: 0.002019, Train Avg Loss: 0.003802, Time: 2:41:32
Epoch id: 15, Training steps: 200, Train Acc: 87.50%, Train Loss: 0.001824, Train Avg Loss: 0.002429, Time: 2:42:03
Epoch id: 15, Training steps: 300, Train Acc: 87.50%, Train Loss: 0.002156, Train Avg Loss: 0.001784, Time: 2:42:34
Epoch id: 15, Training steps: 400, Train Acc: 100.00%, Train Loss: 0.000404, Train Avg Loss: 0.002042, Time: 2:43:05
Epoch id: 15, Training steps: 500, Train Acc: 100.00%, Train Loss: 0.001159, Train Avg Loss: 0.001834, Time: 2:43:36
Epoch id: 15, Training steps: 600, Train Acc: 75.00%, Train Loss: 0.001277, Train Avg Loss: 0.001926, Time: 2:44:07
Epoch id: 15, Training steps: 700, Train Acc: 100.00%, Train Loss: 0.000572, Train Avg Loss: 0.002034, Time: 2:44:39
Epoch id: 15, Training steps: 800, Train Acc: 87.50%, Train Loss: 0.005093, Train Avg Loss: 0.002025, Time: 2:45:10
Epoch id: 15, Training steps: 900, Train Acc: 87.50%, Train Loss: 0.001522, Train Avg Loss: 0.002113, Time: 2:45:41
Epoch id: 15, Training steps: 1000, Train Acc: 87.50%, Train Loss: 0.001277, Train Avg Loss: 0.002220, Time: 2:46:12
Epoch id: 15, Training steps: 1100, Train Acc: 75.00%, Train Loss: 0.003979, Train Avg Loss: 0.001948, Time: 2:46:43
Start evaluation on dev dataset.
Acc. (Correct/Total): 56.19% micro-Prec: 0.7761 micro-Recall:0.7138 micro-F1: 0.7437 dev loss: 0.036360
Start evaluation on test dataset.
Acc. (Correct/Total): 63.18% micro-Prec: 0.8220 micro-Recall:0.7569 micro-F1: 0.7881 dev loss: 0.030601
Epoch id: 16, Training steps: 100, Train Acc: 100.00%, Train Loss: 0.001874, Train Avg Loss: 0.002408, Time: 2:48:22
Epoch id: 16, Training steps: 200, Train Acc: 87.50%, Train Loss: 0.001220, Train Avg Loss: 0.001279, Time: 2:48:53
Epoch id: 16, Training steps: 300, Train Acc: 100.00%, Train Loss: 0.000266, Train Avg Loss: 0.001634, Time: 2:49:24
Epoch id: 16, Training steps: 400, Train Acc: 75.00%, Train Loss: 0.007700, Train Avg Loss: 0.001553, Time: 2:49:56
Epoch id: 16, Training steps: 500, Train Acc: 100.00%, Train Loss: 0.000307, Train Avg Loss: 0.001661, Time: 2:50:27
Epoch id: 16, Training steps: 600, Train Acc: 100.00%, Train Loss: 0.000790, Train Avg Loss: 0.001478, Time: 2:50:58
Epoch id: 16, Training steps: 700, Train Acc: 87.50%, Train Loss: 0.001950, Train Avg Loss: 0.002157, Time: 2:51:29
Epoch id: 16, Training steps: 800, Train Acc: 75.00%, Train Loss: 0.001312, Train Avg Loss: 0.001486, Time: 2:52:00
Epoch id: 16, Training steps: 900, Train Acc: 100.00%, Train Loss: 0.000719, Train Avg Loss: 0.001911, Time: 2:52:31
Epoch id: 16, Training steps: 1000, Train Acc: 87.50%, Train Loss: 0.002015, Train Avg Loss: 0.001961, Time: 2:53:03
Epoch id: 16, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.005554, Train Avg Loss: 0.002464, Time: 2:53:34
Start evaluation on dev dataset.
Acc. (Correct/Total): 55.33% micro-Prec: 0.7631 micro-Recall:0.7300 micro-F1: 0.7462 dev loss: 0.037608
Epoch id: 17, Training steps: 100, Train Acc: 100.00%, Train Loss: 0.000479, Train Avg Loss: 0.002383, Time: 2:54:44
Epoch id: 17, Training steps: 200, Train Acc: 87.50%, Train Loss: 0.002748, Train Avg Loss: 0.001317, Time: 2:55:16
Epoch id: 17, Training steps: 300, Train Acc: 100.00%, Train Loss: 0.000338, Train Avg Loss: 0.001140, Time: 2:55:47
Epoch id: 17, Training steps: 400, Train Acc: 100.00%, Train Loss: 0.000709, Train Avg Loss: 0.001597, Time: 2:56:27
Epoch id: 17, Training steps: 500, Train Acc: 100.00%, Train Loss: 0.000567, Train Avg Loss: 0.001152, Time: 2:57:33
Epoch id: 17, Training steps: 600, Train Acc: 100.00%, Train Loss: 0.000408, Train Avg Loss: 0.001741, Time: 2:58:38
Epoch id: 17, Training steps: 700, Train Acc: 100.00%, Train Loss: 0.001279, Train Avg Loss: 0.001792, Time: 2:59:23
Epoch id: 17, Training steps: 800, Train Acc: 87.50%, Train Loss: 0.004963, Train Avg Loss: 0.001892, Time: 3:00:29
Epoch id: 17, Training steps: 900, Train Acc: 100.00%, Train Loss: 0.000829, Train Avg Loss: 0.001495, Time: 3:01:34
Epoch id: 17, Training steps: 1000, Train Acc: 100.00%, Train Loss: 0.000203, Train Avg Loss: 0.001479, Time: 3:02:40
Epoch id: 17, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.001051, Train Avg Loss: 0.001773, Time: 3:03:45
Start evaluation on dev dataset.
Acc. (Correct/Total): 53.41% micro-Prec: 0.7594 micro-Recall:0.7041 micro-F1: 0.7307 dev loss: 0.039184
Epoch id: 18, Training steps: 100, Train Acc: 100.00%, Train Loss: 0.000702, Train Avg Loss: 0.003005, Time: 3:06:15
Epoch id: 18, Training steps: 200, Train Acc: 87.50%, Train Loss: 0.001441, Train Avg Loss: 0.001900, Time: 3:07:21
Epoch id: 18, Training steps: 300, Train Acc: 87.50%, Train Loss: 0.002466, Train Avg Loss: 0.001489, Time: 3:08:27
Epoch id: 18, Training steps: 400, Train Acc: 75.00%, Train Loss: 0.003931, Train Avg Loss: 0.002092, Time: 3:09:32
Epoch id: 18, Training steps: 500, Train Acc: 75.00%, Train Loss: 0.005039, Train Avg Loss: 0.002025, Time: 3:10:38
Epoch id: 18, Training steps: 600, Train Acc: 100.00%, Train Loss: 0.001107, Train Avg Loss: 0.001441, Time: 3:11:43
Epoch id: 18, Training steps: 700, Train Acc: 100.00%, Train Loss: 0.000917, Train Avg Loss: 0.001636, Time: 3:12:45
Epoch id: 18, Training steps: 800, Train Acc: 100.00%, Train Loss: 0.000592, Train Avg Loss: 0.001835, Time: 3:13:49
Epoch id: 18, Training steps: 900, Train Acc: 100.00%, Train Loss: 0.000992, Train Avg Loss: 0.001653, Time: 3:14:55
Epoch id: 18, Training steps: 1000, Train Acc: 100.00%, Train Loss: 0.000305, Train Avg Loss: 0.001888, Time: 3:16:00
Epoch id: 18, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.000843, Train Avg Loss: 0.001795, Time: 3:17:06
Start evaluation on dev dataset.
Acc. (Correct/Total): 54.65% micro-Prec: 0.7637 micro-Recall:0.6980 micro-F1: 0.7294 dev loss: 0.037443
Epoch id: 19, Training steps: 100, Train Acc: 87.50%, Train Loss: 0.001244, Train Avg Loss: 0.001865, Time: 3:19:36
Epoch id: 19, Training steps: 200, Train Acc: 75.00%, Train Loss: 0.001699, Train Avg Loss: 0.000971, Time: 3:20:42
Epoch id: 19, Training steps: 300, Train Acc: 87.50%, Train Loss: 0.003156, Train Avg Loss: 0.001335, Time: 3:21:47
Epoch id: 19, Training steps: 400, Train Acc: 100.00%, Train Loss: 0.000237, Train Avg Loss: 0.001760, Time: 3:22:53
Epoch id: 19, Training steps: 500, Train Acc: 100.00%, Train Loss: 0.000971, Train Avg Loss: 0.001084, Time: 3:23:58
Epoch id: 19, Training steps: 600, Train Acc: 100.00%, Train Loss: 0.000125, Train Avg Loss: 0.001148, Time: 3:25:04
Epoch id: 19, Training steps: 700, Train Acc: 100.00%, Train Loss: 0.002381, Train Avg Loss: 0.000964, Time: 3:26:09
Epoch id: 19, Training steps: 800, Train Acc: 100.00%, Train Loss: 0.000513, Train Avg Loss: 0.001381, Time: 3:27:13
Epoch id: 19, Training steps: 900, Train Acc: 87.50%, Train Loss: 0.000982, Train Avg Loss: 0.000909, Time: 3:28:19
Epoch id: 19, Training steps: 1000, Train Acc: 100.00%, Train Loss: 0.000595, Train Avg Loss: 0.001131, Time: 3:29:25
Epoch id: 19, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.000291, Train Avg Loss: 0.001382, Time: 3:30:30
Start evaluation on dev dataset.
Acc. (Correct/Total): 53.41% micro-Prec: 0.7546 micro-Recall:0.6938 micro-F1: 0.7229 dev loss: 0.039614
Epoch id: 20, Training steps: 100, Train Acc: 87.50%, Train Loss: 0.000730, Train Avg Loss: 0.001147, Time: 3:33:01
Epoch id: 20, Training steps: 200, Train Acc: 100.00%, Train Loss: 0.000249, Train Avg Loss: 0.000797, Time: 3:34:07
Epoch id: 20, Training steps: 300, Train Acc: 100.00%, Train Loss: 0.000386, Train Avg Loss: 0.000734, Time: 3:35:12
Epoch id: 20, Training steps: 400, Train Acc: 100.00%, Train Loss: 0.000095, Train Avg Loss: 0.001123, Time: 3:36:18
Epoch id: 20, Training steps: 500, Train Acc: 100.00%, Train Loss: 0.000259, Train Avg Loss: 0.001133, Time: 3:37:23
Epoch id: 20, Training steps: 600, Train Acc: 87.50%, Train Loss: 0.001910, Train Avg Loss: 0.001064, Time: 3:38:29
Epoch id: 20, Training steps: 700, Train Acc: 100.00%, Train Loss: 0.000347, Train Avg Loss: 0.001131, Time: 3:39:34
Epoch id: 20, Training steps: 800, Train Acc: 100.00%, Train Loss: 0.000384, Train Avg Loss: 0.001100, Time: 3:40:38
Epoch id: 20, Training steps: 900, Train Acc: 100.00%, Train Loss: 0.002414, Train Avg Loss: 0.000974, Time: 3:41:44
Epoch id: 20, Training steps: 1000, Train Acc: 100.00%, Train Loss: 0.000585, Train Avg Loss: 0.001268, Time: 3:42:50
Epoch id: 20, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.000784, Train Avg Loss: 0.001164, Time: 3:43:55
Start evaluation on dev dataset.
Acc. (Correct/Total): 56.77% micro-Prec: 0.7759 micro-Recall:0.7307 micro-F1: 0.7526 dev loss: 0.037660
Start evaluation on test dataset.
Acc. (Correct/Total): 63.13% micro-Prec: 0.8136 micro-Recall:0.7763 micro-F1: 0.7945 dev loss: 0.030985
Final evaluation on the test dataset.
The number of evaluation instances:  2067
Acc. (Correct/Total): 63.13% micro-Prec: 0.8136 micro-Recall:0.7763 micro-F1: 0.7945 dev loss: 0.030985
              precision    recall  f1-score   support

         教育学     0.8417    0.9710    0.9017       241
          法学     0.8500    0.9107    0.8793       224
      中国语言文学     0.8765    0.8054    0.8394       185
         政治学     0.7843    0.7362    0.7595       163
         社会学     0.8571    0.8408    0.8489       157
         心理学     0.8750    0.6829    0.7671       123
       应用经济学     0.7614    0.5726    0.6537       117
         历史学     0.7831    0.5963    0.6771       109
     环境科学与工程     0.8509    0.8981    0.8739       108
          哲学     0.8800    0.6804    0.7674        97
      外国语言文学     0.8148    0.7765    0.7952        85
         生物学     0.8642    0.8861    0.8750        79
      交通运输工程     0.8837    0.9744    0.9268        78
        临床医学     0.8158    0.8158    0.8158        76
    计算机科学与技术     0.7600    0.8028    0.7808        71
        土木工程     0.8205    0.9697    0.8889        66
   航空宇航科学与技术     1.0000    0.8689    0.9298        61
         民族学     0.7317    0.5455    0.6250        55
   公共卫生与预防医学     0.7222    0.7647    0.7429        51
         美术学     0.8305    0.9800    0.8991        50
         艺术学     0.6786    0.8837    0.7677        43
         地理学     0.8056    0.6905    0.7436        42
         体育学     0.8966    0.6500    0.7536        40
       理论经济学     0.8788    0.7632    0.8169        38
         中医学     0.8387    0.7027    0.7647        37
         物理学     0.8421    0.8889    0.8649        36
          林学     0.7576    0.7576    0.7576        33
          数学     0.8095    0.5312    0.6415        32
     电子科学与技术     0.6957    0.5161    0.5926        31
        基础医学     0.6000    0.5172    0.5556        29
        工商管理     0.8235    0.5185    0.6364        27
       新闻传播学     0.8500    0.7727    0.8095        22
         天文学     0.8000    0.9091    0.8511        22
         地质学     0.9286    0.6190    0.7429        21
         畜牧学     0.8571    0.8571    0.8571        21
   军事思想及军事历史     0.8095    0.8500    0.8293        20
     管理科学与工程     0.5385    0.7778    0.6364        18
     测绘科学与技术     0.8000    0.7059    0.7500        17
        水利工程     0.8571    0.7500    0.8000        16
        大气科学     0.7000    0.8750    0.7778        16
     兵器科学与技术     0.6667    0.8000    0.7273        15
       地球物理学     0.7500    0.2143    0.3333        14
        电气工程     0.8889    0.6154    0.7273        13
         作物学     0.7000    0.5385    0.6087        13
     控制科学与工程     0.4667    0.5385    0.5000        13
     信息与通信工程     0.5333    0.6154    0.5714        13
        公共管理     0.2222    0.1538    0.1818        13
         建筑学     0.7500    0.2308    0.3529        13
     化学工程与技术     0.7692    0.8333    0.8000        12
          力学     0.6667    0.7273    0.6957        11
        海洋科学     0.9091    0.9091    0.9091        11
     轻工技术与工程     0.4286    0.5455    0.4800        11
        农业工程     1.0000    0.4000    0.5714        10
         园艺学     0.9000    0.9000    0.9000        10
       中西医结合     1.0000    0.1000    0.1818        10
        机械工程     0.8889    0.8889    0.8889         9
       科学技术史     1.0000    0.6250    0.7692         8
     船舶与海洋工程     1.0000    0.7500    0.8571         8
   图书情报与档案管理     0.7000    0.8750    0.7778         8
        植物保护     0.7273    1.0000    0.8421         8
     材料科学与工程     1.0000    0.7500    0.8571         8
         统计学     0.5455    0.7500    0.6316         8
          化学     1.0000    1.0000    1.0000         8
     食品科学与工程     0.5714    0.5000    0.5333         8
          水产     0.8750    1.0000    0.9333         7
          药学     1.0000    0.8571    0.9231         7
     农业资源与环境     0.7500    0.8571    0.8000         7
         世界史     0.7000    1.0000    0.8235         7
        系统科学     0.8750    1.0000    0.9333         7
      农林经济管理     0.8000    0.8000    0.8000         5
       军队指挥学     1.0000    0.4000    0.5714         5
        矿业工程     0.7500    0.6000    0.6667         5
     纺织科学与工程     0.7143    1.0000    0.8333         5
  动力工程及工程热物理     0.0000    0.0000    0.0000         4
        林业工程     0.3333    0.2500    0.2857         4
     仪器科学与技术     0.0000    0.0000    0.0000         3
         战略学     0.5000    0.6667    0.5714         3
   地质资源与地质工程     0.5000    1.0000    0.6667         3
        旅游管理     1.0000    0.6667    0.8000         3
 图书馆、情报与档案管理     0.0000    0.0000    0.0000         2
        冶金工程     1.0000    0.5000    0.6667         2
      核科学与技术     1.0000    0.5000    0.6667         2

   micro avg     0.8136    0.7763    0.7945      3093
   macro avg     0.7592    0.6948    0.7053      3093
weighted avg     0.8153    0.7763    0.7868      3093
 samples avg     0.8070    0.7908    0.7846      3093


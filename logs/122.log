  0%|          | 0/82 [00:00<?, ?it/s]100%|██████████| 82/82 [00:00<00:00, 1095327.80it/s]
Vocabulary Size:  39979
[BertClassifier] use visible_matrix: False
Some weights of ErnieRCNNForMultiLabelSequenceClassification were not initialized from the model checkpoint at ./models/ernie3 and are newly initialized: ['classifier.bias', 'lstm.weight_ih_l0_reverse', 'lstm.bias_hh_l0_reverse', 'lstm.bias_ih_l1', 'classifier.weight', 'lstm.bias_hh_l0', 'lstm.weight_hh_l0_reverse', 'lstm.bias_hh_l1', 'lstm.weight_hh_l1_reverse', 'lstm.weight_ih_l0', 'lstm.bias_ih_l1_reverse', 'lstm.bias_hh_l1_reverse', 'lstm.weight_ih_l1_reverse', 'lstm.bias_ih_l0', 'lstm.weight_hh_l1', 'lstm.bias_ih_l0_reverse', 'lstm.weight_hh_l0', 'lstm.weight_ih_l1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model:  ernie-rcnn
pretrained:  ernie3
dataset:  book_multilabels_task
task:  MLC
seq_length:  256
hidden_dropout_prob:  0.1
attention_probs_dropout_prob:  0.1
dropout_rnn:  0.2
rnn_hidden:  256
epochs_num:  32
batch_size:  8
learning_rate:  2e-05
report_steps:  100
acc_percent:  0.9
kg_name:  CnDbpedia
no_kg:  True
no_vm:  True
GPU:  NVIDIA GeForce RTX 2080 Ti
1 GPUs are available. Let's use them.
device:  cuda
Start training.
Loading sentences from ./datasets/book_multilabels_task/train.tsv
There are 9097 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/9097
Loading sentences from ./datasets/book_multilabels_task/dev.tsv
There are 2084 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/2084
Loading sentences from ./datasets/book_multilabels_task/test.tsv
There are 2067 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/2067
Epoch id: 01, Training steps: 0100,  Train Loss: 0.654658,  Train Acc: 00.00%,  Train Avg Loss: 0.677397,  Time: 0:00:20
Epoch id: 01, Training steps: 0200,  Train Loss: 0.572345,  Train Acc: 00.00%,  Train Avg Loss: 0.617445,  Time: 0:00:40
Epoch id: 01, Training steps: 0300,  Train Loss: 0.446226,  Train Acc: 00.00%,  Train Avg Loss: 0.509910,  Time: 0:00:59
Epoch id: 01, Training steps: 0400,  Train Loss: 0.388723,  Train Acc: 00.00%,  Train Avg Loss: 0.401753,  Time: 0:01:19
Epoch id: 01, Training steps: 0500,  Train Loss: 0.293873,  Train Acc: 00.00%,  Train Avg Loss: 0.319810,  Time: 0:01:39
Epoch id: 01, Training steps: 0600,  Train Loss: 0.262801,  Train Acc: 00.00%,  Train Avg Loss: 0.254553,  Time: 0:01:59
Epoch id: 01, Training steps: 0700,  Train Loss: 0.184140,  Train Acc: 00.00%,  Train Avg Loss: 0.195916,  Time: 0:02:19
Epoch id: 01, Training steps: 0800,  Train Loss: 0.127959,  Train Acc: 00.00%,  Train Avg Loss: 0.152180,  Time: 0:02:38
Epoch id: 01, Training steps: 0900,  Train Loss: 0.097838,  Train Acc: 00.00%,  Train Avg Loss: 0.123247,  Time: 0:02:58
Epoch id: 01, Training steps: 1000,  Train Loss: 0.103637,  Train Acc: 00.00%,  Train Avg Loss: 0.108345,  Time: 0:03:18
Epoch id: 01, Training steps: 1100,  Train Loss: 0.092933,  Train Acc: 00.00%,  Train Avg Loss: 0.099164,  Time: 0:03:37
Start evaluation on dev dataset.
Acc. (Correct/Total):  0.00% micro-Prec: 0.0000 micro-Recall:0.0000 micro-F1: 0.0000 dev loss: 0.095876
Epoch id: 02, Training steps: 0100,  Train Loss: 0.088890,  Train Acc: 00.00%,  Train Avg Loss: 0.128657,  Time: 0:04:20
Epoch id: 02, Training steps: 0200,  Train Loss: 0.085471,  Train Acc: 00.00%,  Train Avg Loss: 0.088729,  Time: 0:04:40
Epoch id: 02, Training steps: 0300,  Train Loss: 0.071641,  Train Acc: 00.00%,  Train Avg Loss: 0.087439,  Time: 0:04:59
Epoch id: 02, Training steps: 0400,  Train Loss: 0.070343,  Train Acc: 00.00%,  Train Avg Loss: 0.084960,  Time: 0:05:19
Epoch id: 02, Training steps: 0500,  Train Loss: 0.079515,  Train Acc: 00.00%,  Train Avg Loss: 0.083618,  Time: 0:05:39
Epoch id: 02, Training steps: 0600,  Train Loss: 0.076780,  Train Acc: 00.00%,  Train Avg Loss: 0.082140,  Time: 0:05:59
Epoch id: 02, Training steps: 0700,  Train Loss: 0.081125,  Train Acc: 00.00%,  Train Avg Loss: 0.080380,  Time: 0:06:18
Epoch id: 02, Training steps: 0800,  Train Loss: 0.079924,  Train Acc: 00.00%,  Train Avg Loss: 0.079253,  Time: 0:06:38
Epoch id: 02, Training steps: 0900,  Train Loss: 0.080907,  Train Acc: 00.00%,  Train Avg Loss: 0.075314,  Time: 0:06:58
Epoch id: 02, Training steps: 1000,  Train Loss: 0.063745,  Train Acc: 00.00%,  Train Avg Loss: 0.072721,  Time: 0:07:17
Epoch id: 02, Training steps: 1100,  Train Loss: 0.055272,  Train Acc: 00.00%,  Train Avg Loss: 0.071555,  Time: 0:07:37
Start evaluation on dev dataset.
Acc. (Correct/Total):  0.00% micro-Prec: 0.0000 micro-Recall:0.0000 micro-F1: 0.0000 dev loss: 0.066568
Epoch id: 03, Training steps: 0100,  Train Loss: 0.052503,  Train Acc: 00.00%,  Train Avg Loss: 0.092154,  Time: 0:08:20
Epoch id: 03, Training steps: 0200,  Train Loss: 0.058393,  Train Acc: 00.00%,  Train Avg Loss: 0.064852,  Time: 0:08:39
Epoch id: 03, Training steps: 0300,  Train Loss: 0.065218,  Train Acc: 00.00%,  Train Avg Loss: 0.063804,  Time: 0:08:59
Epoch id: 03, Training steps: 0400,  Train Loss: 0.066929,  Train Acc: 00.00%,  Train Avg Loss: 0.060900,  Time: 0:09:19
Epoch id: 03, Training steps: 0500,  Train Loss: 0.049588,  Train Acc: 00.00%,  Train Avg Loss: 0.057944,  Time: 0:09:38
Epoch id: 03, Training steps: 0600,  Train Loss: 0.042848,  Train Acc: 00.00%,  Train Avg Loss: 0.057021,  Time: 0:09:58
Epoch id: 03, Training steps: 0700,  Train Loss: 0.074275,  Train Acc: 00.00%,  Train Avg Loss: 0.054964,  Time: 0:10:18
Epoch id: 03, Training steps: 0800,  Train Loss: 0.052410,  Train Acc: 00.00%,  Train Avg Loss: 0.051178,  Time: 0:10:37
Epoch id: 03, Training steps: 0900,  Train Loss: 0.045047,  Train Acc: 00.00%,  Train Avg Loss: 0.050940,  Time: 0:10:57
Epoch id: 03, Training steps: 1000,  Train Loss: 0.055092,  Train Acc: 00.00%,  Train Avg Loss: 0.051613,  Time: 0:11:17
Epoch id: 03, Training steps: 1100,  Train Loss: 0.051041,  Train Acc: 00.00%,  Train Avg Loss: 0.048589,  Time: 0:11:37
Start evaluation on dev dataset.
Acc. (Correct/Total):  0.67% micro-Prec: 0.0345 micro-Recall:0.0204 micro-F1: 0.0250 dev loss: 0.047184
Start evaluation on test dataset.
Acc. (Correct/Total):  0.44% micro-Prec: 0.0518 micro-Recall:0.0277 micro-F1: 0.0356 dev loss: 0.044703
Epoch id: 04, Training steps: 0100,  Train Loss: 0.045479,  Train Acc: 00.00%,  Train Avg Loss: 0.063906,  Time: 0:12:35
Epoch id: 04, Training steps: 0200,  Train Loss: 0.041525,  Train Acc: 12.50%,  Train Avg Loss: 0.045366,  Time: 0:12:55
Epoch id: 04, Training steps: 0300,  Train Loss: 0.026383,  Train Acc: 00.00%,  Train Avg Loss: 0.044113,  Time: 0:13:15
Epoch id: 04, Training steps: 0400,  Train Loss: 0.035477,  Train Acc: 00.00%,  Train Avg Loss: 0.043663,  Time: 0:13:34
Epoch id: 04, Training steps: 0500,  Train Loss: 0.052649,  Train Acc: 00.00%,  Train Avg Loss: 0.044209,  Time: 0:13:54
Epoch id: 04, Training steps: 0600,  Train Loss: 0.034303,  Train Acc: 12.50%,  Train Avg Loss: 0.041241,  Time: 0:14:14
Epoch id: 04, Training steps: 0700,  Train Loss: 0.039666,  Train Acc: 12.50%,  Train Avg Loss: 0.042201,  Time: 0:14:34
Epoch id: 04, Training steps: 0800,  Train Loss: 0.030795,  Train Acc: 00.00%,  Train Avg Loss: 0.040644,  Time: 0:14:53
Epoch id: 04, Training steps: 0900,  Train Loss: 0.074850,  Train Acc: 00.00%,  Train Avg Loss: 0.041559,  Time: 0:15:13
Epoch id: 04, Training steps: 1000,  Train Loss: 0.039618,  Train Acc: 00.00%,  Train Avg Loss: 0.041407,  Time: 0:15:33
Epoch id: 04, Training steps: 1100,  Train Loss: 0.041755,  Train Acc: 00.00%,  Train Avg Loss: 0.039575,  Time: 0:15:52
Start evaluation on dev dataset.
Acc. (Correct/Total): 12.91% micro-Prec: 0.2306 micro-Recall:0.1823 micro-F1: 0.1978 dev loss: 0.041617
Start evaluation on test dataset.
Acc. (Correct/Total): 14.90% micro-Prec: 0.2484 micro-Recall:0.1992 micro-F1: 0.2156 dev loss: 0.038201
Epoch id: 05, Training steps: 0100,  Train Loss: 0.043831,  Train Acc: 12.50%,  Train Avg Loss: 0.050841,  Time: 0:16:50
Epoch id: 05, Training steps: 0200,  Train Loss: 0.027015,  Train Acc: 00.00%,  Train Avg Loss: 0.034918,  Time: 0:17:10
Epoch id: 05, Training steps: 0300,  Train Loss: 0.023894,  Train Acc: 12.50%,  Train Avg Loss: 0.037029,  Time: 0:17:27
Epoch id: 05, Training steps: 0400,  Train Loss: 0.034329,  Train Acc: 00.00%,  Train Avg Loss: 0.035622,  Time: 0:17:44
Epoch id: 05, Training steps: 0500,  Train Loss: 0.038719,  Train Acc: 12.50%,  Train Avg Loss: 0.036590,  Time: 0:18:00
Epoch id: 05, Training steps: 0600,  Train Loss: 0.035606,  Train Acc: 00.00%,  Train Avg Loss: 0.036547,  Time: 0:18:18
Epoch id: 05, Training steps: 0700,  Train Loss: 0.041712,  Train Acc: 12.50%,  Train Avg Loss: 0.037016,  Time: 0:18:35
Epoch id: 05, Training steps: 0800,  Train Loss: 0.042031,  Train Acc: 00.00%,  Train Avg Loss: 0.034332,  Time: 0:18:53
Epoch id: 05, Training steps: 0900,  Train Loss: 0.055971,  Train Acc: 12.50%,  Train Avg Loss: 0.034092,  Time: 0:19:10
Epoch id: 05, Training steps: 1000,  Train Loss: 0.054036,  Train Acc: 00.00%,  Train Avg Loss: 0.032637,  Time: 0:19:28
Epoch id: 05, Training steps: 1100,  Train Loss: 0.043884,  Train Acc: 00.00%,  Train Avg Loss: 0.035023,  Time: 0:19:46
Start evaluation on dev dataset.
Acc. (Correct/Total): 23.03% micro-Prec: 0.3563 micro-Recall:0.2955 micro-F1: 0.3151 dev loss: 0.037861
Start evaluation on test dataset.
Acc. (Correct/Total): 28.69% micro-Prec: 0.4279 micro-Recall:0.3587 micro-F1: 0.3815 dev loss: 0.033827
Epoch id: 06, Training steps: 0100,  Train Loss: 0.028165,  Train Acc: 37.50%,  Train Avg Loss: 0.037166,  Time: 0:20:37
Epoch id: 06, Training steps: 0200,  Train Loss: 0.032387,  Train Acc: 00.00%,  Train Avg Loss: 0.027135,  Time: 0:20:55
Epoch id: 06, Training steps: 0300,  Train Loss: 0.024561,  Train Acc: 37.50%,  Train Avg Loss: 0.025627,  Time: 0:21:12
Epoch id: 06, Training steps: 0400,  Train Loss: 0.039326,  Train Acc: 12.50%,  Train Avg Loss: 0.024942,  Time: 0:21:30
Epoch id: 06, Training steps: 0500,  Train Loss: 0.037322,  Train Acc: 12.50%,  Train Avg Loss: 0.024061,  Time: 0:21:47
Epoch id: 06, Training steps: 0600,  Train Loss: 0.017893,  Train Acc: 50.00%,  Train Avg Loss: 0.024880,  Time: 0:22:05
Epoch id: 06, Training steps: 0700,  Train Loss: 0.023038,  Train Acc: 50.00%,  Train Avg Loss: 0.023662,  Time: 0:22:22
Epoch id: 06, Training steps: 0800,  Train Loss: 0.010014,  Train Acc: 75.00%,  Train Avg Loss: 0.026453,  Time: 0:22:40
Epoch id: 06, Training steps: 0900,  Train Loss: 0.025732,  Train Acc: 25.00%,  Train Avg Loss: 0.024928,  Time: 0:22:58
Epoch id: 06, Training steps: 1000,  Train Loss: 0.038661,  Train Acc: 00.00%,  Train Avg Loss: 0.023990,  Time: 0:23:15
Epoch id: 06, Training steps: 1100,  Train Loss: 0.026068,  Train Acc: 12.50%,  Train Avg Loss: 0.023402,  Time: 0:23:33
Start evaluation on dev dataset.
Acc. (Correct/Total): 30.04% micro-Prec: 0.4786 micro-Recall:0.3947 micro-F1: 0.4218 dev loss: 0.035262
Start evaluation on test dataset.
Acc. (Correct/Total): 35.07% micro-Prec: 0.5203 micro-Recall:0.4396 micro-F1: 0.4658 dev loss: 0.031612
Epoch id: 07, Training steps: 0100,  Train Loss: 0.032575,  Train Acc: 25.00%,  Train Avg Loss: 0.027436,  Time: 0:24:24
Epoch id: 07, Training steps: 0200,  Train Loss: 0.009842,  Train Acc: 12.50%,  Train Avg Loss: 0.019356,  Time: 0:24:42
Epoch id: 07, Training steps: 0300,  Train Loss: 0.015744,  Train Acc: 25.00%,  Train Avg Loss: 0.021095,  Time: 0:24:59
Epoch id: 07, Training steps: 0400,  Train Loss: 0.020681,  Train Acc: 62.50%,  Train Avg Loss: 0.020441,  Time: 0:25:17
Epoch id: 07, Training steps: 0500,  Train Loss: 0.017947,  Train Acc: 25.00%,  Train Avg Loss: 0.020719,  Time: 0:25:34
Epoch id: 07, Training steps: 0600,  Train Loss: 0.013451,  Train Acc: 62.50%,  Train Avg Loss: 0.020230,  Time: 0:25:52
Epoch id: 07, Training steps: 0700,  Train Loss: 0.014325,  Train Acc: 25.00%,  Train Avg Loss: 0.021355,  Time: 0:26:09
Epoch id: 07, Training steps: 0800,  Train Loss: 0.013608,  Train Acc: 37.50%,  Train Avg Loss: 0.018872,  Time: 0:26:27
Epoch id: 07, Training steps: 0900,  Train Loss: 0.024764,  Train Acc: 50.00%,  Train Avg Loss: 0.019764,  Time: 0:26:45
Epoch id: 07, Training steps: 1000,  Train Loss: 0.015235,  Train Acc: 12.50%,  Train Avg Loss: 0.018475,  Time: 0:27:02
Epoch id: 07, Training steps: 1100,  Train Loss: 0.041951,  Train Acc: 00.00%,  Train Avg Loss: 0.020161,  Time: 0:27:20
Start evaluation on dev dataset.
Acc. (Correct/Total): 31.72% micro-Prec: 0.4926 micro-Recall:0.4116 micro-F1: 0.4370 dev loss: 0.036223
Start evaluation on test dataset.
Acc. (Correct/Total): 38.07% micro-Prec: 0.5556 micro-Recall:0.4704 micro-F1: 0.4985 dev loss: 0.031426
Epoch id: 08, Training steps: 0100,  Train Loss: 0.021767,  Train Acc: 12.50%,  Train Avg Loss: 0.022364,  Time: 0:28:11
Epoch id: 08, Training steps: 0200,  Train Loss: 0.021419,  Train Acc: 37.50%,  Train Avg Loss: 0.017223,  Time: 0:28:29
Epoch id: 08, Training steps: 0300,  Train Loss: 0.011384,  Train Acc: 37.50%,  Train Avg Loss: 0.016865,  Time: 0:28:47
Epoch id: 08, Training steps: 0400,  Train Loss: 0.030175,  Train Acc: 25.00%,  Train Avg Loss: 0.015904,  Time: 0:29:04
Epoch id: 08, Training steps: 0500,  Train Loss: 0.013654,  Train Acc: 37.50%,  Train Avg Loss: 0.017295,  Time: 0:29:22
Epoch id: 08, Training steps: 0600,  Train Loss: 0.020610,  Train Acc: 37.50%,  Train Avg Loss: 0.016419,  Time: 0:29:39
Epoch id: 08, Training steps: 0700,  Train Loss: 0.022950,  Train Acc: 37.50%,  Train Avg Loss: 0.017159,  Time: 0:29:57
Epoch id: 08, Training steps: 0800,  Train Loss: 0.010791,  Train Acc: 37.50%,  Train Avg Loss: 0.016970,  Time: 0:30:14
Epoch id: 08, Training steps: 0900,  Train Loss: 0.020560,  Train Acc: 50.00%,  Train Avg Loss: 0.014709,  Time: 0:30:32
Epoch id: 08, Training steps: 1000,  Train Loss: 0.012225,  Train Acc: 50.00%,  Train Avg Loss: 0.015928,  Time: 0:30:50
Epoch id: 08, Training steps: 1100,  Train Loss: 0.005788,  Train Acc: 50.00%,  Train Avg Loss: 0.016252,  Time: 0:31:07
Start evaluation on dev dataset.
Acc. (Correct/Total): 37.72% micro-Prec: 0.5554 micro-Recall:0.4746 micro-F1: 0.5003 dev loss: 0.033669
Start evaluation on test dataset.
Acc. (Correct/Total): 41.07% micro-Prec: 0.5953 micro-Recall:0.5077 micro-F1: 0.5363 dev loss: 0.030061
Epoch id: 09, Training steps: 0100,  Train Loss: 0.005306,  Train Acc: 37.50%,  Train Avg Loss: 0.020441,  Time: 0:31:58
Epoch id: 09, Training steps: 0200,  Train Loss: 0.011041,  Train Acc: 37.50%,  Train Avg Loss: 0.014041,  Time: 0:32:16
Epoch id: 09, Training steps: 0300,  Train Loss: 0.026728,  Train Acc: 37.50%,  Train Avg Loss: 0.014256,  Time: 0:32:34
Epoch id: 09, Training steps: 0400,  Train Loss: 0.006062,  Train Acc: 50.00%,  Train Avg Loss: 0.013644,  Time: 0:32:51
Epoch id: 09, Training steps: 0500,  Train Loss: 0.016451,  Train Acc: 50.00%,  Train Avg Loss: 0.013459,  Time: 0:33:09
Epoch id: 09, Training steps: 0600,  Train Loss: 0.011503,  Train Acc: 37.50%,  Train Avg Loss: 0.013510,  Time: 0:33:26
Epoch id: 09, Training steps: 0700,  Train Loss: 0.027748,  Train Acc: 37.50%,  Train Avg Loss: 0.014677,  Time: 0:33:44
Epoch id: 09, Training steps: 0800,  Train Loss: 0.012122,  Train Acc: 37.50%,  Train Avg Loss: 0.013797,  Time: 0:34:01
Epoch id: 09, Training steps: 0900,  Train Loss: 0.015072,  Train Acc: 37.50%,  Train Avg Loss: 0.014063,  Time: 0:34:19
Epoch id: 09, Training steps: 1000,  Train Loss: 0.007744,  Train Acc: 62.50%,  Train Avg Loss: 0.012799,  Time: 0:34:36
Epoch id: 09, Training steps: 1100,  Train Loss: 0.006923,  Train Acc: 75.00%,  Train Avg Loss: 0.013109,  Time: 0:34:54
Start evaluation on dev dataset.
Acc. (Correct/Total): 42.13% micro-Prec: 0.6245 micro-Recall:0.5351 micro-F1: 0.5630 dev loss: 0.034724
Start evaluation on test dataset.
Acc. (Correct/Total): 49.15% micro-Prec: 0.6761 micro-Recall:0.5907 micro-F1: 0.6185 dev loss: 0.029603
Epoch id: 10, Training steps: 0100,  Train Loss: 0.006333,  Train Acc: 62.50%,  Train Avg Loss: 0.015400,  Time: 0:35:46
Epoch id: 10, Training steps: 0200,  Train Loss: 0.011059,  Train Acc: 25.00%,  Train Avg Loss: 0.011517,  Time: 0:36:03
Epoch id: 10, Training steps: 0300,  Train Loss: 0.008713,  Train Acc: 25.00%,  Train Avg Loss: 0.012203,  Time: 0:36:19
Epoch id: 10, Training steps: 0400,  Train Loss: 0.015807,  Train Acc: 37.50%,  Train Avg Loss: 0.011666,  Time: 0:36:36
Epoch id: 10, Training steps: 0500,  Train Loss: 0.004916,  Train Acc: 75.00%,  Train Avg Loss: 0.011851,  Time: 0:36:53
Epoch id: 10, Training steps: 0600,  Train Loss: 0.016015,  Train Acc: 50.00%,  Train Avg Loss: 0.011138,  Time: 0:37:09
Epoch id: 10, Training steps: 0700,  Train Loss: 0.010600,  Train Acc: 50.00%,  Train Avg Loss: 0.011151,  Time: 0:37:26
Epoch id: 10, Training steps: 0800,  Train Loss: 0.013147,  Train Acc: 37.50%,  Train Avg Loss: 0.011314,  Time: 0:37:42
Epoch id: 10, Training steps: 0900,  Train Loss: 0.010745,  Train Acc: 12.50%,  Train Avg Loss: 0.011185,  Time: 0:37:59
Epoch id: 10, Training steps: 1000,  Train Loss: 0.014452,  Train Acc: 37.50%,  Train Avg Loss: 0.010611,  Time: 0:38:15
Epoch id: 10, Training steps: 1100,  Train Loss: 0.021082,  Train Acc: 37.50%,  Train Avg Loss: 0.011352,  Time: 0:38:32
Start evaluation on dev dataset.
Acc. (Correct/Total): 44.67% micro-Prec: 0.6464 micro-Recall:0.5621 micro-F1: 0.5879 dev loss: 0.034373
Start evaluation on test dataset.
Acc. (Correct/Total): 50.90% micro-Prec: 0.7020 micro-Recall:0.6136 micro-F1: 0.6422 dev loss: 0.029662
Epoch id: 11, Training steps: 0100,  Train Loss: 0.005742,  Train Acc: 62.50%,  Train Avg Loss: 0.014496,  Time: 0:39:22
Epoch id: 11, Training steps: 0200,  Train Loss: 0.015536,  Train Acc: 25.00%,  Train Avg Loss: 0.010368,  Time: 0:39:38
Epoch id: 11, Training steps: 0300,  Train Loss: 0.009743,  Train Acc: 50.00%,  Train Avg Loss: 0.009951,  Time: 0:39:55
Epoch id: 11, Training steps: 0400,  Train Loss: 0.004985,  Train Acc: 75.00%,  Train Avg Loss: 0.009536,  Time: 0:40:11
Epoch id: 11, Training steps: 0500,  Train Loss: 0.026118,  Train Acc: 62.50%,  Train Avg Loss: 0.010566,  Time: 0:40:28
Epoch id: 11, Training steps: 0600,  Train Loss: 0.026772,  Train Acc: 25.00%,  Train Avg Loss: 0.009716,  Time: 0:40:44
Epoch id: 11, Training steps: 0700,  Train Loss: 0.001605,  Train Acc: 87.50%,  Train Avg Loss: 0.008678,  Time: 0:41:01
Epoch id: 11, Training steps: 0800,  Train Loss: 0.014834,  Train Acc: 37.50%,  Train Avg Loss: 0.009298,  Time: 0:41:17
Epoch id: 11, Training steps: 0900,  Train Loss: 0.010133,  Train Acc: 50.00%,  Train Avg Loss: 0.008661,  Time: 0:41:34
Epoch id: 11, Training steps: 1000,  Train Loss: 0.013308,  Train Acc: 62.50%,  Train Avg Loss: 0.009568,  Time: 0:41:50
Epoch id: 11, Training steps: 1100,  Train Loss: 0.014528,  Train Acc: 25.00%,  Train Avg Loss: 0.009690,  Time: 0:42:07
Start evaluation on dev dataset.
Acc. (Correct/Total): 45.97% micro-Prec: 0.6574 micro-Recall:0.5716 micro-F1: 0.5983 dev loss: 0.034928
Start evaluation on test dataset.
Acc. (Correct/Total): 52.10% micro-Prec: 0.7117 micro-Recall:0.6223 micro-F1: 0.6516 dev loss: 0.028071
Epoch id: 12, Training steps: 0100,  Train Loss: 0.002478,  Train Acc: 100.00%,  Train Avg Loss: 0.012029,  Time: 0:42:57
Epoch id: 12, Training steps: 0200,  Train Loss: 0.009051,  Train Acc: 37.50%,  Train Avg Loss: 0.008087,  Time: 0:43:14
Epoch id: 12, Training steps: 0300,  Train Loss: 0.010989,  Train Acc: 75.00%,  Train Avg Loss: 0.008763,  Time: 0:43:30
Epoch id: 12, Training steps: 0400,  Train Loss: 0.015400,  Train Acc: 62.50%,  Train Avg Loss: 0.008631,  Time: 0:43:47
Epoch id: 12, Training steps: 0500,  Train Loss: 0.005095,  Train Acc: 50.00%,  Train Avg Loss: 0.007909,  Time: 0:44:03
Epoch id: 12, Training steps: 0600,  Train Loss: 0.010573,  Train Acc: 62.50%,  Train Avg Loss: 0.008043,  Time: 0:44:20
Epoch id: 12, Training steps: 0700,  Train Loss: 0.009066,  Train Acc: 37.50%,  Train Avg Loss: 0.007747,  Time: 0:44:36
Epoch id: 12, Training steps: 0800,  Train Loss: 0.003238,  Train Acc: 75.00%,  Train Avg Loss: 0.007844,  Time: 0:44:53
Epoch id: 12, Training steps: 0900,  Train Loss: 0.009369,  Train Acc: 37.50%,  Train Avg Loss: 0.008308,  Time: 0:45:09
Epoch id: 12, Training steps: 1000,  Train Loss: 0.004251,  Train Acc: 75.00%,  Train Avg Loss: 0.008382,  Time: 0:45:26
Epoch id: 12, Training steps: 1100,  Train Loss: 0.015289,  Train Acc: 50.00%,  Train Avg Loss: 0.007485,  Time: 0:45:42
Start evaluation on dev dataset.
Acc. (Correct/Total): 45.54% micro-Prec: 0.6530 micro-Recall:0.5647 micro-F1: 0.5926 dev loss: 0.035045
Epoch id: 13, Training steps: 0100,  Train Loss: 0.004507,  Train Acc: 75.00%,  Train Avg Loss: 0.009521,  Time: 0:46:18
Epoch id: 13, Training steps: 0200,  Train Loss: 0.003902,  Train Acc: 75.00%,  Train Avg Loss: 0.007298,  Time: 0:46:35
Epoch id: 13, Training steps: 0300,  Train Loss: 0.006479,  Train Acc: 75.00%,  Train Avg Loss: 0.006336,  Time: 0:46:51
Epoch id: 13, Training steps: 0400,  Train Loss: 0.005829,  Train Acc: 25.00%,  Train Avg Loss: 0.006615,  Time: 0:47:08
Epoch id: 13, Training steps: 0500,  Train Loss: 0.001293,  Train Acc: 87.50%,  Train Avg Loss: 0.007359,  Time: 0:47:24
Epoch id: 13, Training steps: 0600,  Train Loss: 0.004834,  Train Acc: 50.00%,  Train Avg Loss: 0.006259,  Time: 0:47:41
Epoch id: 13, Training steps: 0700,  Train Loss: 0.005523,  Train Acc: 62.50%,  Train Avg Loss: 0.006767,  Time: 0:47:57
Epoch id: 13, Training steps: 0800,  Train Loss: 0.009639,  Train Acc: 62.50%,  Train Avg Loss: 0.007041,  Time: 0:48:14
Epoch id: 13, Training steps: 0900,  Train Loss: 0.002603,  Train Acc: 87.50%,  Train Avg Loss: 0.006187,  Time: 0:48:31
Epoch id: 13, Training steps: 1000,  Train Loss: 0.014498,  Train Acc: 62.50%,  Train Avg Loss: 0.007613,  Time: 0:48:49
Epoch id: 13, Training steps: 1100,  Train Loss: 0.004427,  Train Acc: 75.00%,  Train Avg Loss: 0.006691,  Time: 0:49:06
Start evaluation on dev dataset.
Acc. (Correct/Total): 46.98% micro-Prec: 0.6683 micro-Recall:0.5842 micro-F1: 0.6100 dev loss: 0.035914
Start evaluation on test dataset.
Acc. (Correct/Total): 54.43% micro-Prec: 0.7358 micro-Recall:0.6515 micro-F1: 0.6784 dev loss: 0.028454
Epoch id: 14, Training steps: 0100,  Train Loss: 0.001648,  Train Acc: 87.50%,  Train Avg Loss: 0.007917,  Time: 0:49:58
Epoch id: 14, Training steps: 0200,  Train Loss: 0.005633,  Train Acc: 62.50%,  Train Avg Loss: 0.005337,  Time: 0:50:15
Epoch id: 14, Training steps: 0300,  Train Loss: 0.002052,  Train Acc: 75.00%,  Train Avg Loss: 0.005500,  Time: 0:50:33
Epoch id: 14, Training steps: 0400,  Train Loss: 0.005274,  Train Acc: 50.00%,  Train Avg Loss: 0.005508,  Time: 0:50:50
Epoch id: 14, Training steps: 0500,  Train Loss: 0.013532,  Train Acc: 37.50%,  Train Avg Loss: 0.005921,  Time: 0:51:08
Epoch id: 14, Training steps: 0600,  Train Loss: 0.004480,  Train Acc: 87.50%,  Train Avg Loss: 0.005598,  Time: 0:51:25
Epoch id: 14, Training steps: 0700,  Train Loss: 0.003552,  Train Acc: 87.50%,  Train Avg Loss: 0.005999,  Time: 0:51:43
Epoch id: 14, Training steps: 0800,  Train Loss: 0.004383,  Train Acc: 87.50%,  Train Avg Loss: 0.005404,  Time: 0:52:00
Epoch id: 14, Training steps: 0900,  Train Loss: 0.002351,  Train Acc: 75.00%,  Train Avg Loss: 0.005522,  Time: 0:52:16
Epoch id: 14, Training steps: 1000,  Train Loss: 0.004657,  Train Acc: 50.00%,  Train Avg Loss: 0.006023,  Time: 0:52:33
Epoch id: 14, Training steps: 1100,  Train Loss: 0.013535,  Train Acc: 50.00%,  Train Avg Loss: 0.006212,  Time: 0:52:50
Start evaluation on dev dataset.
Acc. (Correct/Total): 49.28% micro-Prec: 0.7022 micro-Recall:0.6152 micro-F1: 0.6414 dev loss: 0.035913
Start evaluation on test dataset.
Acc. (Correct/Total): 54.14% micro-Prec: 0.7472 micro-Recall:0.6574 micro-F1: 0.6858 dev loss: 0.030053
Epoch id: 15, Training steps: 0100,  Train Loss: 0.005803,  Train Acc: 62.50%,  Train Avg Loss: 0.007691,  Time: 0:53:40
Epoch id: 15, Training steps: 0200,  Train Loss: 0.015967,  Train Acc: 50.00%,  Train Avg Loss: 0.005145,  Time: 0:53:57
Epoch id: 15, Training steps: 0300,  Train Loss: 0.006429,  Train Acc: 75.00%,  Train Avg Loss: 0.004864,  Time: 0:54:15
Epoch id: 15, Training steps: 0400,  Train Loss: 0.005023,  Train Acc: 75.00%,  Train Avg Loss: 0.005275,  Time: 0:54:32
Epoch id: 15, Training steps: 0500,  Train Loss: 0.001970,  Train Acc: 87.50%,  Train Avg Loss: 0.004733,  Time: 0:54:50
Epoch id: 15, Training steps: 0600,  Train Loss: 0.004508,  Train Acc: 75.00%,  Train Avg Loss: 0.004703,  Time: 0:55:07
Epoch id: 15, Training steps: 0700,  Train Loss: 0.001079,  Train Acc: 100.00%,  Train Avg Loss: 0.004622,  Time: 0:55:25
Epoch id: 15, Training steps: 0800,  Train Loss: 0.010082,  Train Acc: 62.50%,  Train Avg Loss: 0.004603,  Time: 0:55:42
Epoch id: 15, Training steps: 0900,  Train Loss: 0.006010,  Train Acc: 75.00%,  Train Avg Loss: 0.004750,  Time: 0:56:00
Epoch id: 15, Training steps: 1000,  Train Loss: 0.002254,  Train Acc: 100.00%,  Train Avg Loss: 0.004299,  Time: 0:56:18
Epoch id: 15, Training steps: 1100,  Train Loss: 0.005244,  Train Acc: 75.00%,  Train Avg Loss: 0.004328,  Time: 0:56:35
Start evaluation on dev dataset.
Acc. (Correct/Total): 49.81% micro-Prec: 0.7048 micro-Recall:0.6229 micro-F1: 0.6469 dev loss: 0.036685
Start evaluation on test dataset.
Acc. (Correct/Total): 57.47% micro-Prec: 0.7724 micro-Recall:0.6870 micro-F1: 0.7139 dev loss: 0.029438
Epoch id: 16, Training steps: 0100,  Train Loss: 0.007286,  Train Acc: 25.00%,  Train Avg Loss: 0.005714,  Time: 0:57:27
Epoch id: 16, Training steps: 0200,  Train Loss: 0.006643,  Train Acc: 50.00%,  Train Avg Loss: 0.004270,  Time: 0:57:44
Epoch id: 16, Training steps: 0300,  Train Loss: 0.001347,  Train Acc: 100.00%,  Train Avg Loss: 0.004008,  Time: 0:58:02
Epoch id: 16, Training steps: 0400,  Train Loss: 0.001934,  Train Acc: 75.00%,  Train Avg Loss: 0.003741,  Time: 0:58:19
Epoch id: 16, Training steps: 0500,  Train Loss: 0.008054,  Train Acc: 50.00%,  Train Avg Loss: 0.004273,  Time: 0:58:37
Epoch id: 16, Training steps: 0600,  Train Loss: 0.002838,  Train Acc: 62.50%,  Train Avg Loss: 0.004031,  Time: 0:58:54
Epoch id: 16, Training steps: 0700,  Train Loss: 0.003020,  Train Acc: 75.00%,  Train Avg Loss: 0.003865,  Time: 0:59:12
Epoch id: 16, Training steps: 0800,  Train Loss: 0.009002,  Train Acc: 62.50%,  Train Avg Loss: 0.003878,  Time: 0:59:30
Epoch id: 16, Training steps: 0900,  Train Loss: 0.000935,  Train Acc: 87.50%,  Train Avg Loss: 0.003944,  Time: 0:59:47
Epoch id: 16, Training steps: 1000,  Train Loss: 0.006222,  Train Acc: 75.00%,  Train Avg Loss: 0.004013,  Time: 1:00:05
Epoch id: 16, Training steps: 1100,  Train Loss: 0.005141,  Train Acc: 62.50%,  Train Avg Loss: 0.003382,  Time: 1:00:22
Start evaluation on dev dataset.
Acc. (Correct/Total): 51.92% micro-Prec: 0.7210 micro-Recall:0.6437 micro-F1: 0.6661 dev loss: 0.036548
Start evaluation on test dataset.
Acc. (Correct/Total): 57.52% micro-Prec: 0.7621 micro-Recall:0.6870 micro-F1: 0.7101 dev loss: 0.029600
Epoch id: 17, Training steps: 0100,  Train Loss: 0.002433,  Train Acc: 75.00%,  Train Avg Loss: 0.004732,  Time: 1:01:13
Epoch id: 17, Training steps: 0200,  Train Loss: 0.004074,  Train Acc: 87.50%,  Train Avg Loss: 0.003211,  Time: 1:01:31
Epoch id: 17, Training steps: 0300,  Train Loss: 0.001151,  Train Acc: 100.00%,  Train Avg Loss: 0.003556,  Time: 1:01:48
Epoch id: 17, Training steps: 0400,  Train Loss: 0.004001,  Train Acc: 75.00%,  Train Avg Loss: 0.003551,  Time: 1:02:06
Epoch id: 17, Training steps: 0500,  Train Loss: 0.003014,  Train Acc: 87.50%,  Train Avg Loss: 0.003403,  Time: 1:02:23
Epoch id: 17, Training steps: 0600,  Train Loss: 0.002545,  Train Acc: 75.00%,  Train Avg Loss: 0.003689,  Time: 1:02:41
Epoch id: 17, Training steps: 0700,  Train Loss: 0.001339,  Train Acc: 87.50%,  Train Avg Loss: 0.003561,  Time: 1:02:58
Epoch id: 17, Training steps: 0800,  Train Loss: 0.004078,  Train Acc: 62.50%,  Train Avg Loss: 0.003396,  Time: 1:03:16
Epoch id: 17, Training steps: 0900,  Train Loss: 0.001592,  Train Acc: 87.50%,  Train Avg Loss: 0.003215,  Time: 1:03:34
Epoch id: 17, Training steps: 1000,  Train Loss: 0.005797,  Train Acc: 87.50%,  Train Avg Loss: 0.003835,  Time: 1:03:51
Epoch id: 17, Training steps: 1100,  Train Loss: 0.007185,  Train Acc: 62.50%,  Train Avg Loss: 0.003403,  Time: 1:04:09
Start evaluation on dev dataset.
Acc. (Correct/Total): 52.40% micro-Prec: 0.7232 micro-Recall:0.6516 micro-F1: 0.6713 dev loss: 0.037814
Start evaluation on test dataset.
Acc. (Correct/Total): 58.30% micro-Prec: 0.7702 micro-Recall:0.7000 micro-F1: 0.7204 dev loss: 0.031403
Epoch id: 18, Training steps: 0100,  Train Loss: 0.001054,  Train Acc: 87.50%,  Train Avg Loss: 0.004103,  Time: 1:05:00
Epoch id: 18, Training steps: 0200,  Train Loss: 0.002493,  Train Acc: 62.50%,  Train Avg Loss: 0.003050,  Time: 1:05:18
Epoch id: 18, Training steps: 0300,  Train Loss: 0.001617,  Train Acc: 87.50%,  Train Avg Loss: 0.002914,  Time: 1:05:35
Epoch id: 18, Training steps: 0400,  Train Loss: 0.002364,  Train Acc: 75.00%,  Train Avg Loss: 0.003068,  Time: 1:05:53
Epoch id: 18, Training steps: 0500,  Train Loss: 0.000990,  Train Acc: 100.00%,  Train Avg Loss: 0.003020,  Time: 1:06:11
Epoch id: 18, Training steps: 0600,  Train Loss: 0.002053,  Train Acc: 87.50%,  Train Avg Loss: 0.002932,  Time: 1:06:28
Epoch id: 18, Training steps: 0700,  Train Loss: 0.002207,  Train Acc: 62.50%,  Train Avg Loss: 0.002881,  Time: 1:06:46
Epoch id: 18, Training steps: 0800,  Train Loss: 0.002326,  Train Acc: 87.50%,  Train Avg Loss: 0.003566,  Time: 1:07:03
Epoch id: 18, Training steps: 0900,  Train Loss: 0.001756,  Train Acc: 75.00%,  Train Avg Loss: 0.002911,  Time: 1:07:21
Epoch id: 18, Training steps: 1000,  Train Loss: 0.001647,  Train Acc: 87.50%,  Train Avg Loss: 0.003295,  Time: 1:07:38
Epoch id: 18, Training steps: 1100,  Train Loss: 0.003075,  Train Acc: 62.50%,  Train Avg Loss: 0.003140,  Time: 1:07:56
Start evaluation on dev dataset.
Acc. (Correct/Total): 52.16% micro-Prec: 0.7150 micro-Recall:0.6443 micro-F1: 0.6638 dev loss: 0.038843
Epoch id: 19, Training steps: 0100,  Train Loss: 0.001537,  Train Acc: 87.50%,  Train Avg Loss: 0.003843,  Time: 1:08:33
Epoch id: 19, Training steps: 0200,  Train Loss: 0.002463,  Train Acc: 62.50%,  Train Avg Loss: 0.002489,  Time: 1:08:51
Epoch id: 19, Training steps: 0300,  Train Loss: 0.001260,  Train Acc: 87.50%,  Train Avg Loss: 0.002536,  Time: 1:09:09
Epoch id: 19, Training steps: 0400,  Train Loss: 0.000332,  Train Acc: 100.00%,  Train Avg Loss: 0.002647,  Time: 1:09:26
Epoch id: 19, Training steps: 0500,  Train Loss: 0.000769,  Train Acc: 87.50%,  Train Avg Loss: 0.002369,  Time: 1:09:44
Epoch id: 19, Training steps: 0600,  Train Loss: 0.001760,  Train Acc: 75.00%,  Train Avg Loss: 0.002279,  Time: 1:10:01
Epoch id: 19, Training steps: 0700,  Train Loss: 0.003730,  Train Acc: 87.50%,  Train Avg Loss: 0.002583,  Time: 1:10:19
Epoch id: 19, Training steps: 0800,  Train Loss: 0.002286,  Train Acc: 75.00%,  Train Avg Loss: 0.002415,  Time: 1:10:36
Epoch id: 19, Training steps: 0900,  Train Loss: 0.006887,  Train Acc: 75.00%,  Train Avg Loss: 0.002363,  Time: 1:10:54
Epoch id: 19, Training steps: 1000,  Train Loss: 0.001996,  Train Acc: 50.00%,  Train Avg Loss: 0.002663,  Time: 1:11:12
Epoch id: 19, Training steps: 1100,  Train Loss: 0.007907,  Train Acc: 75.00%,  Train Avg Loss: 0.002671,  Time: 1:11:29
Start evaluation on dev dataset.
Acc. (Correct/Total): 52.83% micro-Prec: 0.7167 micro-Recall:0.6495 micro-F1: 0.6682 dev loss: 0.038235
Start evaluation on test dataset.
Acc. (Correct/Total): 58.88% micro-Prec: 0.7700 micro-Recall:0.6990 micro-F1: 0.7203 dev loss: 0.031248
Epoch id: 20, Training steps: 0100,  Train Loss: 0.004138,  Train Acc: 75.00%,  Train Avg Loss: 0.003042,  Time: 1:12:20
Epoch id: 20, Training steps: 0200,  Train Loss: 0.001218,  Train Acc: 75.00%,  Train Avg Loss: 0.002184,  Time: 1:12:37
Epoch id: 20, Training steps: 0300,  Train Loss: 0.004083,  Train Acc: 75.00%,  Train Avg Loss: 0.002513,  Time: 1:12:55
Epoch id: 20, Training steps: 0400,  Train Loss: 0.006098,  Train Acc: 62.50%,  Train Avg Loss: 0.002606,  Time: 1:13:12
Epoch id: 20, Training steps: 0500,  Train Loss: 0.001500,  Train Acc: 87.50%,  Train Avg Loss: 0.002184,  Time: 1:13:30
Epoch id: 20, Training steps: 0600,  Train Loss: 0.001448,  Train Acc: 75.00%,  Train Avg Loss: 0.002150,  Time: 1:13:48
Epoch id: 20, Training steps: 0700,  Train Loss: 0.004059,  Train Acc: 50.00%,  Train Avg Loss: 0.002167,  Time: 1:14:05
Epoch id: 20, Training steps: 0800,  Train Loss: 0.001342,  Train Acc: 75.00%,  Train Avg Loss: 0.002401,  Time: 1:14:23
Epoch id: 20, Training steps: 0900,  Train Loss: 0.002313,  Train Acc: 75.00%,  Train Avg Loss: 0.002155,  Time: 1:14:40
Epoch id: 20, Training steps: 1000,  Train Loss: 0.001611,  Train Acc: 87.50%,  Train Avg Loss: 0.002225,  Time: 1:14:58
Epoch id: 20, Training steps: 1100,  Train Loss: 0.000490,  Train Acc: 100.00%,  Train Avg Loss: 0.002002,  Time: 1:15:15
Start evaluation on dev dataset.
Acc. (Correct/Total): 53.79% micro-Prec: 0.7238 micro-Recall:0.6651 micro-F1: 0.6796 dev loss: 0.039043
Start evaluation on test dataset.
Acc. (Correct/Total): 60.91% micro-Prec: 0.7879 micro-Recall:0.7217 micro-F1: 0.7411 dev loss: 0.031175
Epoch id: 21, Training steps: 0100,  Train Loss: 0.001291,  Train Acc: 87.50%,  Train Avg Loss: 0.002651,  Time: 1:16:07
Epoch id: 21, Training steps: 0200,  Train Loss: 0.000749,  Train Acc: 75.00%,  Train Avg Loss: 0.001781,  Time: 1:16:24
Epoch id: 21, Training steps: 0300,  Train Loss: 0.000676,  Train Acc: 100.00%,  Train Avg Loss: 0.001899,  Time: 1:16:42
Epoch id: 21, Training steps: 0400,  Train Loss: 0.001035,  Train Acc: 87.50%,  Train Avg Loss: 0.001533,  Time: 1:16:59
Epoch id: 21, Training steps: 0500,  Train Loss: 0.001408,  Train Acc: 75.00%,  Train Avg Loss: 0.001686,  Time: 1:17:17
Epoch id: 21, Training steps: 0600,  Train Loss: 0.002259,  Train Acc: 75.00%,  Train Avg Loss: 0.002017,  Time: 1:17:34
Epoch id: 21, Training steps: 0700,  Train Loss: 0.003962,  Train Acc: 62.50%,  Train Avg Loss: 0.002013,  Time: 1:17:52
Epoch id: 21, Training steps: 0800,  Train Loss: 0.003430,  Train Acc: 75.00%,  Train Avg Loss: 0.001873,  Time: 1:18:10
Epoch id: 21, Training steps: 0900,  Train Loss: 0.000969,  Train Acc: 100.00%,  Train Avg Loss: 0.002202,  Time: 1:18:27
Epoch id: 21, Training steps: 1000,  Train Loss: 0.000924,  Train Acc: 87.50%,  Train Avg Loss: 0.001907,  Time: 1:18:45
Epoch id: 21, Training steps: 1100,  Train Loss: 0.004115,  Train Acc: 87.50%,  Train Avg Loss: 0.002111,  Time: 1:19:02
Start evaluation on dev dataset.
Acc. (Correct/Total): 55.13% micro-Prec: 0.7386 micro-Recall:0.6854 micro-F1: 0.6971 dev loss: 0.039297
Start evaluation on test dataset.
Acc. (Correct/Total): 61.15% micro-Prec: 0.7862 micro-Recall:0.7280 micro-F1: 0.7439 dev loss: 0.031674
Epoch id: 22, Training steps: 0100,  Train Loss: 0.001063,  Train Acc: 87.50%,  Train Avg Loss: 0.002459,  Time: 1:19:54
Epoch id: 22, Training steps: 0200,  Train Loss: 0.000690,  Train Acc: 87.50%,  Train Avg Loss: 0.001582,  Time: 1:20:12
Epoch id: 22, Training steps: 0300,  Train Loss: 0.004111,  Train Acc: 75.00%,  Train Avg Loss: 0.001756,  Time: 1:20:29
Epoch id: 22, Training steps: 0400,  Train Loss: 0.002861,  Train Acc: 87.50%,  Train Avg Loss: 0.001663,  Time: 1:20:47
Epoch id: 22, Training steps: 0500,  Train Loss: 0.001465,  Train Acc: 75.00%,  Train Avg Loss: 0.001890,  Time: 1:21:04
Epoch id: 22, Training steps: 0600,  Train Loss: 0.000762,  Train Acc: 100.00%,  Train Avg Loss: 0.001536,  Time: 1:21:22
Epoch id: 22, Training steps: 0700,  Train Loss: 0.013065,  Train Acc: 62.50%,  Train Avg Loss: 0.001608,  Time: 1:21:39
Epoch id: 22, Training steps: 0800,  Train Loss: 0.000796,  Train Acc: 100.00%,  Train Avg Loss: 0.001506,  Time: 1:21:57
Epoch id: 22, Training steps: 0900,  Train Loss: 0.006339,  Train Acc: 87.50%,  Train Avg Loss: 0.001882,  Time: 1:22:15
Epoch id: 22, Training steps: 1000,  Train Loss: 0.000540,  Train Acc: 100.00%,  Train Avg Loss: 0.001710,  Time: 1:22:32
Epoch id: 22, Training steps: 1100,  Train Loss: 0.001522,  Train Acc: 100.00%,  Train Avg Loss: 0.001440,  Time: 1:22:50
Start evaluation on dev dataset.
Acc. (Correct/Total): 54.94% micro-Prec: 0.7278 micro-Recall:0.6723 micro-F1: 0.6861 dev loss: 0.039201
Epoch id: 23, Training steps: 0100,  Train Loss: 0.001192,  Train Acc: 87.50%,  Train Avg Loss: 0.001968,  Time: 1:23:27
Epoch id: 23, Training steps: 0200,  Train Loss: 0.000520,  Train Acc: 100.00%,  Train Avg Loss: 0.001412,  Time: 1:23:45
Epoch id: 23, Training steps: 0300,  Train Loss: 0.001863,  Train Acc: 87.50%,  Train Avg Loss: 0.001383,  Time: 1:24:02
Epoch id: 23, Training steps: 0400,  Train Loss: 0.000835,  Train Acc: 87.50%,  Train Avg Loss: 0.001663,  Time: 1:24:20
Epoch id: 23, Training steps: 0500,  Train Loss: 0.000735,  Train Acc: 100.00%,  Train Avg Loss: 0.001574,  Time: 1:24:37
Epoch id: 23, Training steps: 0600,  Train Loss: 0.001055,  Train Acc: 87.50%,  Train Avg Loss: 0.001272,  Time: 1:24:55
Epoch id: 23, Training steps: 0700,  Train Loss: 0.000729,  Train Acc: 100.00%,  Train Avg Loss: 0.001181,  Time: 1:25:12
Epoch id: 23, Training steps: 0800,  Train Loss: 0.000190,  Train Acc: 100.00%,  Train Avg Loss: 0.001387,  Time: 1:25:30
Epoch id: 23, Training steps: 0900,  Train Loss: 0.001648,  Train Acc: 87.50%,  Train Avg Loss: 0.001548,  Time: 1:25:48
Epoch id: 23, Training steps: 1000,  Train Loss: 0.000565,  Train Acc: 100.00%,  Train Avg Loss: 0.001310,  Time: 1:26:05
Epoch id: 23, Training steps: 1100,  Train Loss: 0.000685,  Train Acc: 100.00%,  Train Avg Loss: 0.001520,  Time: 1:26:23
Start evaluation on dev dataset.
Acc. (Correct/Total): 54.65% micro-Prec: 0.7397 micro-Recall:0.6798 micro-F1: 0.6943 dev loss: 0.040788
Epoch id: 24, Training steps: 0100,  Train Loss: 0.000674,  Train Acc: 87.50%,  Train Avg Loss: 0.001877,  Time: 1:27:00
Epoch id: 24, Training steps: 0200,  Train Loss: 0.001114,  Train Acc: 100.00%,  Train Avg Loss: 0.001217,  Time: 1:27:18
Epoch id: 24, Training steps: 0300,  Train Loss: 0.001670,  Train Acc: 75.00%,  Train Avg Loss: 0.001248,  Time: 1:27:35
Epoch id: 24, Training steps: 0400,  Train Loss: 0.001308,  Train Acc: 87.50%,  Train Avg Loss: 0.001119,  Time: 1:27:53
Epoch id: 24, Training steps: 0500,  Train Loss: 0.006032,  Train Acc: 50.00%,  Train Avg Loss: 0.001183,  Time: 1:28:11
Epoch id: 24, Training steps: 0600,  Train Loss: 0.001725,  Train Acc: 87.50%,  Train Avg Loss: 0.001385,  Time: 1:28:28
Epoch id: 24, Training steps: 0700,  Train Loss: 0.000827,  Train Acc: 100.00%,  Train Avg Loss: 0.001121,  Time: 1:28:46
Epoch id: 24, Training steps: 0800,  Train Loss: 0.001207,  Train Acc: 100.00%,  Train Avg Loss: 0.000962,  Time: 1:29:03
Epoch id: 24, Training steps: 0900,  Train Loss: 0.000652,  Train Acc: 100.00%,  Train Avg Loss: 0.001089,  Time: 1:29:21
Epoch id: 24, Training steps: 1000,  Train Loss: 0.000551,  Train Acc: 87.50%,  Train Avg Loss: 0.001241,  Time: 1:29:38
Epoch id: 24, Training steps: 1100,  Train Loss: 0.001115,  Train Acc: 87.50%,  Train Avg Loss: 0.001230,  Time: 1:29:56
Start evaluation on dev dataset.
Acc. (Correct/Total): 55.23% micro-Prec: 0.7394 micro-Recall:0.6839 micro-F1: 0.6968 dev loss: 0.040278
Start evaluation on test dataset.
Acc. (Correct/Total): 61.15% micro-Prec: 0.7841 micro-Recall:0.7263 micro-F1: 0.7420 dev loss: 0.032911
Epoch id: 25, Training steps: 0100,  Train Loss: 0.000252,  Train Acc: 100.00%,  Train Avg Loss: 0.001609,  Time: 1:30:47
Epoch id: 25, Training steps: 0200,  Train Loss: 0.000420,  Train Acc: 100.00%,  Train Avg Loss: 0.000899,  Time: 1:31:04
Epoch id: 25, Training steps: 0300,  Train Loss: 0.001054,  Train Acc: 87.50%,  Train Avg Loss: 0.001015,  Time: 1:31:22
Epoch id: 25, Training steps: 0400,  Train Loss: 0.000837,  Train Acc: 100.00%,  Train Avg Loss: 0.001117,  Time: 1:31:39
Epoch id: 25, Training steps: 0500,  Train Loss: 0.000961,  Train Acc: 100.00%,  Train Avg Loss: 0.001094,  Time: 1:31:57
Epoch id: 25, Training steps: 0600,  Train Loss: 0.001141,  Train Acc: 100.00%,  Train Avg Loss: 0.001235,  Time: 1:32:14
Epoch id: 25, Training steps: 0700,  Train Loss: 0.000452,  Train Acc: 100.00%,  Train Avg Loss: 0.000977,  Time: 1:32:32
Epoch id: 25, Training steps: 0800,  Train Loss: 0.001025,  Train Acc: 87.50%,  Train Avg Loss: 0.001150,  Time: 1:32:50
Epoch id: 25, Training steps: 0900,  Train Loss: 0.000843,  Train Acc: 100.00%,  Train Avg Loss: 0.001131,  Time: 1:33:07
Epoch id: 25, Training steps: 1000,  Train Loss: 0.001047,  Train Acc: 87.50%,  Train Avg Loss: 0.001148,  Time: 1:33:25
Epoch id: 25, Training steps: 1100,  Train Loss: 0.000459,  Train Acc: 100.00%,  Train Avg Loss: 0.000973,  Time: 1:33:42
Start evaluation on dev dataset.
Acc. (Correct/Total): 56.00% micro-Prec: 0.7435 micro-Recall:0.6936 micro-F1: 0.7038 dev loss: 0.040800
Start evaluation on test dataset.
Acc. (Correct/Total): 61.78% micro-Prec: 0.7920 micro-Recall:0.7383 micro-F1: 0.7518 dev loss: 0.033094
Epoch id: 26, Training steps: 0100,  Train Loss: 0.002716,  Train Acc: 87.50%,  Train Avg Loss: 0.001603,  Time: 1:34:34
Epoch id: 26, Training steps: 0200,  Train Loss: 0.000363,  Train Acc: 100.00%,  Train Avg Loss: 0.001003,  Time: 1:34:52
Epoch id: 26, Training steps: 0300,  Train Loss: 0.001112,  Train Acc: 100.00%,  Train Avg Loss: 0.000967,  Time: 1:35:09
Epoch id: 26, Training steps: 0400,  Train Loss: 0.001165,  Train Acc: 100.00%,  Train Avg Loss: 0.001017,  Time: 1:35:27
Epoch id: 26, Training steps: 0500,  Train Loss: 0.000423,  Train Acc: 100.00%,  Train Avg Loss: 0.001197,  Time: 1:35:44
Epoch id: 26, Training steps: 0600,  Train Loss: 0.000536,  Train Acc: 100.00%,  Train Avg Loss: 0.001202,  Time: 1:36:02
Epoch id: 26, Training steps: 0700,  Train Loss: 0.001284,  Train Acc: 75.00%,  Train Avg Loss: 0.000963,  Time: 1:36:19
Epoch id: 26, Training steps: 0800,  Train Loss: 0.000326,  Train Acc: 100.00%,  Train Avg Loss: 0.000977,  Time: 1:36:37
Epoch id: 26, Training steps: 0900,  Train Loss: 0.000506,  Train Acc: 100.00%,  Train Avg Loss: 0.000845,  Time: 1:36:54
Epoch id: 26, Training steps: 1000,  Train Loss: 0.000783,  Train Acc: 87.50%,  Train Avg Loss: 0.001238,  Time: 1:37:12
Epoch id: 26, Training steps: 1100,  Train Loss: 0.001816,  Train Acc: 87.50%,  Train Avg Loss: 0.001077,  Time: 1:37:30
Start evaluation on dev dataset.
Acc. (Correct/Total): 55.52% micro-Prec: 0.7354 micro-Recall:0.6891 micro-F1: 0.6979 dev loss: 0.041421
Epoch id: 27, Training steps: 0100,  Train Loss: 0.001173,  Train Acc: 87.50%,  Train Avg Loss: 0.001281,  Time: 1:38:07
Epoch id: 27, Training steps: 0200,  Train Loss: 0.001982,  Train Acc: 62.50%,  Train Avg Loss: 0.000712,  Time: 1:38:25
Epoch id: 27, Training steps: 0300,  Train Loss: 0.001653,  Train Acc: 75.00%,  Train Avg Loss: 0.000790,  Time: 1:38:42
Epoch id: 27, Training steps: 0400,  Train Loss: 0.000342,  Train Acc: 100.00%,  Train Avg Loss: 0.000969,  Time: 1:39:00
Epoch id: 27, Training steps: 0500,  Train Loss: 0.000261,  Train Acc: 100.00%,  Train Avg Loss: 0.000749,  Time: 1:39:17
Epoch id: 27, Training steps: 0600,  Train Loss: 0.001795,  Train Acc: 75.00%,  Train Avg Loss: 0.000823,  Time: 1:39:35
Epoch id: 27, Training steps: 0700,  Train Loss: 0.000839,  Train Acc: 87.50%,  Train Avg Loss: 0.000855,  Time: 1:39:52
Epoch id: 27, Training steps: 0800,  Train Loss: 0.000630,  Train Acc: 87.50%,  Train Avg Loss: 0.000911,  Time: 1:40:10
Epoch id: 27, Training steps: 0900,  Train Loss: 0.001337,  Train Acc: 87.50%,  Train Avg Loss: 0.000823,  Time: 1:40:27
Epoch id: 27, Training steps: 1000,  Train Loss: 0.000358,  Train Acc: 100.00%,  Train Avg Loss: 0.000841,  Time: 1:40:45
Epoch id: 27, Training steps: 1100,  Train Loss: 0.000223,  Train Acc: 100.00%,  Train Avg Loss: 0.000986,  Time: 1:41:03
Start evaluation on dev dataset.
Acc. (Correct/Total): 55.52% micro-Prec: 0.7410 micro-Recall:0.6915 micro-F1: 0.7012 dev loss: 0.041510
Epoch id: 28, Training steps: 0100,  Train Loss: 0.001174,  Train Acc: 87.50%,  Train Avg Loss: 0.001081,  Time: 1:41:40
Epoch id: 28, Training steps: 0200,  Train Loss: 0.000531,  Train Acc: 100.00%,  Train Avg Loss: 0.000787,  Time: 1:41:58
Epoch id: 28, Training steps: 0300,  Train Loss: 0.001576,  Train Acc: 87.50%,  Train Avg Loss: 0.000860,  Time: 1:42:15
Epoch id: 28, Training steps: 0400,  Train Loss: 0.000804,  Train Acc: 87.50%,  Train Avg Loss: 0.000746,  Time: 1:42:33
Epoch id: 28, Training steps: 0500,  Train Loss: 0.000886,  Train Acc: 87.50%,  Train Avg Loss: 0.000742,  Time: 1:42:50
Epoch id: 28, Training steps: 0600,  Train Loss: 0.000162,  Train Acc: 100.00%,  Train Avg Loss: 0.000710,  Time: 1:43:08
Epoch id: 28, Training steps: 0700,  Train Loss: 0.000967,  Train Acc: 87.50%,  Train Avg Loss: 0.000741,  Time: 1:43:25
Epoch id: 28, Training steps: 0800,  Train Loss: 0.000233,  Train Acc: 100.00%,  Train Avg Loss: 0.000853,  Time: 1:43:43
Epoch id: 28, Training steps: 0900,  Train Loss: 0.001321,  Train Acc: 75.00%,  Train Avg Loss: 0.000838,  Time: 1:44:01
Epoch id: 28, Training steps: 1000,  Train Loss: 0.000268,  Train Acc: 100.00%,  Train Avg Loss: 0.000780,  Time: 1:44:18
Epoch id: 28, Training steps: 1100,  Train Loss: 0.000434,  Train Acc: 100.00%,  Train Avg Loss: 0.000788,  Time: 1:44:36
Start evaluation on dev dataset.
Acc. (Correct/Total): 56.19% micro-Prec: 0.7406 micro-Recall:0.6914 micro-F1: 0.7018 dev loss: 0.041500
Start evaluation on test dataset.
Acc. (Correct/Total): 62.41% micro-Prec: 0.7896 micro-Recall:0.7363 micro-F1: 0.7502 dev loss: 0.033383
Epoch id: 29, Training steps: 0100,  Train Loss: 0.000144,  Train Acc: 100.00%,  Train Avg Loss: 0.001123,  Time: 1:45:27
Epoch id: 29, Training steps: 0200,  Train Loss: 0.000224,  Train Acc: 100.00%,  Train Avg Loss: 0.000704,  Time: 1:45:44
Epoch id: 29, Training steps: 0300,  Train Loss: 0.002707,  Train Acc: 75.00%,  Train Avg Loss: 0.000655,  Time: 1:46:02
Epoch id: 29, Training steps: 0400,  Train Loss: 0.000406,  Train Acc: 100.00%,  Train Avg Loss: 0.000655,  Time: 1:46:19
Epoch id: 29, Training steps: 0500,  Train Loss: 0.000535,  Train Acc: 100.00%,  Train Avg Loss: 0.000553,  Time: 1:46:37
Epoch id: 29, Training steps: 0600,  Train Loss: 0.000573,  Train Acc: 87.50%,  Train Avg Loss: 0.000783,  Time: 1:46:55
Epoch id: 29, Training steps: 0700,  Train Loss: 0.002693,  Train Acc: 87.50%,  Train Avg Loss: 0.000700,  Time: 1:47:12
Epoch id: 29, Training steps: 0800,  Train Loss: 0.000296,  Train Acc: 100.00%,  Train Avg Loss: 0.000759,  Time: 1:47:30
Epoch id: 29, Training steps: 0900,  Train Loss: 0.000179,  Train Acc: 100.00%,  Train Avg Loss: 0.000606,  Time: 1:47:47
Epoch id: 29, Training steps: 1000,  Train Loss: 0.001313,  Train Acc: 87.50%,  Train Avg Loss: 0.000749,  Time: 1:48:05
Epoch id: 29, Training steps: 1100,  Train Loss: 0.000636,  Train Acc: 87.50%,  Train Avg Loss: 0.000652,  Time: 1:48:22
Start evaluation on dev dataset.
Acc. (Correct/Total): 56.38% micro-Prec: 0.7442 micro-Recall:0.6995 micro-F1: 0.7072 dev loss: 0.042198
Start evaluation on test dataset.
Acc. (Correct/Total): 62.26% micro-Prec: 0.7990 micro-Recall:0.7425 micro-F1: 0.7568 dev loss: 0.033916
Epoch id: 30, Training steps: 0100,  Train Loss: 0.000558,  Train Acc: 87.50%,  Train Avg Loss: 0.001006,  Time: 1:49:14
Epoch id: 30, Training steps: 0200,  Train Loss: 0.001545,  Train Acc: 87.50%,  Train Avg Loss: 0.000632,  Time: 1:49:31
Epoch id: 30, Training steps: 0300,  Train Loss: 0.000556,  Train Acc: 100.00%,  Train Avg Loss: 0.000575,  Time: 1:49:49
Epoch id: 30, Training steps: 0400,  Train Loss: 0.000519,  Train Acc: 100.00%,  Train Avg Loss: 0.000684,  Time: 1:50:07
Epoch id: 30, Training steps: 0500,  Train Loss: 0.000882,  Train Acc: 100.00%,  Train Avg Loss: 0.000573,  Time: 1:50:24
Epoch id: 30, Training steps: 0600,  Train Loss: 0.000711,  Train Acc: 100.00%,  Train Avg Loss: 0.000617,  Time: 1:50:42
Epoch id: 30, Training steps: 0700,  Train Loss: 0.001097,  Train Acc: 100.00%,  Train Avg Loss: 0.000597,  Time: 1:50:59
Epoch id: 30, Training steps: 0800,  Train Loss: 0.000458,  Train Acc: 100.00%,  Train Avg Loss: 0.000654,  Time: 1:51:17
Epoch id: 30, Training steps: 0900,  Train Loss: 0.000309,  Train Acc: 100.00%,  Train Avg Loss: 0.000709,  Time: 1:51:34
Epoch id: 30, Training steps: 1000,  Train Loss: 0.000139,  Train Acc: 100.00%,  Train Avg Loss: 0.000633,  Time: 1:51:52
Epoch id: 30, Training steps: 1100,  Train Loss: 0.000189,  Train Acc: 100.00%,  Train Avg Loss: 0.000643,  Time: 1:52:10
Start evaluation on dev dataset.
Acc. (Correct/Total): 56.43% micro-Prec: 0.7475 micro-Recall:0.7002 micro-F1: 0.7087 dev loss: 0.042272
Start evaluation on test dataset.
Acc. (Correct/Total): 62.07% micro-Prec: 0.7995 micro-Recall:0.7446 micro-F1: 0.7579 dev loss: 0.033980
Epoch id: 31, Training steps: 0100,  Train Loss: 0.000428,  Train Acc: 100.00%,  Train Avg Loss: 0.000831,  Time: 1:53:01
Epoch id: 31, Training steps: 0200,  Train Loss: 0.000420,  Train Acc: 100.00%,  Train Avg Loss: 0.000674,  Time: 1:53:19
Epoch id: 31, Training steps: 0300,  Train Loss: 0.000221,  Train Acc: 100.00%,  Train Avg Loss: 0.000550,  Time: 1:53:36
Epoch id: 31, Training steps: 0400,  Train Loss: 0.000150,  Train Acc: 100.00%,  Train Avg Loss: 0.000637,  Time: 1:53:54
Epoch id: 31, Training steps: 0500,  Train Loss: 0.000454,  Train Acc: 100.00%,  Train Avg Loss: 0.000694,  Time: 1:54:11
Epoch id: 31, Training steps: 0600,  Train Loss: 0.000401,  Train Acc: 100.00%,  Train Avg Loss: 0.000561,  Time: 1:54:29
Epoch id: 31, Training steps: 0700,  Train Loss: 0.000744,  Train Acc: 87.50%,  Train Avg Loss: 0.000582,  Time: 1:54:47
Epoch id: 31, Training steps: 0800,  Train Loss: 0.000517,  Train Acc: 100.00%,  Train Avg Loss: 0.000605,  Time: 1:55:04
Epoch id: 31, Training steps: 0900,  Train Loss: 0.000241,  Train Acc: 100.00%,  Train Avg Loss: 0.000583,  Time: 1:55:22
Epoch id: 31, Training steps: 1000,  Train Loss: 0.001194,  Train Acc: 75.00%,  Train Avg Loss: 0.000579,  Time: 1:55:39
Epoch id: 31, Training steps: 1100,  Train Loss: 0.000443,  Train Acc: 100.00%,  Train Avg Loss: 0.000552,  Time: 1:55:57
Start evaluation on dev dataset.
Acc. (Correct/Total): 55.71% micro-Prec: 0.7411 micro-Recall:0.6969 micro-F1: 0.7042 dev loss: 0.042619
Epoch id: 32, Training steps: 0100,  Train Loss: 0.000725,  Train Acc: 100.00%,  Train Avg Loss: 0.000777,  Time: 1:56:34
Epoch id: 32, Training steps: 0200,  Train Loss: 0.000925,  Train Acc: 87.50%,  Train Avg Loss: 0.000554,  Time: 1:56:52
Epoch id: 32, Training steps: 0300,  Train Loss: 0.001014,  Train Acc: 75.00%,  Train Avg Loss: 0.000622,  Time: 1:57:09
Epoch id: 32, Training steps: 0400,  Train Loss: 0.001296,  Train Acc: 87.50%,  Train Avg Loss: 0.000557,  Time: 1:57:27
Epoch id: 32, Training steps: 0500,  Train Loss: 0.000178,  Train Acc: 100.00%,  Train Avg Loss: 0.000590,  Time: 1:57:45
Epoch id: 32, Training steps: 0600,  Train Loss: 0.001594,  Train Acc: 75.00%,  Train Avg Loss: 0.000596,  Time: 1:58:02
Epoch id: 32, Training steps: 0700,  Train Loss: 0.000643,  Train Acc: 87.50%,  Train Avg Loss: 0.000561,  Time: 1:58:20
Epoch id: 32, Training steps: 0800,  Train Loss: 0.000193,  Train Acc: 100.00%,  Train Avg Loss: 0.000503,  Time: 1:58:37
Epoch id: 32, Training steps: 0900,  Train Loss: 0.000791,  Train Acc: 87.50%,  Train Avg Loss: 0.000602,  Time: 1:58:55
Epoch id: 32, Training steps: 1000,  Train Loss: 0.000299,  Train Acc: 100.00%,  Train Avg Loss: 0.000598,  Time: 1:59:13
Epoch id: 32, Training steps: 1100,  Train Loss: 0.000463,  Train Acc: 100.00%,  Train Avg Loss: 0.000462,  Time: 1:59:30
Start evaluation on dev dataset.
Acc. (Correct/Total): 56.24% micro-Prec: 0.7435 micro-Recall:0.6995 micro-F1: 0.7070 dev loss: 0.042620
Final evaluation on the test dataset.
The number of evaluation instances:  2067
Acc. (Correct/Total): 62.07% micro-Prec: 0.7995 micro-Recall:0.7446 micro-F1: 0.7579 dev loss: 0.033980
              precision    recall  f1-score   support

         教育学     0.9065    0.9253    0.9158       241
          法学     0.8967    0.8527    0.8741       224
      中国语言文学     0.8537    0.7568    0.8023       185
         政治学     0.7600    0.6994    0.7284       163
         社会学     0.8601    0.7834    0.8200       157
         心理学     0.8554    0.5772    0.6893       123
       应用经济学     0.7907    0.5812    0.6700       117
         历史学     0.9844    0.5780    0.7283       109
     环境科学与工程     0.8774    0.8611    0.8692       108
          哲学     0.8571    0.6186    0.7186        97
      外国语言文学     0.8143    0.6706    0.7355        85
         生物学     0.8442    0.8228    0.8333        79
      交通运输工程     0.9000    0.9231    0.9114        78
        临床医学     0.8571    0.7105    0.7770        76
    计算机科学与技术     0.7465    0.7465    0.7465        71
        土木工程     0.9265    0.9545    0.9403        66
   航空宇航科学与技术     0.9344    0.9344    0.9344        61
         民族学     0.7500    0.4909    0.5934        55
   公共卫生与预防医学     0.6364    0.6863    0.6604        51
         美术学     0.8909    0.9800    0.9333        50
         艺术学     0.8140    0.8140    0.8140        43
         地理学     0.8710    0.6429    0.7397        42
         体育学     0.8846    0.5750    0.6970        40
       理论经济学     0.7250    0.7632    0.7436        38
         中医学     0.8857    0.8378    0.8611        37
         物理学     0.8421    0.8889    0.8649        36
          林学     0.8333    0.6061    0.7018        33
          数学     0.6818    0.4688    0.5556        32
     电子科学与技术     0.6667    0.3871    0.4898        31
        基础医学     0.3704    0.3448    0.3571        29
        工商管理     0.8421    0.5926    0.6957        27
       新闻传播学     0.8750    0.6364    0.7368        22
         天文学     0.8571    0.8182    0.8372        22
         地质学     1.0000    0.6667    0.8000        21
         畜牧学     0.8636    0.9048    0.8837        21
   军事思想及军事历史     0.7895    0.7500    0.7692        20
     管理科学与工程     0.6190    0.7222    0.6667        18
     测绘科学与技术     0.7333    0.6471    0.6875        17
        水利工程     0.9231    0.7500    0.8276        16
        大气科学     0.8000    0.7500    0.7742        16
     兵器科学与技术     0.5909    0.8667    0.7027        15
       地球物理学     0.6250    0.3571    0.4545        14
        电气工程     1.0000    0.4615    0.6316        13
         作物学     0.7000    0.5385    0.6087        13
     控制科学与工程     0.3636    0.3077    0.3333        13
     信息与通信工程     0.7143    0.7692    0.7407        13
        公共管理     0.2857    0.1538    0.2000        13
         建筑学     1.0000    0.5385    0.7000        13
     化学工程与技术     0.8182    0.7500    0.7826        12
          力学     0.6667    0.3636    0.4706        11
        海洋科学     0.9000    0.8182    0.8571        11
     轻工技术与工程     0.4167    0.4545    0.4348        11
        农业工程     1.0000    0.6000    0.7500        10
         园艺学     0.7778    0.7000    0.7368        10
       中西医结合     1.0000    0.3000    0.4615        10
        机械工程     1.0000    0.6667    0.8000         9
       科学技术史     1.0000    0.7500    0.8571         8
     船舶与海洋工程     0.8750    0.8750    0.8750         8
   图书情报与档案管理     0.8571    0.7500    0.8000         8
        植物保护     0.8889    1.0000    0.9412         8
     材料科学与工程     0.8571    0.7500    0.8000         8
         统计学     0.6364    0.8750    0.7368         8
          化学     1.0000    0.8750    0.9333         8
     食品科学与工程     1.0000    0.5000    0.6667         8
          水产     1.0000    0.7143    0.8333         7
          药学     0.8571    0.8571    0.8571         7
     农业资源与环境     1.0000    0.5714    0.7273         7
         世界史     0.8750    1.0000    0.9333         7
        系统科学     0.8000    0.5714    0.6667         7
      农林经济管理     0.6667    0.8000    0.7273         5
       军队指挥学     1.0000    0.4000    0.5714         5
        矿业工程     0.6000    0.6000    0.6000         5
     纺织科学与工程     0.7143    1.0000    0.8333         5
  动力工程及工程热物理     0.0000    0.0000    0.0000         4
        林业工程     0.5000    0.5000    0.5000         4
     仪器科学与技术     0.0000    0.0000    0.0000         3
         战略学     1.0000    0.3333    0.5000         3
   地质资源与地质工程     0.6000    1.0000    0.7500         3
        旅游管理     1.0000    0.6667    0.8000         3
 图书馆、情报与档案管理     0.0000    0.0000    0.0000         2
        冶金工程     1.0000    1.0000    1.0000         2
      核科学与技术     0.0000    0.0000    0.0000         2

   micro avg     0.8339    0.7307    0.7789      3093
   macro avg     0.7732    0.6555    0.6946      3093
weighted avg     0.8339    0.7307    0.7715      3093
 samples avg     0.7995    0.7446    0.7579      3093


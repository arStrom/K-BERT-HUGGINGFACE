nohup: 忽略输入
  0%|          | 0/82 [00:00<?, ?it/s]100%|██████████| 82/82 [00:00<00:00, 815006.94it/s]
model:  ernie-rcnn-catlstmwide
pretrained:  ernie1
task:  MLC-slice
dataset:  book_multilabels_task_slice
seq_length:  256
hidden_dropout_prob:  0.1
attention_probs_dropout_prob:  0.1
epochs_num:  20
batch_size:  8
learning_rate:  2e-05
report_steps:  100
kg_name:  CnDbpedia
no_kg:  True
no_vm:  True
GPU:  NVIDIA GeForce RTX 2080 Ti
Vocabulary Size:  17964
[BertClassifier] use visible_matrix: False
Some weights of ErnieRCNNForMultiLabelSequenceClassificationSliceCatLSTMWide were not initialized from the model checkpoint at ./models/ernie1 and are newly initialized: ['output_layer_1.bias', 'lstm.bias_ih_l1', 'lstm.bias_ih_l0', 'lstm.weight_ih_l0', 'output_layer_1.weight', 'lstm.bias_ih_l1_reverse', 'lstm.weight_hh_l1_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.bias_hh_l0_reverse', 'lstm.weight_hh_l0', 'classifier.weight', 'classifier.bias', 'lstm.bias_hh_l1', 'lstm.bias_hh_l0', 'lstm.bias_ih_l0_reverse', 'lstm.weight_hh_l1', 'lstm.weight_ih_l1_reverse', 'lstm.weight_ih_l1', 'lstm.weight_ih_l0_reverse', 'lstm.bias_hh_l1_reverse']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
1 GPUs are available. Let's use them.
device:  cuda
Start training.
Loading sentences from ./datasets/book_multilabels_task_slice/train.tsv
There are 9097 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/9097
Loading sentences from ./datasets/book_multilabels_task_slice/dev.tsv
There are 2084 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/2084
Loading sentences from ./datasets/book_multilabels_task_slice/test.tsv
There are 2067 sentence in total. We use 1 processes to inject knowledge into sentences.
Progress of process 0: 0/2067
Epoch id: 1, Training steps: 100, Train Acc:  0.00%, Train Loss: 0.751233, Train Avg Loss: 0.812443, Time: 0:00:48
Epoch id: 1, Training steps: 200, Train Acc:  0.00%, Train Loss: 0.477275, Train Avg Loss: 0.616014, Time: 0:01:38
Epoch id: 1, Training steps: 300, Train Acc:  0.00%, Train Loss: 0.253202, Train Avg Loss: 0.353110, Time: 0:02:28
Epoch id: 1, Training steps: 400, Train Acc:  0.00%, Train Loss: 0.124278, Train Avg Loss: 0.174636, Time: 0:03:18
Epoch id: 1, Training steps: 500, Train Acc:  0.00%, Train Loss: 0.104801, Train Avg Loss: 0.108200, Time: 0:04:08
Epoch id: 1, Training steps: 600, Train Acc:  0.00%, Train Loss: 0.087637, Train Avg Loss: 0.092033, Time: 0:04:59
Epoch id: 1, Training steps: 700, Train Acc:  0.00%, Train Loss: 0.097535, Train Avg Loss: 0.086983, Time: 0:05:49
Epoch id: 1, Training steps: 800, Train Acc:  0.00%, Train Loss: 0.082278, Train Avg Loss: 0.083972, Time: 0:06:39
Epoch id: 1, Training steps: 900, Train Acc:  0.00%, Train Loss: 0.086959, Train Avg Loss: 0.081578, Time: 0:07:30
Epoch id: 1, Training steps: 1000, Train Acc:  0.00%, Train Loss: 0.097808, Train Avg Loss: 0.080991, Time: 0:08:20
Epoch id: 1, Training steps: 1100, Train Acc:  0.00%, Train Loss: 0.086508, Train Avg Loss: 0.081329, Time: 0:09:11
Start evaluation on dev dataset.
Acc. (Correct/Total):  0.00% micro-Prec: 0.0000 micro-Recall:0.0000 micro-F1: 0.0000 dev loss: 0.087232
Epoch id: 2, Training steps: 100, Train Acc:  0.00%, Train Loss: 0.082068, Train Avg Loss: 0.109645, Time: 0:11:08
Epoch id: 2, Training steps: 200, Train Acc:  0.00%, Train Loss: 0.068655, Train Avg Loss: 0.076945, Time: 0:11:58
Epoch id: 2, Training steps: 300, Train Acc:  0.00%, Train Loss: 0.068041, Train Avg Loss: 0.076671, Time: 0:12:48
Epoch id: 2, Training steps: 400, Train Acc:  0.00%, Train Loss: 0.059979, Train Avg Loss: 0.072086, Time: 0:13:39
Epoch id: 2, Training steps: 500, Train Acc:  0.00%, Train Loss: 0.065145, Train Avg Loss: 0.065814, Time: 0:14:29
Epoch id: 2, Training steps: 600, Train Acc:  0.00%, Train Loss: 0.053615, Train Avg Loss: 0.062561, Time: 0:15:19
Epoch id: 2, Training steps: 700, Train Acc:  0.00%, Train Loss: 0.070086, Train Avg Loss: 0.057068, Time: 0:16:10
Epoch id: 2, Training steps: 800, Train Acc:  0.00%, Train Loss: 0.063418, Train Avg Loss: 0.054637, Time: 0:17:00
Epoch id: 2, Training steps: 900, Train Acc: 12.50%, Train Loss: 0.043121, Train Avg Loss: 0.049516, Time: 0:17:50
Epoch id: 2, Training steps: 1000, Train Acc: 12.50%, Train Loss: 0.048890, Train Avg Loss: 0.045705, Time: 0:18:41
Epoch id: 2, Training steps: 1100, Train Acc:  0.00%, Train Loss: 0.042312, Train Avg Loss: 0.045387, Time: 0:19:31
Start evaluation on dev dataset.
Acc. (Correct/Total): 19.67% micro-Prec: 0.8651 micro-Recall:0.2366 micro-F1: 0.3716 dev loss: 0.049029
Start evaluation on test dataset.
Acc. (Correct/Total): 23.22% micro-Prec: 0.9065 micro-Recall:0.2758 micro-F1: 0.4229 dev loss: 0.045520
Epoch id: 3, Training steps: 100, Train Acc: 25.00%, Train Loss: 0.029246, Train Avg Loss: 0.055546, Time: 0:22:14
Epoch id: 3, Training steps: 200, Train Acc: 25.00%, Train Loss: 0.032560, Train Avg Loss: 0.043674, Time: 0:23:05
Epoch id: 3, Training steps: 300, Train Acc: 37.50%, Train Loss: 0.031696, Train Avg Loss: 0.042208, Time: 0:23:55
Epoch id: 3, Training steps: 400, Train Acc:  0.00%, Train Loss: 0.053090, Train Avg Loss: 0.039390, Time: 0:24:45
Epoch id: 3, Training steps: 500, Train Acc: 25.00%, Train Loss: 0.050464, Train Avg Loss: 0.049744, Time: 0:25:36
Epoch id: 3, Training steps: 600, Train Acc: 25.00%, Train Loss: 0.050194, Train Avg Loss: 0.045609, Time: 0:26:26
Epoch id: 3, Training steps: 700, Train Acc:  0.00%, Train Loss: 0.062518, Train Avg Loss: 0.043359, Time: 0:27:16
Epoch id: 3, Training steps: 800, Train Acc: 12.50%, Train Loss: 0.037304, Train Avg Loss: 0.037870, Time: 0:28:06
Epoch id: 3, Training steps: 900, Train Acc: 37.50%, Train Loss: 0.031451, Train Avg Loss: 0.036536, Time: 0:28:57
Epoch id: 3, Training steps: 1000, Train Acc: 37.50%, Train Loss: 0.032369, Train Avg Loss: 0.033455, Time: 0:29:47
Epoch id: 3, Training steps: 1100, Train Acc: 12.50%, Train Loss: 0.038803, Train Avg Loss: 0.033905, Time: 0:30:37
Start evaluation on dev dataset.
Acc. (Correct/Total): 22.41% micro-Prec: 0.8023 micro-Recall:0.2457 micro-F1: 0.3762 dev loss: 0.070743
Start evaluation on test dataset.
Acc. (Correct/Total): 28.45% micro-Prec: 0.8658 micro-Recall:0.3065 micro-F1: 0.4527 dev loss: 0.069052
Epoch id: 4, Training steps: 100, Train Acc: 12.50%, Train Loss: 0.056529, Train Avg Loss: 0.061986, Time: 0:33:21
Epoch id: 4, Training steps: 200, Train Acc: 12.50%, Train Loss: 0.035005, Train Avg Loss: 0.045586, Time: 0:34:11
Epoch id: 4, Training steps: 300, Train Acc: 12.50%, Train Loss: 0.046810, Train Avg Loss: 0.041029, Time: 0:35:01
Epoch id: 4, Training steps: 400, Train Acc: 12.50%, Train Loss: 0.032255, Train Avg Loss: 0.041111, Time: 0:35:51
Epoch id: 4, Training steps: 500, Train Acc: 12.50%, Train Loss: 0.049155, Train Avg Loss: 0.039141, Time: 0:36:42
Epoch id: 4, Training steps: 600, Train Acc: 25.00%, Train Loss: 0.036421, Train Avg Loss: 0.035221, Time: 0:37:32
Epoch id: 4, Training steps: 700, Train Acc: 50.00%, Train Loss: 0.016790, Train Avg Loss: 0.036889, Time: 0:38:22
Epoch id: 4, Training steps: 800, Train Acc: 12.50%, Train Loss: 0.049962, Train Avg Loss: 0.035723, Time: 0:39:12
Epoch id: 4, Training steps: 900, Train Acc: 12.50%, Train Loss: 0.058531, Train Avg Loss: 0.033853, Time: 0:40:03
Epoch id: 4, Training steps: 1000, Train Acc: 37.50%, Train Loss: 0.038316, Train Avg Loss: 0.033280, Time: 0:40:53
Epoch id: 4, Training steps: 1100, Train Acc: 50.00%, Train Loss: 0.025925, Train Avg Loss: 0.031884, Time: 0:41:43
Start evaluation on dev dataset.
Acc. (Correct/Total): 37.19% micro-Prec: 0.7900 micro-Recall:0.4811 micro-F1: 0.5980 dev loss: 0.040682
Start evaluation on test dataset.
Acc. (Correct/Total): 45.48% micro-Prec: 0.8538 micro-Recall:0.5477 micro-F1: 0.6673 dev loss: 0.036467
Epoch id: 5, Training steps: 100, Train Acc: 12.50%, Train Loss: 0.031218, Train Avg Loss: 0.051214, Time: 0:44:27
Epoch id: 5, Training steps: 200, Train Acc: 75.00%, Train Loss: 0.007034, Train Avg Loss: 0.034878, Time: 0:45:17
Epoch id: 5, Training steps: 300, Train Acc: 12.50%, Train Loss: 0.041054, Train Avg Loss: 0.029197, Time: 0:46:07
Epoch id: 5, Training steps: 400, Train Acc: 50.00%, Train Loss: 0.016425, Train Avg Loss: 0.045138, Time: 0:46:58
Epoch id: 5, Training steps: 500, Train Acc: 25.00%, Train Loss: 0.034510, Train Avg Loss: 0.038097, Time: 0:47:48
Epoch id: 5, Training steps: 600, Train Acc: 12.50%, Train Loss: 0.042125, Train Avg Loss: 0.034228, Time: 0:48:38
Epoch id: 5, Training steps: 700, Train Acc: 25.00%, Train Loss: 0.055346, Train Avg Loss: 0.031111, Time: 0:49:29
Epoch id: 5, Training steps: 800, Train Acc: 50.00%, Train Loss: 0.017963, Train Avg Loss: 0.023968, Time: 0:50:19
Epoch id: 5, Training steps: 900, Train Acc: 12.50%, Train Loss: 0.036554, Train Avg Loss: 0.029793, Time: 0:51:09
Epoch id: 5, Training steps: 1000, Train Acc: 37.50%, Train Loss: 0.022200, Train Avg Loss: 0.032539, Time: 0:51:59
Epoch id: 5, Training steps: 1100, Train Acc: 37.50%, Train Loss: 0.033380, Train Avg Loss: 0.034000, Time: 0:52:50
Start evaluation on dev dataset.
Acc. (Correct/Total): 31.38% micro-Prec: 0.7538 micro-Recall:0.3856 micro-F1: 0.5102 dev loss: 0.051081
Epoch id: 6, Training steps: 100, Train Acc: 62.50%, Train Loss: 0.015902, Train Avg Loss: 0.039834, Time: 0:54:46
Epoch id: 6, Training steps: 200, Train Acc: 50.00%, Train Loss: 0.014588, Train Avg Loss: 0.025408, Time: 0:55:36
Epoch id: 6, Training steps: 300, Train Acc: 62.50%, Train Loss: 0.021196, Train Avg Loss: 0.020334, Time: 0:56:27
Epoch id: 6, Training steps: 400, Train Acc: 37.50%, Train Loss: 0.028722, Train Avg Loss: 0.022421, Time: 0:57:17
Epoch id: 6, Training steps: 500, Train Acc: 62.50%, Train Loss: 0.014745, Train Avg Loss: 0.020821, Time: 0:58:07
Epoch id: 6, Training steps: 600, Train Acc: 37.50%, Train Loss: 0.020844, Train Avg Loss: 0.021696, Time: 0:58:58
Epoch id: 6, Training steps: 700, Train Acc: 50.00%, Train Loss: 0.021027, Train Avg Loss: 0.022730, Time: 0:59:48
Epoch id: 6, Training steps: 800, Train Acc: 37.50%, Train Loss: 0.016233, Train Avg Loss: 0.024196, Time: 1:00:38
Epoch id: 6, Training steps: 900, Train Acc: 50.00%, Train Loss: 0.016178, Train Avg Loss: 0.020361, Time: 1:01:29
Epoch id: 6, Training steps: 1000, Train Acc: 50.00%, Train Loss: 0.012334, Train Avg Loss: 0.021154, Time: 1:02:19
Epoch id: 6, Training steps: 1100, Train Acc: 25.00%, Train Loss: 0.025142, Train Avg Loss: 0.020725, Time: 1:03:09
Start evaluation on dev dataset.
Acc. (Correct/Total): 43.91% micro-Prec: 0.8111 micro-Recall:0.5422 micro-F1: 0.6500 dev loss: 0.034545
Start evaluation on test dataset.
Acc. (Correct/Total): 49.98% micro-Prec: 0.8681 micro-Recall:0.5936 micro-F1: 0.7051 dev loss: 0.030281
Epoch id: 7, Training steps: 100, Train Acc: 25.00%, Train Loss: 0.028436, Train Avg Loss: 0.028626, Time: 1:05:53
Epoch id: 7, Training steps: 200, Train Acc: 25.00%, Train Loss: 0.023502, Train Avg Loss: 0.020107, Time: 1:06:43
Epoch id: 7, Training steps: 300, Train Acc: 50.00%, Train Loss: 0.025199, Train Avg Loss: 0.018917, Time: 1:07:33
Epoch id: 7, Training steps: 400, Train Acc: 75.00%, Train Loss: 0.007139, Train Avg Loss: 0.017161, Time: 1:08:24
Epoch id: 7, Training steps: 500, Train Acc: 50.00%, Train Loss: 0.013971, Train Avg Loss: 0.015474, Time: 1:09:14
Epoch id: 7, Training steps: 600, Train Acc: 25.00%, Train Loss: 0.014770, Train Avg Loss: 0.016087, Time: 1:10:04
Epoch id: 7, Training steps: 700, Train Acc: 62.50%, Train Loss: 0.012079, Train Avg Loss: 0.016111, Time: 1:10:55
Epoch id: 7, Training steps: 800, Train Acc: 62.50%, Train Loss: 0.010013, Train Avg Loss: 0.016644, Time: 1:11:45
Epoch id: 7, Training steps: 900, Train Acc: 37.50%, Train Loss: 0.023839, Train Avg Loss: 0.017604, Time: 1:12:35
Epoch id: 7, Training steps: 1000, Train Acc: 37.50%, Train Loss: 0.014283, Train Avg Loss: 0.015851, Time: 1:13:25
Epoch id: 7, Training steps: 1100, Train Acc: 37.50%, Train Loss: 0.021430, Train Avg Loss: 0.016241, Time: 1:14:16
Start evaluation on dev dataset.
Acc. (Correct/Total): 47.12% micro-Prec: 0.7938 micro-Recall:0.5995 micro-F1: 0.6831 dev loss: 0.036717
Start evaluation on test dataset.
Acc. (Correct/Total): 54.43% micro-Prec: 0.8485 micro-Recall:0.6502 micro-F1: 0.7362 dev loss: 0.032542
Epoch id: 8, Training steps: 100, Train Acc: 25.00%, Train Loss: 0.014571, Train Avg Loss: 0.025725, Time: 1:16:59
Epoch id: 8, Training steps: 200, Train Acc: 25.00%, Train Loss: 0.021327, Train Avg Loss: 0.019100, Time: 1:17:49
Epoch id: 8, Training steps: 300, Train Acc: 37.50%, Train Loss: 0.023680, Train Avg Loss: 0.029819, Time: 1:18:39
Epoch id: 8, Training steps: 400, Train Acc: 37.50%, Train Loss: 0.011223, Train Avg Loss: 0.025288, Time: 1:19:30
Epoch id: 8, Training steps: 500, Train Acc: 50.00%, Train Loss: 0.018074, Train Avg Loss: 0.024191, Time: 1:20:20
Epoch id: 8, Training steps: 600, Train Acc: 62.50%, Train Loss: 0.007615, Train Avg Loss: 0.021835, Time: 1:21:10
Epoch id: 8, Training steps: 700, Train Acc: 25.00%, Train Loss: 0.017115, Train Avg Loss: 0.020079, Time: 1:22:00
Epoch id: 8, Training steps: 800, Train Acc: 37.50%, Train Loss: 0.016774, Train Avg Loss: 0.019055, Time: 1:22:51
Epoch id: 8, Training steps: 900, Train Acc: 87.50%, Train Loss: 0.007350, Train Avg Loss: 0.019786, Time: 1:23:41
Epoch id: 8, Training steps: 1000, Train Acc: 75.00%, Train Loss: 0.009821, Train Avg Loss: 0.018791, Time: 1:24:31
Epoch id: 8, Training steps: 1100, Train Acc: 37.50%, Train Loss: 0.025520, Train Avg Loss: 0.018337, Time: 1:25:21
Start evaluation on dev dataset.
Acc. (Correct/Total): 42.80% micro-Prec: 0.7821 micro-Recall:0.5322 micro-F1: 0.6334 dev loss: 0.039833
Epoch id: 9, Training steps: 100, Train Acc: 62.50%, Train Loss: 0.011142, Train Avg Loss: 0.023314, Time: 1:27:17
Epoch id: 9, Training steps: 200, Train Acc: 87.50%, Train Loss: 0.004516, Train Avg Loss: 0.015569, Time: 1:28:07
Epoch id: 9, Training steps: 300, Train Acc: 50.00%, Train Loss: 0.016002, Train Avg Loss: 0.013804, Time: 1:28:57
Epoch id: 9, Training steps: 400, Train Acc: 75.00%, Train Loss: 0.010989, Train Avg Loss: 0.012233, Time: 1:29:48
Epoch id: 9, Training steps: 500, Train Acc: 62.50%, Train Loss: 0.013029, Train Avg Loss: 0.014787, Time: 1:30:38
Epoch id: 9, Training steps: 600, Train Acc: 37.50%, Train Loss: 0.022163, Train Avg Loss: 0.014536, Time: 1:31:28
Epoch id: 9, Training steps: 700, Train Acc: 50.00%, Train Loss: 0.017639, Train Avg Loss: 0.013767, Time: 1:32:18
Epoch id: 9, Training steps: 800, Train Acc: 50.00%, Train Loss: 0.017606, Train Avg Loss: 0.013742, Time: 1:33:08
Epoch id: 9, Training steps: 900, Train Acc: 87.50%, Train Loss: 0.007456, Train Avg Loss: 0.013695, Time: 1:33:58
Epoch id: 9, Training steps: 1000, Train Acc: 87.50%, Train Loss: 0.010447, Train Avg Loss: 0.012820, Time: 1:34:49
Epoch id: 9, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.006073, Train Avg Loss: 0.012235, Time: 1:35:39
Start evaluation on dev dataset.
Acc. (Correct/Total): 50.43% micro-Prec: 0.7833 micro-Recall:0.6400 micro-F1: 0.7044 dev loss: 0.036757
Start evaluation on test dataset.
Acc. (Correct/Total): 55.97% micro-Prec: 0.8163 micro-Recall:0.6767 micro-F1: 0.7400 dev loss: 0.031892
Epoch id: 10, Training steps: 100, Train Acc: 75.00%, Train Loss: 0.010743, Train Avg Loss: 0.013800, Time: 1:38:22
Epoch id: 10, Training steps: 200, Train Acc: 75.00%, Train Loss: 0.007579, Train Avg Loss: 0.011341, Time: 1:39:13
Epoch id: 10, Training steps: 300, Train Acc: 50.00%, Train Loss: 0.014128, Train Avg Loss: 0.012081, Time: 1:40:03
Epoch id: 10, Training steps: 400, Train Acc: 50.00%, Train Loss: 0.014590, Train Avg Loss: 0.011814, Time: 1:40:53
Epoch id: 10, Training steps: 500, Train Acc: 50.00%, Train Loss: 0.012663, Train Avg Loss: 0.012453, Time: 1:41:43
Epoch id: 10, Training steps: 600, Train Acc: 50.00%, Train Loss: 0.008769, Train Avg Loss: 0.013105, Time: 1:42:34
Epoch id: 10, Training steps: 700, Train Acc: 75.00%, Train Loss: 0.004632, Train Avg Loss: 0.011215, Time: 1:43:24
Epoch id: 10, Training steps: 800, Train Acc: 75.00%, Train Loss: 0.012217, Train Avg Loss: 0.011780, Time: 1:44:14
Epoch id: 10, Training steps: 900, Train Acc: 75.00%, Train Loss: 0.009922, Train Avg Loss: 0.015009, Time: 1:45:04
Epoch id: 10, Training steps: 1000, Train Acc: 25.00%, Train Loss: 0.018903, Train Avg Loss: 0.013291, Time: 1:45:55
Epoch id: 10, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.003853, Train Avg Loss: 0.012768, Time: 1:46:45
Start evaluation on dev dataset.
Acc. (Correct/Total): 48.22% micro-Prec: 0.7715 micro-Recall:0.6209 micro-F1: 0.6881 dev loss: 0.039525
Epoch id: 11, Training steps: 100, Train Acc: 37.50%, Train Loss: 0.026342, Train Avg Loss: 0.015595, Time: 1:48:41
Epoch id: 11, Training steps: 200, Train Acc: 62.50%, Train Loss: 0.020184, Train Avg Loss: 0.010660, Time: 1:49:31
Epoch id: 11, Training steps: 300, Train Acc: 50.00%, Train Loss: 0.010392, Train Avg Loss: 0.011083, Time: 1:50:21
Epoch id: 11, Training steps: 400, Train Acc: 50.00%, Train Loss: 0.016130, Train Avg Loss: 0.009831, Time: 1:51:12
Epoch id: 11, Training steps: 500, Train Acc: 87.50%, Train Loss: 0.005374, Train Avg Loss: 0.008876, Time: 1:52:02
Epoch id: 11, Training steps: 600, Train Acc: 62.50%, Train Loss: 0.004998, Train Avg Loss: 0.009652, Time: 1:52:52
Epoch id: 11, Training steps: 700, Train Acc: 62.50%, Train Loss: 0.006137, Train Avg Loss: 0.008649, Time: 1:53:42
Epoch id: 11, Training steps: 800, Train Acc: 50.00%, Train Loss: 0.010612, Train Avg Loss: 0.009802, Time: 1:54:33
Epoch id: 11, Training steps: 900, Train Acc: 87.50%, Train Loss: 0.010123, Train Avg Loss: 0.008938, Time: 1:55:23
Epoch id: 11, Training steps: 1000, Train Acc: 62.50%, Train Loss: 0.007679, Train Avg Loss: 0.010109, Time: 1:56:13
Epoch id: 11, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.002439, Train Avg Loss: 0.008546, Time: 1:57:03
Start evaluation on dev dataset.
Acc. (Correct/Total): 51.39% micro-Prec: 0.7836 micro-Recall:0.6471 micro-F1: 0.7089 dev loss: 0.034136
Start evaluation on test dataset.
Acc. (Correct/Total): 57.52% micro-Prec: 0.8306 micro-Recall:0.6835 micro-F1: 0.7499 dev loss: 0.028826
Epoch id: 12, Training steps: 100, Train Acc: 75.00%, Train Loss: 0.009905, Train Avg Loss: 0.011147, Time: 1:59:46
Epoch id: 12, Training steps: 200, Train Acc: 50.00%, Train Loss: 0.019326, Train Avg Loss: 0.006647, Time: 2:00:37
Epoch id: 12, Training steps: 300, Train Acc: 100.00%, Train Loss: 0.001349, Train Avg Loss: 0.006969, Time: 2:01:27
Epoch id: 12, Training steps: 400, Train Acc: 100.00%, Train Loss: 0.001987, Train Avg Loss: 0.006537, Time: 2:02:17
Epoch id: 12, Training steps: 500, Train Acc: 62.50%, Train Loss: 0.008749, Train Avg Loss: 0.007526, Time: 2:03:08
Epoch id: 12, Training steps: 600, Train Acc: 75.00%, Train Loss: 0.005322, Train Avg Loss: 0.006716, Time: 2:03:58
Epoch id: 12, Training steps: 700, Train Acc: 62.50%, Train Loss: 0.016845, Train Avg Loss: 0.006827, Time: 2:04:48
Epoch id: 12, Training steps: 800, Train Acc: 75.00%, Train Loss: 0.007217, Train Avg Loss: 0.006232, Time: 2:05:38
Epoch id: 12, Training steps: 900, Train Acc: 62.50%, Train Loss: 0.007994, Train Avg Loss: 0.007083, Time: 2:06:29
Epoch id: 12, Training steps: 1000, Train Acc: 50.00%, Train Loss: 0.012654, Train Avg Loss: 0.007580, Time: 2:07:19
Epoch id: 12, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.003592, Train Avg Loss: 0.007796, Time: 2:08:09
Start evaluation on dev dataset.
Acc. (Correct/Total): 52.98% micro-Prec: 0.7895 micro-Recall:0.6701 micro-F1: 0.7249 dev loss: 0.033287
Start evaluation on test dataset.
Acc. (Correct/Total): 59.12% micro-Prec: 0.8227 micro-Recall:0.7097 micro-F1: 0.7620 dev loss: 0.029197
Epoch id: 13, Training steps: 100, Train Acc: 75.00%, Train Loss: 0.005515, Train Avg Loss: 0.010358, Time: 2:10:53
Epoch id: 13, Training steps: 200, Train Acc: 100.00%, Train Loss: 0.002226, Train Avg Loss: 0.005800, Time: 2:11:44
Epoch id: 13, Training steps: 300, Train Acc: 62.50%, Train Loss: 0.005698, Train Avg Loss: 0.005698, Time: 2:12:34
Epoch id: 13, Training steps: 400, Train Acc: 75.00%, Train Loss: 0.004354, Train Avg Loss: 0.006040, Time: 2:13:24
Epoch id: 13, Training steps: 500, Train Acc: 75.00%, Train Loss: 0.005426, Train Avg Loss: 0.005671, Time: 2:14:15
Epoch id: 13, Training steps: 600, Train Acc: 62.50%, Train Loss: 0.005159, Train Avg Loss: 0.005516, Time: 2:15:05
Epoch id: 13, Training steps: 700, Train Acc: 100.00%, Train Loss: 0.002091, Train Avg Loss: 0.005953, Time: 2:15:55
Epoch id: 13, Training steps: 800, Train Acc: 100.00%, Train Loss: 0.002734, Train Avg Loss: 0.006124, Time: 2:16:46
Epoch id: 13, Training steps: 900, Train Acc: 87.50%, Train Loss: 0.003128, Train Avg Loss: 0.005624, Time: 2:17:36
Epoch id: 13, Training steps: 1000, Train Acc: 75.00%, Train Loss: 0.005221, Train Avg Loss: 0.006042, Time: 2:18:26
Epoch id: 13, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.001645, Train Avg Loss: 0.006204, Time: 2:19:17
Start evaluation on dev dataset.
Acc. (Correct/Total): 52.02% micro-Prec: 0.7832 micro-Recall:0.6562 micro-F1: 0.7141 dev loss: 0.033582
Epoch id: 14, Training steps: 100, Train Acc: 62.50%, Train Loss: 0.007527, Train Avg Loss: 0.007191, Time: 2:21:13
Epoch id: 14, Training steps: 200, Train Acc: 87.50%, Train Loss: 0.003771, Train Avg Loss: 0.005434, Time: 2:22:03
Epoch id: 14, Training steps: 300, Train Acc: 75.00%, Train Loss: 0.003798, Train Avg Loss: 0.005047, Time: 2:22:53
Epoch id: 14, Training steps: 400, Train Acc: 75.00%, Train Loss: 0.002981, Train Avg Loss: 0.004665, Time: 2:23:44
Epoch id: 14, Training steps: 500, Train Acc: 87.50%, Train Loss: 0.004738, Train Avg Loss: 0.004817, Time: 2:24:34
Epoch id: 14, Training steps: 600, Train Acc: 75.00%, Train Loss: 0.008028, Train Avg Loss: 0.004630, Time: 2:25:24
Epoch id: 14, Training steps: 700, Train Acc: 87.50%, Train Loss: 0.003660, Train Avg Loss: 0.004524, Time: 2:26:14
Epoch id: 14, Training steps: 800, Train Acc: 75.00%, Train Loss: 0.004150, Train Avg Loss: 0.005169, Time: 2:27:05
Epoch id: 14, Training steps: 900, Train Acc: 87.50%, Train Loss: 0.002458, Train Avg Loss: 0.005072, Time: 2:27:55
Epoch id: 14, Training steps: 1000, Train Acc: 75.00%, Train Loss: 0.011328, Train Avg Loss: 0.004706, Time: 2:28:45
Epoch id: 14, Training steps: 1100, Train Acc: 75.00%, Train Loss: 0.007456, Train Avg Loss: 0.004584, Time: 2:29:36
Start evaluation on dev dataset.
Acc. (Correct/Total): 53.12% micro-Prec: 0.7760 micro-Recall:0.6818 micro-F1: 0.7258 dev loss: 0.035553
Start evaluation on test dataset.
Acc. (Correct/Total): 60.62% micro-Prec: 0.8218 micro-Recall:0.7245 micro-F1: 0.7701 dev loss: 0.029885
Epoch id: 15, Training steps: 100, Train Acc: 75.00%, Train Loss: 0.007920, Train Avg Loss: 0.005687, Time: 2:32:19
Epoch id: 15, Training steps: 200, Train Acc: 75.00%, Train Loss: 0.006284, Train Avg Loss: 0.003999, Time: 2:33:10
Epoch id: 15, Training steps: 300, Train Acc: 100.00%, Train Loss: 0.001166, Train Avg Loss: 0.003560, Time: 2:34:00
Epoch id: 15, Training steps: 400, Train Acc: 87.50%, Train Loss: 0.003757, Train Avg Loss: 0.003882, Time: 2:34:51
Epoch id: 15, Training steps: 500, Train Acc: 87.50%, Train Loss: 0.002810, Train Avg Loss: 0.004064, Time: 2:35:41
Epoch id: 15, Training steps: 600, Train Acc: 75.00%, Train Loss: 0.003339, Train Avg Loss: 0.004392, Time: 2:36:32
Epoch id: 15, Training steps: 700, Train Acc: 62.50%, Train Loss: 0.006878, Train Avg Loss: 0.003714, Time: 2:37:22
Epoch id: 15, Training steps: 800, Train Acc: 62.50%, Train Loss: 0.004925, Train Avg Loss: 0.003832, Time: 2:38:12
Epoch id: 15, Training steps: 900, Train Acc: 75.00%, Train Loss: 0.006064, Train Avg Loss: 0.003835, Time: 2:39:03
Epoch id: 15, Training steps: 1000, Train Acc: 87.50%, Train Loss: 0.003454, Train Avg Loss: 0.003589, Time: 2:39:53
Epoch id: 15, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.001902, Train Avg Loss: 0.004157, Time: 2:40:44
Start evaluation on dev dataset.
Acc. (Correct/Total): 54.03% micro-Prec: 0.7834 micro-Recall:0.6792 micro-F1: 0.7276 dev loss: 0.033917
Start evaluation on test dataset.
Acc. (Correct/Total): 60.47% micro-Prec: 0.8302 micro-Recall:0.7226 micro-F1: 0.7727 dev loss: 0.028751
Epoch id: 16, Training steps: 100, Train Acc: 100.00%, Train Loss: 0.001892, Train Avg Loss: 0.004841, Time: 2:43:28
Epoch id: 16, Training steps: 200, Train Acc: 100.00%, Train Loss: 0.002235, Train Avg Loss: 0.003363, Time: 2:44:19
Epoch id: 16, Training steps: 300, Train Acc: 100.00%, Train Loss: 0.003138, Train Avg Loss: 0.003377, Time: 2:45:09
Epoch id: 16, Training steps: 400, Train Acc: 75.00%, Train Loss: 0.003777, Train Avg Loss: 0.003526, Time: 2:46:00
Epoch id: 16, Training steps: 500, Train Acc: 75.00%, Train Loss: 0.004205, Train Avg Loss: 0.003376, Time: 2:46:50
Epoch id: 16, Training steps: 600, Train Acc: 100.00%, Train Loss: 0.002919, Train Avg Loss: 0.002999, Time: 2:47:40
Epoch id: 16, Training steps: 700, Train Acc: 100.00%, Train Loss: 0.000684, Train Avg Loss: 0.003638, Time: 2:48:31
Epoch id: 16, Training steps: 800, Train Acc: 62.50%, Train Loss: 0.004478, Train Avg Loss: 0.003218, Time: 2:49:21
Epoch id: 16, Training steps: 900, Train Acc: 100.00%, Train Loss: 0.000927, Train Avg Loss: 0.003351, Time: 2:50:12
Epoch id: 16, Training steps: 1000, Train Acc: 62.50%, Train Loss: 0.002744, Train Avg Loss: 0.003653, Time: 2:51:02
Epoch id: 16, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.001775, Train Avg Loss: 0.003606, Time: 2:51:53
Start evaluation on dev dataset.
Acc. (Correct/Total): 51.87% micro-Prec: 0.7737 micro-Recall:0.6640 micro-F1: 0.7146 dev loss: 0.034999
Epoch id: 17, Training steps: 100, Train Acc: 100.00%, Train Loss: 0.001822, Train Avg Loss: 0.004789, Time: 2:53:49
Epoch id: 17, Training steps: 200, Train Acc: 75.00%, Train Loss: 0.008284, Train Avg Loss: 0.003557, Time: 2:54:39
Epoch id: 17, Training steps: 300, Train Acc: 100.00%, Train Loss: 0.000924, Train Avg Loss: 0.003251, Time: 2:55:30
Epoch id: 17, Training steps: 400, Train Acc: 62.50%, Train Loss: 0.006016, Train Avg Loss: 0.003300, Time: 2:56:20
Epoch id: 17, Training steps: 500, Train Acc: 87.50%, Train Loss: 0.001368, Train Avg Loss: 0.002984, Time: 2:57:11
Epoch id: 17, Training steps: 600, Train Acc: 87.50%, Train Loss: 0.002809, Train Avg Loss: 0.002959, Time: 2:58:01
Epoch id: 17, Training steps: 700, Train Acc: 87.50%, Train Loss: 0.002719, Train Avg Loss: 0.002973, Time: 2:58:52
Epoch id: 17, Training steps: 800, Train Acc: 87.50%, Train Loss: 0.002519, Train Avg Loss: 0.002675, Time: 2:59:42
Epoch id: 17, Training steps: 900, Train Acc: 75.00%, Train Loss: 0.004005, Train Avg Loss: 0.002733, Time: 3:00:33
Epoch id: 17, Training steps: 1000, Train Acc: 62.50%, Train Loss: 0.004046, Train Avg Loss: 0.002639, Time: 3:01:23
Epoch id: 17, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.002990, Train Avg Loss: 0.003156, Time: 3:02:13
Start evaluation on dev dataset.
Acc. (Correct/Total): 53.31% micro-Prec: 0.7729 micro-Recall:0.6821 micro-F1: 0.7247 dev loss: 0.034935
Epoch id: 18, Training steps: 100, Train Acc: 100.00%, Train Loss: 0.001395, Train Avg Loss: 0.003743, Time: 3:04:10
Epoch id: 18, Training steps: 200, Train Acc: 100.00%, Train Loss: 0.001456, Train Avg Loss: 0.002702, Time: 3:05:00
Epoch id: 18, Training steps: 300, Train Acc: 100.00%, Train Loss: 0.001234, Train Avg Loss: 0.002253, Time: 3:05:51
Epoch id: 18, Training steps: 400, Train Acc: 75.00%, Train Loss: 0.002612, Train Avg Loss: 0.002639, Time: 3:06:41
Epoch id: 18, Training steps: 500, Train Acc: 87.50%, Train Loss: 0.004512, Train Avg Loss: 0.002402, Time: 3:07:32
Epoch id: 18, Training steps: 600, Train Acc: 100.00%, Train Loss: 0.000459, Train Avg Loss: 0.002734, Time: 3:08:22
Epoch id: 18, Training steps: 700, Train Acc: 100.00%, Train Loss: 0.000763, Train Avg Loss: 0.002316, Time: 3:09:12
Epoch id: 18, Training steps: 800, Train Acc: 87.50%, Train Loss: 0.002912, Train Avg Loss: 0.002803, Time: 3:10:03
Epoch id: 18, Training steps: 900, Train Acc: 100.00%, Train Loss: 0.001597, Train Avg Loss: 0.002630, Time: 3:10:53
Epoch id: 18, Training steps: 1000, Train Acc: 100.00%, Train Loss: 0.001304, Train Avg Loss: 0.002300, Time: 3:11:44
Epoch id: 18, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.002231, Train Avg Loss: 0.002293, Time: 3:12:34
Start evaluation on dev dataset.
Acc. (Correct/Total): 54.37% micro-Prec: 0.7794 micro-Recall:0.6954 micro-F1: 0.7350 dev loss: 0.034564
Start evaluation on test dataset.
Acc. (Correct/Total): 61.15% micro-Prec: 0.8223 micro-Recall:0.7346 micro-F1: 0.7760 dev loss: 0.028790
Epoch id: 19, Training steps: 100, Train Acc: 62.50%, Train Loss: 0.002802, Train Avg Loss: 0.003297, Time: 3:15:18
Epoch id: 19, Training steps: 200, Train Acc: 87.50%, Train Loss: 0.001539, Train Avg Loss: 0.002455, Time: 3:16:08
Epoch id: 19, Training steps: 300, Train Acc: 100.00%, Train Loss: 0.001166, Train Avg Loss: 0.002189, Time: 3:16:59
Epoch id: 19, Training steps: 400, Train Acc: 100.00%, Train Loss: 0.001431, Train Avg Loss: 0.002057, Time: 3:17:49
Epoch id: 19, Training steps: 500, Train Acc: 100.00%, Train Loss: 0.001267, Train Avg Loss: 0.002510, Time: 3:18:40
Epoch id: 19, Training steps: 600, Train Acc: 100.00%, Train Loss: 0.001104, Train Avg Loss: 0.002198, Time: 3:19:30
Epoch id: 19, Training steps: 700, Train Acc: 75.00%, Train Loss: 0.002949, Train Avg Loss: 0.002381, Time: 3:20:20
Epoch id: 19, Training steps: 800, Train Acc: 100.00%, Train Loss: 0.000904, Train Avg Loss: 0.002221, Time: 3:21:11
Epoch id: 19, Training steps: 900, Train Acc: 75.00%, Train Loss: 0.003803, Train Avg Loss: 0.002367, Time: 3:22:01
Epoch id: 19, Training steps: 1000, Train Acc: 100.00%, Train Loss: 0.001268, Train Avg Loss: 0.002135, Time: 3:22:52
Epoch id: 19, Training steps: 1100, Train Acc: 87.50%, Train Loss: 0.001777, Train Avg Loss: 0.002164, Time: 3:23:42
Start evaluation on dev dataset.
Acc. (Correct/Total): 53.65% micro-Prec: 0.7781 micro-Recall:0.6925 micro-F1: 0.7328 dev loss: 0.034570
Epoch id: 20, Training steps: 100, Train Acc: 100.00%, Train Loss: 0.001951, Train Avg Loss: 0.002944, Time: 3:25:38
Epoch id: 20, Training steps: 200, Train Acc: 100.00%, Train Loss: 0.000331, Train Avg Loss: 0.001985, Time: 3:26:29
Epoch id: 20, Training steps: 300, Train Acc: 87.50%, Train Loss: 0.002119, Train Avg Loss: 0.002071, Time: 3:27:19
Epoch id: 20, Training steps: 400, Train Acc: 100.00%, Train Loss: 0.000333, Train Avg Loss: 0.002232, Time: 3:28:10
Epoch id: 20, Training steps: 500, Train Acc: 87.50%, Train Loss: 0.001902, Train Avg Loss: 0.002062, Time: 3:29:00
Epoch id: 20, Training steps: 600, Train Acc: 75.00%, Train Loss: 0.005421, Train Avg Loss: 0.002154, Time: 3:29:51
Epoch id: 20, Training steps: 700, Train Acc: 100.00%, Train Loss: 0.000622, Train Avg Loss: 0.001991, Time: 3:30:41
Epoch id: 20, Training steps: 800, Train Acc: 87.50%, Train Loss: 0.003771, Train Avg Loss: 0.002034, Time: 3:31:32
Epoch id: 20, Training steps: 900, Train Acc: 100.00%, Train Loss: 0.000833, Train Avg Loss: 0.002174, Time: 3:32:22
Epoch id: 20, Training steps: 1000, Train Acc: 100.00%, Train Loss: 0.001423, Train Avg Loss: 0.002224, Time: 3:33:12
Epoch id: 20, Training steps: 1100, Train Acc: 100.00%, Train Loss: 0.000436, Train Avg Loss: 0.002142, Time: 3:34:03
Start evaluation on dev dataset.
Acc. (Correct/Total): 54.03% micro-Prec: 0.7798 micro-Recall:0.6912 micro-F1: 0.7328 dev loss: 0.034556
Final evaluation on the test dataset.
The number of evaluation instances:  2067
Acc. (Correct/Total): 61.15% micro-Prec: 0.8223 micro-Recall:0.7346 micro-F1: 0.7760 dev loss: 0.028790
              precision    recall  f1-score   support

         教育学     0.8555    0.9336    0.8929       241
          法学     0.8384    0.8571    0.8477       224
      中国语言文学     0.8773    0.7730    0.8218       185
         政治学     0.7958    0.6933    0.7410       163
         社会学     0.8392    0.7643    0.8000       157
         心理学     0.8701    0.5447    0.6700       123
       应用经济学     0.7683    0.5385    0.6332       117
         历史学     0.8415    0.6330    0.7225       109
     环境科学与工程     0.9082    0.8241    0.8641       108
          哲学     0.8500    0.7010    0.7684        97
      外国语言文学     0.8333    0.7059    0.7643        85
         生物学     0.7857    0.8354    0.8098        79
      交通运输工程     0.8929    0.9615    0.9259        78
        临床医学     0.9219    0.7763    0.8429        76
    计算机科学与技术     0.8594    0.7746    0.8148        71
        土木工程     0.9275    0.9697    0.9481        66
   航空宇航科学与技术     0.9649    0.9016    0.9322        61
         民族学     0.7059    0.4364    0.5393        55
   公共卫生与预防医学     0.6290    0.7647    0.6903        51
         美术学     0.8679    0.9200    0.8932        50
         艺术学     0.7805    0.7442    0.7619        43
         地理学     0.7895    0.7143    0.7500        42
         体育学     0.8846    0.5750    0.6970        40
       理论经济学     0.7568    0.7368    0.7467        38
         中医学     0.9091    0.8108    0.8571        37
         物理学     0.7692    0.8333    0.8000        36
          林学     0.8182    0.5455    0.6545        33
          数学     0.8421    0.5000    0.6275        32
     电子科学与技术     0.5152    0.5484    0.5312        31
        基础医学     0.5417    0.4483    0.4906        29
        工商管理     1.0000    0.5926    0.7442        27
       新闻传播学     0.8333    0.6818    0.7500        22
         天文学     0.8182    0.8182    0.8182        22
         地质学     0.8750    0.6667    0.7568        21
         畜牧学     0.8571    0.8571    0.8571        21
   军事思想及军事历史     0.8824    0.7500    0.8108        20
     管理科学与工程     0.5833    0.7778    0.6667        18
     测绘科学与技术     0.7500    0.8824    0.8108        17
        水利工程     0.9091    0.6250    0.7407        16
        大气科学     0.7500    0.7500    0.7500        16
     兵器科学与技术     0.6875    0.7333    0.7097        15
       地球物理学     1.0000    0.2143    0.3529        14
        电气工程     1.0000    0.5385    0.7000        13
         作物学     0.6667    0.6154    0.6400        13
     控制科学与工程     0.2727    0.2308    0.2500        13
     信息与通信工程     0.6667    0.4615    0.5455        13
        公共管理     0.1765    0.2308    0.2000        13
         建筑学     1.0000    0.2308    0.3750        13
     化学工程与技术     0.6667    0.6667    0.6667        12
          力学     1.0000    0.6364    0.7778        11
        海洋科学     0.9091    0.9091    0.9091        11
     轻工技术与工程     0.5714    0.3636    0.4444        11
        农业工程     1.0000    0.3000    0.4615        10
         园艺学     0.8333    1.0000    0.9091        10
       中西医结合     1.0000    0.6000    0.7500        10
        机械工程     0.8571    0.6667    0.7500         9
       科学技术史     1.0000    0.6250    0.7692         8
     船舶与海洋工程     0.8571    0.7500    0.8000         8
   图书情报与档案管理     0.7143    0.6250    0.6667         8
        植物保护     0.8889    1.0000    0.9412         8
     材料科学与工程     0.8571    0.7500    0.8000         8
         统计学     0.6364    0.8750    0.7368         8
          化学     0.7778    0.8750    0.8235         8
     食品科学与工程     0.8000    0.5000    0.6154         8
          水产     1.0000    1.0000    1.0000         7
          药学     1.0000    0.8571    0.9231         7
     农业资源与环境     0.8333    0.7143    0.7692         7
         世界史     0.7500    0.8571    0.8000         7
        系统科学     0.8571    0.8571    0.8571         7
      农林经济管理     0.5000    0.8000    0.6154         5
       军队指挥学     1.0000    0.6000    0.7500         5
        矿业工程     0.6667    0.4000    0.5000         5
     纺织科学与工程     0.7143    1.0000    0.8333         5
  动力工程及工程热物理     0.0000    0.0000    0.0000         4
        林业工程     0.3333    0.2500    0.2857         4
     仪器科学与技术     0.0000    0.0000    0.0000         3
         战略学     1.0000    0.3333    0.5000         3
   地质资源与地质工程     0.5000    0.6667    0.5714         3
        旅游管理     1.0000    0.3333    0.5000         3
 图书馆、情报与档案管理     0.0000    0.0000    0.0000         2
        冶金工程     1.0000    0.5000    0.6667         2
      核科学与技术     0.0000    0.0000    0.0000         2

   micro avg     0.8223    0.7346    0.7760      3093
   macro avg     0.7645    0.6431    0.6794      3093
weighted avg     0.8255    0.7346    0.7685      3093
 samples avg     0.7914    0.7524    0.7573      3093

